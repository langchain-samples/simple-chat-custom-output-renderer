[
  {
    "role": "user",
    "id": "7f7fac88-2541-4a2d-bcba-3997dd1ca39b",
    "content": "What is tool in langraph or langchain"
  },
  {
    "role": "assistant",
    "tool_calls": [
      {
        "type": "function",
        "id": "call_qFSBi0VujIidhMjBEUe8KnQG",
        "function": {
          "name": "SearchDocsByLangChain",
          "arguments": "{\"language\": \"python\", \"page_size\": 5, \"query\": \"tools\"}"
        }
      },
      {
        "type": "function",
        "id": "call_FLbA3fadTLm4243aCxnF9duL",
        "function": {
          "name": "search_support_articles",
          "arguments": "{\"collections\": \"OSS (LangChain and LangGraph),LangSmith Studio,SDKs and APIs\"}"
        }
      }
    ],
    "id": "lc_run--019b384d-3db2-7340-a2f9-862a0dac60b9",
    "content": ""
  },
  {
    "role": "tool",
    "name": "SearchDocsByLangChain",
    "tool_call_id": "call_qFSBi0VujIidhMjBEUe8KnQG",
    "id": "4be41f80-94b1-4c42-99f9-b571406f3cad",
    "content": "Result 1:\nTitle: Configure prompt settings\nLink: https://docs.langchain.comlangsmith/managing-model-configurations\nContent: The LangSmith [playground](/langsmith/prompt-engineering-concepts#prompt-playground) enables you to control various settings for your prompts. The **Prompt Settings** window contains:\n\n* [Model configuration](#model-configurations)\n* [Tool settings](#tool-settings)\n* [Prompt formatting](#prompt-formatting)\n\nTo access **Prompt Settings**:\n\n1. Navigate to the **Playground** in the left sidebar.\n2. Under the **Prompts** heading select the gear <Icon icon=\"gear\" iconType=\"solid\" /> icon next to the model name, which will launch the **Prompt Settings** window.\n\n   <div style={{ textAlign: 'center' }}>\n     <img className=\"block dark:hidden\" src=\"https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=6c0f7d7012b1e5295fe545149f955e6b\" alt=\"Model Configuration window in the LangSmith UI, settings for Provider, Model, Temperature, Max Output Tokens, Top P, Presence Penalty, Frequency Penalty, Reasoning Effort, etc.\" data-og-width=\"886\" width=\"886\" data-og-height=\"689\" height=\"689\" data-path=\"langsmith/images/model-config-light.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=280&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=4e3b9ad92f6f14f4e0523bef50199318 280w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=560&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=e538eb740495a8afa8bfc552b13ae294 560w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=840&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=ebe73264e977153c869fd04d1552d09b 840w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=1100&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=2eeb01882056046bc73cc019d674af7e 1100w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=1650&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=8f28fe2fe8054cf0623fb9d17f91966f 1650w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=2500&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=cf9ad39be3623e73322d123699e73f19 2500w\" />\n\n     <img className=\"hidden dark:block\" src=\"https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=2e9da272c3fc8f7ac958c6e6d1da85e3\" alt=\"Model Configuration window in the LangSmith UI, settings for Provider, Model, Temperature, Max Output Tokens, Top P, Presence Penalty, Frequency Penalty, Reasoning Effort, etc.\" data-og-width=\"881\" width=\"881\" data-og-height=\"732\" height=\"732\" data-path=\"langsmith/images/model-config-dark.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=280&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=652fb75a4682cfc813743a1260764e59 280w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=560&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=02c980a8387f3d69a5870660b1668080 560w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=840&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=ee633c06056fa7ad46ea58a179afa169 840w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=1100&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=f62a35ed726b5f89c156a40c9ea76f2c 1100w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=1650&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=18114575db8e6c7ce928763ddcb88c12 1650w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=2500&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=ab24dc4975def52db55c4896ead5b77c 2500w\" />\n   </div>\n\n## Model configurations\n\nModel configurations define the parameters your prompt runs against. In the LangSmith Playground, you can save and manage these configurations, which allows you to reuse your preferred settings across prompts and sessions. For details on specific settings, refer to your model provider\u2019s documentation (for example, [Anthropic](https://platform.claude.com/docs/en/api/messages), [OpenAI](https://platform.openai.com/docs/api-reference/responses/create)).\n\n### Create saved configurations\n\n1. In the **Model Configurations** tab, adjust the model configuration as needed\u2014you can select a [saved configuration to edit](#edit-configurations).\n2. Click the **Save As** button in the top bar.\n3. Enter a name and optional description for your configuration and confirm.\n4. Now that you've saved the configuration, anyone in your organization's [workspace](/langsmith/administration-overview#workspaces) can access it. All saved configurations are available in the **Model Configuration** dropdown.\n5. Once you have created a saved configuration, you can set it as your default, so any new prompt you create will automatically use this configuration. To set a configuration as your default, click the **Set as default** <Icon icon=\"thumbtack\" iconType=\"solid\" /> icon next to the model name in the dropdown.\n\n### Edit configurations\n\n1. To rename a saved configuration, or update the description, select the configuration name or description and make the necessary changes.\n2. Update the current configuration's parameters as needed and click the **Save** button at the top.\n\n### Delete configurations\n\n1. Select the configuration you want to remove.\n2. Click the trash <Icon icon=\"trash\" iconType=\"solid\" /> icon to delete it.\n\n### Extra parameters\n\nThe **Extra Parameters** field allows you to pass additional model parameters that aren't directly supported in the LangSmith interface. This is particularly useful in two scenarios:\n\n1. When model providers release new parameters that haven't yet been integrated into the LangSmith interface. You can specify these parameters in JSON format to use them right away. For example:\n\n   ```json  theme={null}\n   {\n       \"reasoning_effort\": \"medium\"\n   }\n   ```\n\n2. When troubleshooting parameter-related errors in the playground, such as:\n\n   ```\n   TypeError: AsyncCompletions.create() got an unexpected keyword argument 'max_concurrency'\n   ```\n\n   If you receive an error about unnecessary parameters (which is more common when using [LangChain JS](/oss/python/langchain/overview) for run tracing), you can use this field to remove the extra parameters.\n\n## Tool settings\n\n[*Tools*](/langsmith/prompt-engineering-concepts#tools) enable your LLM to perform tasks like searching the web, looking up information, and so on. In the **Tools Settings** tab, you can manage the ways your LLM uses and accesses the tools you have defined in your prompt, including:\n\n* **Parallel Tool Calls**: Calling multiple tools in parallel when appropriate. This allows the model to gather information from different sources simultaneously. (Dependent on model support for parallel execution.)\n* **Tool Choice**: Select the tools that the model can access. For more details, refer to [Use tools in a prompt](/langsmith/use-tools).\n\n## Prompt formatting\n\nThe **Prompt Format** tab allows you to specify:\n\n* The **Prompt type**. For details on chat and completion prompts, refer to [Prompt engineering](/langsmith/prompt-engineering-concepts#chat-vs-completion) concepts.\n* The **Template format**. For details on prompt templating and using variables, refer to [F-string vs. mustache](/langsmith/prompt-engineering-concepts##f-string-vs-mustache).\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/managing-model-configurations.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 2:\nTitle: Tools and Toolkits\nLink: https://docs.langchain.comoss/javascript/integrations/tools/index\nContent: [Tools](/oss/javascript/langchain/tools) are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models.\n\nA [toolkit](/oss/javascript/langchain/tools#toolkits) is a collection of tools meant to be used together.\n\n## Integration Platforms\n\nThe following platforms provide access to multiple tools and services through a unified interface:\n\n| Tool/Toolkit                                            | Number of Integrations | Pricing             | Key Features                                               |\n| ------------------------------------------------------- | ---------------------- | ------------------- | ---------------------------------------------------------- |\n| [Composio](/oss/javascript/integrations/tools/composio) | 500+                   | Free tier available | OAuth handling, event-driven workflows, multi-user support |\n\n## All Tools and Toolkits\n\n<Columns cols={3}>\n  <Card title=\"Azure Container Apps Dynamic Sessions\" icon=\"link\" href=\"/oss/javascript/integrations/tools/azure_dynamic_sessions\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Connery Action Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/connery\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Composio\" icon=\"link\" href=\"/oss/javascript/integrations/tools/composio\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Dall-E Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/dalle\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Decodo Tools\" icon=\"link\" href=\"/oss/javascript/integrations/tools/decodo\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Discord Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/discord_tool\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"DuckDuckGoSearch\" icon=\"link\" href=\"/oss/javascript/integrations/tools/duckduckgo_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"ExaSearchResults\" icon=\"link\" href=\"/oss/javascript/integrations/tools/exa_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"FalkorDB\" icon=\"link\" href=\"/oss/javascript/integrations/tools/falkordb\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Gmail Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_gmail\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"GOAT\" icon=\"link\" href=\"/oss/javascript/integrations/tools/goat\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Calendar Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_calendar\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Places Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_places\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Routes Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_routes\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Scholar\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_scholar\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Trends Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_trends\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"JigsawStack Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/jigsawstack\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Agent with AWS Lambda\" icon=\"link\" href=\"/oss/javascript/integrations/tools/lambda_agent\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Python interpreter tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/pyinterpreter\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"SearchApi tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/searchapi\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Searxng Search tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/searxng\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"SerpAPI\" icon=\"link\" href=\"/oss/javascript/integrations/tools/serpapi\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"StackExchange Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/stackexchange\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Stagehand AI Web Automation Toolkit\" icon=\"link\" href=\"/oss/javascript/integrations/tools/stagehand\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Crawl\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_crawl\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Extract\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_extract\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Map\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_map\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Search\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Web Browser Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/webbrowser\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Wikipedia tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/wikipedia\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"WolframAlpha Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/wolframalpha\" arrow=\"true\" cta=\"View guide\" />\n</Columns>\n\n<Info>\n  If you'd like to write your own tool, see [this how-to](/oss/javascript/langchain/tools#customize-tool-properties). If you'd like to contribute an integration, see [Contributing integrations](/oss/javascript/contributing#add-a-new-integration).\n</Info>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/tools/index.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 3:\nTitle: Tools\nLink: https://docs.langchain.comoss/javascript/langchain/tools\nContent: Many AI applications interact with users via natural language. However, some use cases require models to interface directly with external systems\u2014such as APIs, databases, or file systems\u2014using structured input.\n\nTools are components that [agents](/oss/javascript/langchain/agents) call to perform actions. They extend model capabilities by letting them interact with the world through well-defined inputs and outputs.\n\nTools encapsulate a callable function and its input schema. These can be passed to compatible [chat models](/oss/javascript/langchain/models), allowing the model to decide whether to invoke a tool and with what arguments. In these scenarios, tool calling enables models to generate requests that conform to a specified input schema.\n\n<Note>\n  **Server-side tool use**\n\n  Some chat models (e.g., [OpenAI](/oss/javascript/integrations/chat/openai), [Anthropic](/oss/javascript/integrations/chat/anthropic), and [Gemini](/oss/javascript/integrations/chat/google_generative_ai)) feature [built-in tools](/oss/javascript/langchain/models#server-side-tool-use) that are executed server-side, such as web search and code interpreters. Refer to the [provider overview](/oss/javascript/integrations/providers/overview) to learn how to access these tools with your specific chat model.\n</Note>\n\n## Create tools\n\n### Basic tool definition\n\nThe simplest way to create a tool is by importing the `tool` function from the `langchain` package. You can use [zod](https://zod.dev/) to define the tool's input schema:\n\n```ts  theme={null}\nimport * as z from \"zod\"\nimport { tool } from \"langchain\"\n\nconst searchDatabase = tool(\n  ({ query, limit }) => `Found ${limit} results for '${query}'`,\n  {\n    name: \"search_database\",\n    description: \"Search the customer database for records matching the query.\",\n    schema: z.object({\n      query: z.string().describe(\"Search terms to look for\"),\n      limit: z.number().describe(\"Maximum number of results to return\"),\n    }),\n  }\n);\n```\n\n## Accessing Context\n\n<Info>\n  **Why this matters:** Tools are most powerful when they can access agent state, runtime context, and long-term memory. This enables tools to make context-aware decisions, personalize responses, and maintain information across conversations.\n\n  The runtime context provides a structured way to supply runtime data, such as DB connections, user IDs, or config, into your tools. This avoids global state and keeps tools testable and reusable.\n</Info>\n\n#### Context\n\nTools can access an agent's runtime context through the `config` parameter:\n\n```ts  theme={null}\nimport * as z from \"zod\"\nimport { ChatOpenAI } from \"@langchain/openai\"\nimport { createAgent } from \"langchain\"\n\nconst getUserName = tool(\n  (_, config) => {\n    return config.context.user_name\n  },\n  {\n    name: \"get_user_name\",\n    description: \"Get the user's name.\",\n    schema: z.object({}),\n  }\n);\n\nconst contextSchema = z.object({\n  user_name: z.string(),\n});\n\nconst agent = createAgent({\n  model: new ChatOpenAI({ model: \"gpt-4o\" }),\n  tools: [getUserName],\n  contextSchema,\n});\n\nconst result = await agent.invoke(\n  {\n    messages: [{ role: \"user\", content: \"What is my name?\" }]\n  },\n  {\n    context: { user_name: \"John Smith\" }\n  }\n);\n```\n\n#### Memory (Store)\n\nAccess persistent data across conversations using the store. The store is accessed via `config.store` and allows you to save and retrieve user-specific or application-specific data.\n\n```ts expandable theme={null}\nimport * as z from \"zod\";\nimport { createAgent, tool } from \"langchain\";\nimport { InMemoryStore } from \"@langchain/langgraph\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst store = new InMemoryStore();\n\n// Access memory\nconst getUserInfo = tool(\n  async ({ user_id }) => {\n    const value = await store.get([\"users\"], user_id);\n    console.log(\"get_user_info\", user_id, value);\n    return value;\n  },\n  {\n    name: \"get_user_info\",\n    description: \"Look up user info.\",\n    schema: z.object({\n      user_id: z.string(),\n    }),\n  }\n);\n\n// Update memory\nconst saveUserInfo = tool(\n  async ({ user_id, name, age, email }) => {\n    console.log(\"save_user_info\", user_id, name, age, email);\n    await store.put([\"users\"], user_id, { name, age, email });\n    return \"Successfully saved user info.\";\n  },\n  {\n    name: \"save_user_info\",\n    description: \"Save user info.\",\n    schema: z.object({\n      user_id: z.string(),\n      name: z.string(),\n      age: z.number(),\n      email: z.string(),\n    }),\n  }\n);\n\nconst agent = createAgent({\n  model: new ChatOpenAI({ model: \"gpt-4o\" }),\n  tools: [getUserInfo, saveUserInfo],\n  store,\n});\n\n// First session: save user info\nawait agent.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\",\n    },\n  ],\n});\n\n// Second session: get user info\nconst result = await agent.invoke({\n  messages: [\n    { role: \"user\", content: \"Get user info for user with id 'abc123'\" },\n  ],\n});\n\nconsole.log(result);\n// Here is the user info for user with ID \"abc123\":\n// - Name: Foo\n// - Age: 25\n// - Email: foo@langchain.dev\n```\n\n#### Stream Writer\n\nStream custom updates from tools as they execute using `config.streamWriter`. This is useful for providing real-time feedback to users about what a tool is doing.\n\n```ts  theme={null}\nimport * as z from \"zod\";\nimport { tool } from \"langchain\";\n\nconst getWeather = tool(\n  ({ city }, config) => {\n    const writer = config.streamWriter;\n\n    // Stream custom updates as the tool executes\n    writer(`Looking up data for city: ${city}`);\n    writer(`Acquired data for city: ${city}`);\n\n    return `It's always sunny in ${city}!`;\n  },\n  {\n    name: \"get_weather\",\n    description: \"Get weather for a given city.\",\n    schema: z.object({\n      city: z.string(),\n    }),\n  }\n);\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/tools.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 4:\nTitle: Google\nLink: https://docs.langchain.comoss/python/integrations/providers/google\nContent: Tools\nGoogle Search Perform web searches using Google Custom Search Engine (CSE). Google Drive Tools for interacting with Google Drive. Google Finance Query financial data. Google Jobs Query job listings. Google Lens Perform visual searches. Google Places Search for places information. Google Scholar Search academic papers. Google Trends Query Google Trends data.\n\nToolkits\nCollections of tools for specific Google services. Gmail Toolkit to create, get, search, and send emails using the Gmail API.\n\nYouTube\nSearch tool Search YouTube videos without the official API. Audio loader Download audio from YouTube videos. Transcripts loader Load video transcripts. Edit the source of this page on GitHub. Connect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.\n\n---\n\nResult 5:\nTitle: Tools\nLink: https://docs.langchain.comoss/python/langchain/tools\nContent: Many AI applications interact with users via natural language. However, some use cases require models to interface directly with external systems\u2014such as APIs, databases, or file systems\u2014using structured input.\n\nTools are components that [agents](/oss/python/langchain/agents) call to perform actions. They extend model capabilities by letting them interact with the world through well-defined inputs and outputs.\n\nTools encapsulate a callable function and its input schema. These can be passed to compatible [chat models](/oss/python/langchain/models), allowing the model to decide whether to invoke a tool and with what arguments. In these scenarios, tool calling enables models to generate requests that conform to a specified input schema.\n\n<Note>\n  **Server-side tool use**\n\n  Some chat models (e.g., [OpenAI](/oss/python/integrations/chat/openai), [Anthropic](/oss/python/integrations/chat/anthropic), and [Gemini](/oss/python/integrations/chat/google_generative_ai)) feature [built-in tools](/oss/python/langchain/models#server-side-tool-use) that are executed server-side, such as web search and code interpreters. Refer to the [provider overview](/oss/python/integrations/providers/overview) to learn how to access these tools with your specific chat model.\n</Note>\n\n## Create tools\n\n### Basic tool definition\n\nThe simplest way to create a tool is with the [`@tool`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.tool) decorator. By default, the function's docstring becomes the tool's description that helps the model understand when to use it:\n\n```python  theme={null}\nfrom langchain.tools import tool\n\n@tool\ndef search_database(query: str, limit: int = 10) -> str:\n    \"\"\"Search the customer database for records matching the query.\n\n    Args:\n        query: Search terms to look for\n        limit: Maximum number of results to return\n    \"\"\"\n    return f\"Found {limit} results for '{query}'\"\n```\n\nType hints are **required** as they define the tool's input schema. The docstring should be informative and concise to help the model understand the tool's purpose.\n\n### Customize tool properties\n\n#### Custom tool name\n\nBy default, the tool name comes from the function name. Override it when you need something more descriptive:\n\n```python  theme={null}\n@tool(\"web_search\")  # Custom name\ndef search(query: str) -> str:\n    \"\"\"Search the web for information.\"\"\"\n    return f\"Results for: {query}\"\n\nprint(search.name)  # web_search\n```\n\n#### Custom tool description\n\nOverride the auto-generated tool description for clearer model guidance:\n\n```python  theme={null}\n@tool(\"calculator\", description=\"Performs arithmetic calculations. Use this for any math problems.\")\ndef calc(expression: str) -> str:\n    \"\"\"Evaluate mathematical expressions.\"\"\"\n    return str(eval(expression))\n```\n\n### Advanced schema definition\n\nDefine complex inputs with Pydantic models or JSON schemas:\n\n<CodeGroup>\n  ```python Pydantic model theme={null}\n  from pydantic import BaseModel, Field\n  from typing import Literal\n\n  class WeatherInput(BaseModel):\n      \"\"\"Input for weather queries.\"\"\"\n      location: str = Field(description=\"City name or coordinates\")\n      units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n          default=\"celsius\",\n          description=\"Temperature unit preference\"\n      )\n      include_forecast: bool = Field(\n          default=False,\n          description=\"Include 5-day forecast\"\n      )\n\n  @tool(args_schema=WeatherInput)\n  def get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n      \"\"\"Get current weather and optional forecast.\"\"\"\n      temp = 22 if units == \"celsius\" else 72\n      result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n      if include_forecast:\n          result += \"\\nNext 5 days: Sunny\"\n      return result\n  ```\n\n  ```python JSON Schema theme={null}\n  weather_schema = {\n      \"type\": \"object\",\n      \"properties\": {\n          \"location\": {\"type\": \"string\"},\n          \"units\": {\"type\": \"string\"},\n          \"include_forecast\": {\"type\": \"boolean\"}\n      },\n      \"required\": [\"location\", \"units\", \"include_forecast\"]\n  }\n\n  @tool(args_schema=weather_schema)\n  def get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n      \"\"\"Get current weather and optional forecast.\"\"\"\n      temp = 22 if units == \"celsius\" else 72\n      result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n      if include_forecast:\n          result += \"\\nNext 5 days: Sunny\"\n      return result\n  ```\n</CodeGroup>\n\n### Reserved argument names\n\nThe following parameter names are reserved and cannot be used as tool arguments. Using these names will cause runtime errors.\n\n| Parameter name | Purpose                                                                |\n| -------------- | ---------------------------------------------------------------------- |\n| `config`       | Reserved for passing `RunnableConfig` to tools internally              |\n| `runtime`      | Reserved for `ToolRuntime` parameter (accessing state, context, store) |\n\nTo access runtime information, use the [`ToolRuntime`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.ToolRuntime) parameter instead of naming your own arguments `config` or `runtime`.\n\n## Accessing Context\n\n<Info>\n  **Why this matters:** Tools are most powerful when they can access agent state, runtime context, and long-term memory. This enables tools to make context-aware decisions, personalize responses, and maintain information across conversations.\n\n  Runtime context provides a way to inject dependencies (like database connections, user IDs, or configuration) into your tools at runtime, making them more testable and reusable.\n</Info>\n\nTools can access runtime information through the `ToolRuntime` parameter, which provides:\n\n* **State** - Mutable data that flows through execution (e.g., messages, counters, custom fields)\n* **Context** - Immutable configuration like user IDs, session details, or application-specific configuration\n* **Store** - Persistent long-term memory across conversations\n* **Stream Writer** - Stream custom updates as tools execute\n* **Config** - `RunnableConfig` for the execution\n* **Tool Call ID** - ID of the current tool call\n\n```mermaid  theme={null}\ngraph LR\n    %% Runtime Context\n    subgraph \"\ud83d\udd27 Tool Runtime Context\"\n        A[Tool Call] --> B[ToolRuntime]\n        B --> C[State Access]\n        B --> D[Context Access]\n        B --> E[Store Access]\n        B --> F[Stream Writer]\n    end\n\n    %% Available Resources\n    subgraph \"\ud83d\udcca Available Resources\"\n        C --> G[Messages]\n        C --> H[Custom State]\n        D --> I[User ID]\n        D --> J[Session Info]\n        E --> K[Long-term Memory]\n        E --> L[User Preferences]\n    end\n\n    %% Tool Capabilities\n    subgraph \"\u26a1 Enhanced Tool Capabilities\"\n        M[Context-Aware Tools]\n        N[Stateful Tools]\n        O[Memory-Enabled Tools]\n        P[Streaming Tools]\n    end\n\n    %% Connections\n    G --> M\n    H --> N\n    I --> M\n    J --> M\n    K --> O\n    L --> O\n    F --> P\n```\n\n### `ToolRuntime`\n\nUse `ToolRuntime` to access all runtime information in a single parameter. Simply add `runtime: ToolRuntime` to your tool signature, and it will be automatically injected without being exposed to the LLM.\n\n<Info>\n  **`ToolRuntime`**: A unified parameter that provides tools access to state, context, store, streaming, config, and tool call ID. This replaces the older pattern of using separate [`InjectedState`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedState), [`InjectedStore`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedStore), [`get_runtime`](https://reference.langchain.com/python/langgraph/runtime/#langgraph.runtime.get_runtime), and [`InjectedToolCallId`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.InjectedToolCallId) annotations.\n\n  The runtime automatically provides these capabilities to your tool functions without you having to pass them explicitly or use global state.\n</Info>\n\n**Accessing state:**\n\nTools can access the current graph state using `ToolRuntime`:\n\n```python  theme={null}\nfrom langchain.tools import tool, ToolRuntime\n\n# Access the current conversation state\n@tool\ndef summarize_conversation(\n    runtime: ToolRuntime\n) -> str:\n    \"\"\"Summarize the conversation so far.\"\"\"\n    messages = runtime.state[\"messages\"]\n\n    human_msgs = sum(1 for m in messages if m.__class__.__name__ == \"HumanMessage\")\n    ai_msgs = sum(1 for m in messages if m.__class__.__name__ == \"AIMessage\")\n    tool_msgs = sum(1 for m in messages if m.__class__.__name__ == \"ToolMessage\")\n\n    return f\"Conversation has {human_msgs} user messages, {ai_msgs} AI responses, and {tool_msgs} tool results\"\n\n# Access custom state fields\n@tool\ndef get_user_preference(\n    pref_name: str,\n    runtime: ToolRuntime  # ToolRuntime parameter is not visible to the model\n) -> str:\n    \"\"\"Get a user preference value.\"\"\"\n    preferences = runtime.state.get(\"user_preferences\", {})\n    return preferences.get(pref_name, \"Not set\")\n```\n\n<Warning>\n  The `runtime` parameter is hidden from the model. For the example above, the model only sees `pref_name` in the tool schema - `runtime` is *not* included in the request.\n</Warning>\n\n**Updating state:**\n\nUse [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) to update the agent's state or control the graph's execution flow:\n\n```python  theme={null}\nfrom langgraph.types import Command\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langchain.tools import tool, ToolRuntime\n\n# Update the conversation history by removing all messages\n@tool\ndef clear_conversation() -> Command:\n    \"\"\"Clear the conversation history.\"\"\"\n\n    return Command(\n        update={\n            \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)],\n        }\n    )\n\n# Update the user_name in the agent state\n@tool\ndef update_user_name(\n    new_name: str,\n    runtime: ToolRuntime\n) -> Command:\n    \"\"\"Update the user's name.\"\"\"\n    return Command(update={\"user_name\": new_name})\n```\n\n#### Context\n\nAccess immutable configuration and contextual data like user IDs, session details, or application-specific configuration through `runtime.context`.\n\nTools can access runtime context through `ToolRuntime`:\n\n```python  theme={null}\nfrom dataclasses import dataclass\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n\nUSER_DATABASE = {\n    \"user123\": {\n        \"name\": \"Alice Johnson\",\n        \"account_type\": \"Premium\",\n        \"balance\": 5000,\n        \"email\": \"alice@example.com\"\n    },\n    \"user456\": {\n        \"name\": \"Bob Smith\",\n        \"account_type\": \"Standard\",\n        \"balance\": 1200,\n        \"email\": \"bob@example.com\"\n    }\n}\n\n@dataclass\nclass UserContext:\n    user_id: str\n\n@tool\ndef get_account_info(runtime: ToolRuntime[UserContext]) -> str:\n    \"\"\"Get the current user's account information.\"\"\"\n    user_id = runtime.context.user_id\n\n    if user_id in USER_DATABASE:\n        user = USER_DATABASE[user_id]\n        return f\"Account holder: {user['name']}\\nType: {user['account_type']}\\nBalance: ${user['balance']}\"\n    return \"User not found\"\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\nagent = create_agent(\n    model,\n    tools=[get_account_info],\n    context_schema=UserContext,\n    system_prompt=\"You are a financial assistant.\"\n)\n\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my current balance?\"}]},\n    context=UserContext(user_id=\"user123\")\n)\n```\n\n#### Memory (Store)\n\nAccess persistent data across conversations using the store. The store is accessed via `runtime.store` and allows you to save and retrieve user-specific or application-specific data.\n\nTools can access and update the store through `ToolRuntime`:\n\n```python expandable theme={null}\nfrom typing import Any\nfrom langgraph.store.memory import InMemoryStore\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n\n# Access memory\n@tool\ndef get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n    \"\"\"Look up user info.\"\"\"\n    store = runtime.store\n    user_info = store.get((\"users\",), user_id)\n    return str(user_info.value) if user_info else \"Unknown user\"\n\n# Update memory\n@tool\ndef save_user_info(user_id: str, user_info: dict[str, Any], runtime: ToolRuntime) -> str:\n    \"\"\"Save user info.\"\"\"\n    store = runtime.store\n    store.put((\"users\",), user_id, user_info)\n    return \"Successfully saved user info.\"\n\nstore = InMemoryStore()\nagent = create_agent(\n    model,\n    tools=[get_user_info, save_user_info],\n    store=store\n)\n\n# First session: save user info\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\"}]\n})\n\n# Second session: get user info\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Get user info for user with id 'abc123'\"}]\n})\n# Here is the user info for user with ID \"abc123\":\n# - Name: Foo\n# - Age: 25\n# - Email: foo@langchain.dev\n```\n\n#### Stream Writer\n\nStream custom updates from tools as they execute using `runtime.stream_writer`. This is useful for providing real-time feedback to users about what a tool is doing.\n\n```python  theme={null}\nfrom langchain.tools import tool, ToolRuntime\n\n@tool\ndef get_weather(city: str, runtime: ToolRuntime) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    writer = runtime.stream_writer\n\n    # Stream custom updates as the tool executes\n    writer(f\"Looking up data for city: {city}\")\n    writer(f\"Acquired data for city: {city}\")\n\n    return f\"It's always sunny in {city}!\"\n```\n\n<Note>\n  If you use `runtime.stream_writer` inside your tool, the tool must be invoked within a LangGraph execution context. See [Streaming](/oss/python/langchain/streaming) for more details.\n</Note>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/tools.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n"
  },
  {
    "role": "tool",
    "name": "search_support_articles",
    "tool_call_id": "call_FLbA3fadTLm4243aCxnF9duL",
    "id": "0f6d5678-d529-4c03-8841-bb02ff6f382f",
    "content": "{\n  \"collections\": \"OSS (LangChain and LangGraph),LangSmith Studio,SDKs and APIs\",\n  \"total\": 17,\n  \"articles\": [\n    {\n      \"id\": \"bb651320-775e-4dfa-a054-c955cc3a0d5d\",\n      \"title\": \"Why Do Pydantic\\u00a0date\\u00a0Fields Fail in LangGraph State?\",\n      \"url\": \"https://support.langchain.com/articles/7196116702-why-do-pydantic-date-fields-fail-in-langgraph-state\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"ae959c68-a996-4426-8c8e-ef3fa1dd88cc\",\n      \"title\": \"How do I connect JIRA, Slack, and Confluence MCPs with LangChain?\",\n      \"url\": \"https://support.langchain.com/articles/3473375007-how-do-i-connect-jira-slack-and-confluence-mcps-with-langchain\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"2836b779-a2f5-4058-a994-4fe2502166ca\",\n      \"title\": \"Missing Runs in LangSmith Experiment View with Concurrent Evaluations\",\n      \"url\": \"https://support.langchain.com/articles/8223468578-missing-runs-in-langsmith-experiment-view-with-concurrent-evaluations\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"d55d04fa-c883-4055-b266-343e5157ad31\",\n      \"title\": \"Preserving Trace Hierarchy with Manual RunTree Creation\",\n      \"url\": \"https://support.langchain.com/articles/9515178454-preserving-trace-hierarchy-with-manual-runtree-creation\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"9e06b53a-7b85-4793-b7b6-e179c0c8d815\",\n      \"title\": \"Isolating Subgraph State When Calling Graphs from Tools\",\n      \"url\": \"https://support.langchain.com/articles/6131002418-isolating-subgraph-state-when-calling-graphs-from-tools\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"9ef77ded-7211-4d09-944a-289972726262\",\n      \"title\": \"Why am I getting \\\"Failed to send compressed multipart ingest\\\" errors in LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9901468881-why-am-i-getting-failed-to-send-compressed-multipart-ingest-errors-in-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"e72b134e-bd5a-471d-93ea-8def86caf74a\",\n      \"title\": \"Why do I see inconsistent output formats for the same agent across different traces?\",\n      \"url\": \"https://support.langchain.com/articles/2041161407-why-do-i-see-inconsistent-output-formats-for-the-same-agent-across-different-traces\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"3ea46ebf-6af5-4ce2-b678-1c7d4b82caba\",\n      \"title\": \"Can I reopen a run after calling patch() to write additional data?\",\n      \"url\": \"https://support.langchain.com/articles/9964614152-can-i-reopen-a-run-after-calling-patch-to-write-additional-data\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"32994e7d-a182-41df-9f3d-271adf84fde2\",\n      \"title\": \"How do I filter runs by multiple run IDs using tree filters?\",\n      \"url\": \"https://support.langchain.com/articles/2574288399-how-do-i-filter-runs-by-multiple-run-ids-using-tree-filters\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f5a80963-8fe3-415f-b0e2-04b6f5093f12\",\n      \"title\": \"How do I filter runs by name using the LangSmith SDK?\",\n      \"url\": \"https://support.langchain.com/articles/5601207552-how-do-i-filter-runs-by-name-using-the-langsmith-sdk\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f51b0bb0-b838-40db-baa9-f9099ae34c2f\",\n      \"title\": \"How do I use LangSmith tracing with Cloudflare Workers?\",\n      \"url\": \"https://support.langchain.com/articles/1885761495-how-do-i-use-langsmith-tracing-with-cloudflare-workers\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"d270716f-edc0-49d9-b5d1-497b5d0e4e6d\",\n      \"title\": \"Private Network Access Blocking LangSmith Studio Connection\",\n      \"url\": \"https://support.langchain.com/articles/1897181200-private-network-access-blocking-langsmith-studio-connection\",\n      \"collection\": \"LangSmith Studio\"\n    },\n    {\n      \"id\": \"e2c86d05-b6fd-4bb3-8637-3f6d35c106dd\",\n      \"title\": \"How do I trace Vercel AI SDK calls with LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9620089182-how-do-i-trace-vercel-ai-sdk-calls-with-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"5f2572a3-9086-4d92-8d15-69f7b8e4c8be\",\n      \"title\": \"MCP Server Runtime in Google Colab / Jupyter Notebook\",\n      \"url\": \"https://support.langchain.com/articles/1061688976-mcp-server-runtime-in-google-colab-jupyter-notebook\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"68fbf7da-954d-454e-8ad4-73e1f1f63b74\",\n      \"title\": \"LangSmith Studio vs Agent Chat UI: When to Use What\",\n      \"url\": \"https://support.langchain.com/articles/1353449293-langsmith-studio-vs-agent-chat-ui\",\n      \"collection\": \"LangSmith Studio\"\n    },\n    {\n      \"id\": \"ada8fd1b-4800-434e-8d6f-b5186b170941\",\n      \"title\": \"LangSmith Studio URL Redirects to Error Page\",\n      \"url\": \"https://support.langchain.com/articles/4270790436-langsmith-studio-url-redirects-to-error-page\",\n      \"collection\": \"LangSmith Studio\"\n    },\n    {\n      \"id\": \"45269e32-5322-4a17-8866-da640169d21d\",\n      \"title\": \"How do I export annotated traces in bulk from LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9958349143-how-do-i-export-annotated-traces-in-bulk-from-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    }\n  ],\n  \"note\": \"All articles listed are public and have content. Use IDs to fetch full content.\"\n}"
  },
  {
    "role": "assistant",
    "id": "lc_run--019b384d-5fe0-73f2-9ed5-249c1e3d6a02",
    "content": "**A tool in LangChain/LangGraph is a callable component (a function) that an agent or model can invoke to perform external actions\u2014like calling APIs, querying a database, running code, or reading/writing files.**\n\nTools let the model extend its capabilities by exposing a defined input schema and returning structured outputs; in Python you typically create them with `@tool`, in JavaScript/TypeScript with `tool()`/toolkits, and tools can access runtime/context via `ToolRuntime` so they remain testable and stateful.\n\n```python\nfrom langchain.tools import tool\n\n@tool\ndef search_database(query: str, limit: int = 10) -> str:\n    \"\"\"Search the customer database for records matching the query.\"\"\"\n    # Implementation: run DB query, format results\n    return f\"Found {limit} results for '{query}'\"  # returned value goes back to the agent\n```\n\n## Examples and runtime access\n\nTools can include richer schemas (Pydantic/JSON in Python, zod in JS) and can access runtime/context, store, and streaming via `ToolRuntime` (hidden from the model). This is how a tool can read user-specific context or update persistent memory:\n\n```python\nfrom langchain.tools import tool, ToolRuntime\n\n@tool\ndef get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n    \"\"\"Look up user info from the runtime store.\"\"\"\n    user_info = runtime.store.get((\"users\",), user_id)\n    return str(user_info.value) if user_info else \"Unknown user\"\n```\n\n- Tools are chosen by the model (tool calling) when the model decides a specific external action is needed.\n- Toolkits are collections of related tools (useful for grouping integrations).\n- Some providers offer server-side built-in tools (e.g., web search, code interpreters) that the model can call directly.\n\nRelevant docs:\n\n- [Tools (Python)](https://docs.langchain.com/oss/python/langchain/tools)  \n- [Tools (JavaScript)](https://docs.langchain.com/oss/javascript/langchain/tools)  \n- [Tools and Toolkits (Integrations)](https://docs.langchain.com/oss/javascript/integrations/tools/index)"
  },
  {
    "role": "user",
    "id": "47fc5605-a3f6-47d5-8629-b2494be405eb",
    "content": "What is gmailtool used for"
  },
  {
    "role": "assistant",
    "tool_calls": [
      {
        "type": "function",
        "id": "call_3VdYYN8YjXDFAuXq35kJqwPi",
        "function": {
          "name": "SearchDocsByLangChain",
          "arguments": "{\"language\": \"python\", \"page_size\": 5, \"query\": \"gmail\"}"
        }
      },
      {
        "type": "function",
        "id": "call_3HVwEGo72osb0EbBfsC3vABN",
        "function": {
          "name": "search_support_articles",
          "arguments": "{\"collections\": \"OSS (LangChain and LangGraph),SDKs and APIs\"}"
        }
      }
    ],
    "id": "lc_run--019b384e-9594-70b3-ba15-40d60002a121",
    "content": ""
  },
  {
    "role": "tool",
    "name": "SearchDocsByLangChain",
    "tool_call_id": "call_3VdYYN8YjXDFAuXq35kJqwPi",
    "id": "09ec8630-e776-4350-b097-66a3d5a4834f",
    "content": "Result 1:\nTitle: Essentials\nLink: https://docs.langchain.comlangsmith/agent-builder-essentials\nContent: ## Tools\n\nTools let your agents interact with your apps and services. Your agents can send emails, create calendar events, post messages, search the web, and more. Choose from built-in tools for Gmail, Slack, Google Calendar, GitHub, and many others.\n\nSee [Supported tools](/langsmith/agent-builder-tools) for a complete list.\n\n## Triggers\n\nTriggers define when your agent should start running. You can connect your agent to external tools or time-based schedules, letting it respond automatically to messages, emails, or recurring events.\n\nHere are some popular ways to trigger your agent:\n\n<CardGroup cols={3}>\n  <Card title=\"Slack\" icon=\"slack\">\n    Activate your agent when messages are received in specific Slack channels.\n  </Card>\n\n  <Card title=\"Gmail\" icon=\"envelope\">\n    Trigger your agent when emails are received.\n  </Card>\n\n  <Card title=\"Cron schedules\" icon=\"clock\">\n    Run your agent on a time-based schedule for recurring tasks.\n  </Card>\n</CardGroup>\n\n## Memory and updates\n\nYour agents get smarter over time. They remember important information from previous conversations and can update themselves to work better.\n\n* Memory: Agents remember relevant details from past interactions, so they can make better decisions in future conversations.\n* Self-updates: Agents can add new tools, remove ones they don't need, or adjust their instructions to improve how they work.\n* What stays the same: Agents can't change their name, description, or the triggers that start them.\n\n## Custom models\n\nAgent Builder supports custom models. You can override the default Anthropic or OpenAI model for a specific agent by editing the agent's settings:\n\n1. In the [LangSmith UI](https://smith.langchain.com), navigate to the agent you want to edit.\n2. Click on the <Icon icon=\"gear\" /> settings icon in the top right corner.\n3. In the **Model** section, select **+ Add custom model**.\n4. Enter the model ID, display name, base URL, and API key name and value.\n5. Click **Save**.\n\n<Note>\n  Custom models may not perform as well as built-in models. Test your custom model before using it in production.\n</Note>\n\n## Sub-agents\n\nBuild complex agents by breaking big tasks into smaller, specialized helpers. Think of sub-agents as a team of specialists\u2014each one handles a specific part of the job while working together with your main agent.\n\nThis approach makes it easier to build sophisticated systems. Instead of one agent trying to do everything, you can have specialized helpers that each excel at their part of the task.\n\nHere are some ways you might use sub-agents:\n\n* Split into sub-tasks: Have one agent fetch data, another summarize it, and a third format the results.\n* Specialized tools: Give different agents access to different tools based on what they need to do.\n* Independent work: Let sub-agents work on their own, then bring their results back to the main agent.\n\n## Human in the loop\n\nStay in control of important decisions. You can set up your agent to pause and ask for your approval before taking certain actions. This ensures your agent handles most tasks automatically, while you retain oversight.\n\n### Setting up approval steps\n\n<Steps>\n  <Step title=\"Select a tool\">\n    When setting up your agent, choose the tool or action you want to review before it runs.\n  </Step>\n\n  <Step title=\"Turn on approval\">\n    Find the approval option for that tool and switch it on.\n  </Step>\n\n  <Step title=\"Agent waits for you\">\n    When your agent reaches that step, it will pause and wait for your approval before continuing.\n  </Step>\n</Steps>\n\n### What you can do when your agent pauses\n\nWhen your agent stops to ask for approval, you have three options:\n\n<CardGroup cols={3}>\n  <Card title=\"Accept\" icon=\"check\">\n    Give the green light and let your agent proceed with its plan.\n  </Card>\n\n  <Card title=\"Edit\" icon=\"pen-to-square\">\n    Modify the agent's message or parameters before allowing it to continue.\n  </Card>\n\n  <Card title=\"Send feedback\" icon=\"comment\">\n    Share feedback to help your agent learn and improve.\n  </Card>\n</CardGroup>\n\n## Next steps\n\n* [Set up your workspace](/langsmith/agent-builder-setup)\n* [Connect apps and services](/langsmith/agent-builder-tools)\n* [Use remote connections](/langsmith/agent-builder-mcp-framework)\n* [Choose between workspace and private agents](/langsmith/agent-builder-workspace-vs-private)\n* [Call agents from your app](/langsmith/agent-builder-code)\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/agent-builder-essentials.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 2:\nTitle: LangSmith Tool Server\nLink: https://docs.langchain.comlangsmith/agent-builder-mcp-framework\nContent: The LangSmith Tool Server is a standalone MCP framework for building and deploying tools with built-in authentication and authorization. Use the Tool Server when you want to:\n\n* [Create custom tools](#create-a-custom-toolkit) that integrate with LangSmith's [Agent Auth](/langsmith/agent-auth) for OAuth authentication\n* [Build an MCP gateway](#use-as-an-mcp-gateway) for agents you're building yourself (outside of Agent Builder)\n\n<Note>\n  If you're using [Agent Builder](/langsmith/agent-builder), you don't need to interact with the Tool Server directly. Agent Builder provides [built-in tools](/langsmith/agent-builder-tools) and supports [remote MCP servers](/langsmith/agent-builder-tools#using-remote-mcp-servers) without requiring Tool Server setup.\n\n  However, you can configure the associated tool server instance as an MCP server, which will allow you to use your custom MCP servers in your agent.\n</Note>\n\nDownload the [PyPi package](https://pypi.org/project/langsmith-tool-server/) to get started.\n\n## Create a custom toolkit\n\nInstall the LangSmith Tool Server and LangChain CLI:\n\n```bash  theme={null}\npip install langsmith-tool-server\npip install langchain-cli-v2\n```\n\nCreate a new toolkit:\n\n```bash  theme={null}\nlangchain tools new my-toolkit\ncd my-toolkit\n```\n\nThis creates a toolkit with the following structure:\n\n```\nmy-toolkit/\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 toolkit.toml\n\u2514\u2500\u2500 my_toolkit/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 auth.py\n    \u2514\u2500\u2500 tools/\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 ...\n```\n\nDefine your tools using the `@tool` decorator:\n\n```python  theme={null}\nfrom langsmith_tool_server import tool\n\n@tool\ndef hello(name: str) -> str:\n    \"\"\"Greet someone by name.\"\"\"\n    return f\"Hello, {name}!\"\n\n@tool\ndef add(x: int, y: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    return x + y\n\nTOOLS = [hello, add]\n```\n\nRun the server:\n\n```bash  theme={null}\nlangchain tools serve\n```\n\nYour tool server will start on `http://localhost:8000`.\n\n## Call tools via MCP protocol\n\nBelow is an example that lists available tools and calls the `add` tool:\n\n```python  theme={null}\nimport asyncio\nimport aiohttp\n\nasync def mcp_request(url: str, method: str, params: dict = None):\n    async with aiohttp.ClientSession() as session:\n        payload = {\"jsonrpc\": \"2.0\", \"method\": method, \"params\": params or {}, \"id\": 1}\n        async with session.post(f\"{url}/mcp\", json=payload) as response:\n            return await response.json()\n\nasync def main():\n    url = \"http://localhost:8000\"\n\n    tools = await mcp_request(url, \"tools/list\")\n    print(f\"Tools: {tools}\")\n\n    result = await mcp_request(url, \"tools/call\", {\"name\": \"add\", \"arguments\": {\"a\": 5, \"b\": 3}})\n    print(f\"Result: {result}\")\n\nasyncio.run(main())\n```\n\n## Use as an MCP gateway\n\nThe LangSmith Tool Server can act as an MCP gateway, aggregating tools from multiple MCP servers into a single endpoint. Configure MCP servers in your `toolkit.toml`:\n\n```toml  theme={null}\n[toolkit]\nname = \"my-toolkit\"\ntools = \"./my_toolkit/__init__.py:TOOLS\"\n\n[[mcp_servers]]\nname = \"weather\"\ntransport = \"streamable_http\"\nurl = \"http://localhost:8001/mcp/\"\n\n[[mcp_servers]]\nname = \"math\"\ntransport = \"stdio\"\ncommand = \"python\"\nargs = [\"-m\", \"mcp_server_math\"]\n```\n\nAll tools from connected MCP servers are exposed through your server's `/mcp` endpoint. MCP tools are prefixed with their server name to avoid conflicts (e.g., `weather_get_forecast`, `math_add`).\n\n## Authenticate\n\n### OAuth for third-party APIs\n\nFor tools that need to access third-party APIs (like Google, GitHub, Slack, etc.), you can use OAuth authentication with [Agent Auth](/langsmith/agent-auth).\n\nBefore using OAuth in your tools, you'll need to configure an OAuth provider in your LangSmith workspace settings. See the [Agent Auth documentation](/langsmith/agent-auth) for setup instructions.\n\nOnce configured, specify the `auth_provider` in your tool decorator:\n\n```python  theme={null}\nfrom langsmith_tool_server import tool, Context\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\n\n@tool(\n    auth_provider=\"google\",\n    scopes=[\"https://www.googleapis.com/auth/gmail.readonly\"],\n    integration=\"gmail\"\n)\nasync def read_emails(context: Context, max_results: int = 10) -> str:\n    \"\"\"Read recent emails from Gmail.\"\"\"\n    credentials = Credentials(token=context.token)\n    service = build('gmail', 'v1', credentials=credentials)\n    # ... Gmail API calls\n    return f\"Retrieved {max_results} emails\"\n```\n\nTools with `auth_provider` must:\n\n* Have `context: Context` as the first parameter\n* Specify at least one scope\n* Use `context.token` to make authenticated API calls\n\n### Custom request authentication\n\nCustom authentication allows you to validate requests and integrate with your identity provider. Define an authentication handler in your `auth.py` file:\n\n```python  theme={null}\nfrom langsmith_tool_server import Auth\n\nauth = Auth()\n\n@auth.authenticate\nasync def authenticate(authorization: str = None) -> dict:\n    \"\"\"Validate requests and return user identity.\"\"\"\n    if not authorization or not authorization.startswith(\"Bearer \"):\n        raise auth.exceptions.HTTPException(\n            status_code=401,\n            detail=\"Unauthorized\"\n        )\n\n    token = authorization.replace(\"Bearer \", \"\")\n    # Validate token with your identity provider\n    user = await verify_token_with_idp(token)\n\n    return {\"identity\": user.id}\n```\n\nThe handler runs on every request and must return a dict with `identity` (and optionally `permissions`).\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/agent-builder-mcp-framework.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 3:\nTitle: Workspace vs. private agents\nLink: https://docs.langchain.comlangsmith/agent-builder-workspace-vs-private\nContent: Agent Builder supports two visibility modes:\n\n* Private agents: private to the creator. Useful for personal workflows and experiments.\n* Workspace agents: shared within the workspace. Good for team workflows, or agents you want to share with others.\n\n## Differences\n\n* Ownership and access: private agents are only visible to you; workspace agents are visible to anyone else within the same LangSmith workspace.\n* Tool Authentication:\n  * **OAuth**: Both modes support OAuth and secret-based tools. OAuth credentials are always scoped to a user, so workspace agents can not share OAuth tokens, and new users cloning workspace agents must re-authenticate with the selected tools.\n  * **Secrets**: Since secrets are scoped to a workspace, workspace agents & private agents will both use the same LangSmith secret.\n\n## What's public vs. private\n\n### Threads/chat history\n\nThreads are always user scoped, so even if an agent is workspace scoped, the chat history created within that agent will always be private, and only accessible to the specific user who created them.\n\n### System prompt, tools, sub-agents\n\nThe system prompt, selected tools, and sub-agents will be public on workspace scoped agents. Users will not be able to modify these fields on the original workspace scoped agent, but can make changes once they've cloned the agent.\n\n### Triggers\n\nThe trigger type on workspace scoped agents is public (e.g., Slack message received), but the specific connection with the trigger (e.g. the Slack channel, or Gmail address) is not shared. This way, users know what trigger to use when cloning an agent, but can't gain unauthorized access to any connections the original user has set up.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/agent-builder-workspace-vs-private.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 4:\nTitle: Google\nLink: https://docs.langchain.comoss/python/integrations/providers/google\nContent: Toolkits\nCollections of tools for specific Google services. Gmail Toolkit to create, get, search, and send emails using the Gmail API.\n\nTools\nGoogle Search Perform web searches using Google Custom Search Engine (CSE). Google Drive Tools for interacting with Google Drive. Google Finance Query financial data. Google Jobs Query job listings. Google Lens Perform visual searches. Google Places Search for places information. Google Scholar Search academic papers. Google Trends Query Google Trends data.\n\nSearch\nSearchApi searchapi.io provides API access to Google search results, YouTube, and more. SerpApi SerpApi provides API access to Google search results. Serper.dev serper.dev provides API access to Google search results.\n\n---\n\nResult 5:\nTitle: Tools and toolkits\nLink: https://docs.langchain.comoss/python/integrations/tools/index\nContent: Productivity\nThe following table shows tools that can be used to automate tasks in productivity tools: Tool/Toolkit Pricing GitHub Toolkit Free GitLab Toolkit Free for personal project Gmail Toolkit Free, with limit of 250 quota units per user per second Infobip Tool Free trial, with variable pricing after Jira Toolkit Free, with rate limits Office365 Toolkit Free with Office365, includes rate limits Slack Toolkit Free Twilio Tool Free trial, with pay-as-you-go pricing after\n\nAll tools and toolkits\nADS4GPTs AgentQL AINetwork Toolkit Alpha Vantage Amadeus Toolkit Anchor Browser Apify Actor ArXiv AskNews AWS Lambda Azure AI Services Toolkit Azure Cognitive Services Toolkit Azure Container Apps Dynamic Sessions Shell (bash) Bearly Code Interpreter Bing Search Bodo DataFrames Brave Search BrightData Web Scraper API BrightData SERP BrightData Unlocker Cassandra Database Toolkit CDP ChatGPT Plugins ClickUp Toolkit Cogniswitch Toolkit Compass DeFi Toolkit Composio Connery Toolkit Dall-E Image Generator Dappier Databricks Unity Catalog DataForSEO Dataherald Daytona Data Analysis DuckDuckGo Search Discord E2B Data Analysis Eden AI ElevenLabs Text2Speech Exa Search File System Financial Datasets Toolkit FMP Data GitHub Toolkit GitLab Toolkit Gmail Toolkit GOAT Privy Golden Query Google Books Google Calendar Toolkit Google Cloud Text-to-Speech Google Drive Google Finance Google Imagen Google Jobs Google Lens Google Places Google Scholar Google Search Google Serper Google Trends Gradio GraphQL HuggingFace Hub Tools Human as a Tool Hyperbrowser Browser Agent Tools Hyperbrowser Web Scraping Tools IBM watsonx.ai IBM watsonx.ai (SQL) IFTTT WebHooks Infobip Ionic Shopping Tool Jenkins Jina Search Jira Toolkit JSON Toolkit Lemon Agent Linkup Search Tool Memgraph Memorize Mojeek Search MultiOn Toolkit NASA Toolkit Naver Search Nuclia Understanding NVIDIA Riva Office365 Toolkit OpenAPI Toolkit Natural Language API Toolkits OpenGradient OpenWeatherMap Oracle AI Vector Search Oxylabs Pandas Dataframe Passio NutritionAI Parallel Extract Parallel Search Permit PlayWright Browser Toolkit Polygon IO Toolkit PowerBI Toolkit Prolog PubMed Python REPL Reddit Search Requests Toolkit Riza Code Interpreter Robocorp Toolkit Salesforce SceneXplain ScrapeGraph Scrapeless Crawl Scrapeless Scraping API Scrapeless Universal Scraping SearchApi SearxNG Search Semantic Scholar API SerpApi Slack Toolkit Spark SQL Toolkit SQLDatabase Toolkit StackExchange Steam Toolkit Stripe Tableau Taiga Tavily Extract Tavily Search Tilores MCP Toolbox Twilio Upstage Valthera ValyuContext Vectara Wikidata Wikipedia Wolfram Alpha WRITER Tools Yahoo Finance News You.com Search YouTube Zapier Natural Language Actions ZenGuard AI If you'd like to contribute an integration, see Contributing integrations. Edit this page on GitHub or file an issue. Connect these docs to Claude, VSCode, and more via MCP for real-time answers.\n\nSearch\nThe following table shows tools that execute online searches in some shape or form: Tool/Toolkit Free/Paid Return Data Bing Search Paid URL, Snippet, Title Brave Search Free URL, Snippet, Title DuckDuckgoSearch Free URL, Snippet, Title Exa Search 1000 free searches/month URL, Author, Title, Published Date Google Search Paid URL, Snippet, Title Google Serper Free URL, Snippet, Title, Search Rank, Site Links Jina Search 1M Response Tokens Free URL, Snippet, Title, Page Content Mojeek Search Paid URL, Snippet, Title Parallel Search Paid URL, Title, Excerpts SearchApi 100 Free Searches on Sign Up URL, Snippet, Title, Search Rank, Site Links, Authors SearxNG Search Free URL, Snippet, Title, Category SerpApi 250 Free Searches/Month Answer Tavily Search 1000 free searches/month URL, Content, Title, Images, Answer You.com Search Free for 60 days URL, Title, Page Content\n"
  },
  {
    "role": "tool",
    "name": "search_support_articles",
    "tool_call_id": "call_3HVwEGo72osb0EbBfsC3vABN",
    "id": "5c064fe7-42da-4cb2-877f-544ba1f8c653",
    "content": "{\n  \"collections\": \"OSS (LangChain and LangGraph),SDKs and APIs\",\n  \"total\": 14,\n  \"articles\": [\n    {\n      \"id\": \"bb651320-775e-4dfa-a054-c955cc3a0d5d\",\n      \"title\": \"Why Do Pydantic\\u00a0date\\u00a0Fields Fail in LangGraph State?\",\n      \"url\": \"https://support.langchain.com/articles/7196116702-why-do-pydantic-date-fields-fail-in-langgraph-state\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"ae959c68-a996-4426-8c8e-ef3fa1dd88cc\",\n      \"title\": \"How do I connect JIRA, Slack, and Confluence MCPs with LangChain?\",\n      \"url\": \"https://support.langchain.com/articles/3473375007-how-do-i-connect-jira-slack-and-confluence-mcps-with-langchain\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"2836b779-a2f5-4058-a994-4fe2502166ca\",\n      \"title\": \"Missing Runs in LangSmith Experiment View with Concurrent Evaluations\",\n      \"url\": \"https://support.langchain.com/articles/8223468578-missing-runs-in-langsmith-experiment-view-with-concurrent-evaluations\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"d55d04fa-c883-4055-b266-343e5157ad31\",\n      \"title\": \"Preserving Trace Hierarchy with Manual RunTree Creation\",\n      \"url\": \"https://support.langchain.com/articles/9515178454-preserving-trace-hierarchy-with-manual-runtree-creation\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"9e06b53a-7b85-4793-b7b6-e179c0c8d815\",\n      \"title\": \"Isolating Subgraph State When Calling Graphs from Tools\",\n      \"url\": \"https://support.langchain.com/articles/6131002418-isolating-subgraph-state-when-calling-graphs-from-tools\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"9ef77ded-7211-4d09-944a-289972726262\",\n      \"title\": \"Why am I getting \\\"Failed to send compressed multipart ingest\\\" errors in LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9901468881-why-am-i-getting-failed-to-send-compressed-multipart-ingest-errors-in-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"e72b134e-bd5a-471d-93ea-8def86caf74a\",\n      \"title\": \"Why do I see inconsistent output formats for the same agent across different traces?\",\n      \"url\": \"https://support.langchain.com/articles/2041161407-why-do-i-see-inconsistent-output-formats-for-the-same-agent-across-different-traces\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"3ea46ebf-6af5-4ce2-b678-1c7d4b82caba\",\n      \"title\": \"Can I reopen a run after calling patch() to write additional data?\",\n      \"url\": \"https://support.langchain.com/articles/9964614152-can-i-reopen-a-run-after-calling-patch-to-write-additional-data\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"32994e7d-a182-41df-9f3d-271adf84fde2\",\n      \"title\": \"How do I filter runs by multiple run IDs using tree filters?\",\n      \"url\": \"https://support.langchain.com/articles/2574288399-how-do-i-filter-runs-by-multiple-run-ids-using-tree-filters\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f5a80963-8fe3-415f-b0e2-04b6f5093f12\",\n      \"title\": \"How do I filter runs by name using the LangSmith SDK?\",\n      \"url\": \"https://support.langchain.com/articles/5601207552-how-do-i-filter-runs-by-name-using-the-langsmith-sdk\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f51b0bb0-b838-40db-baa9-f9099ae34c2f\",\n      \"title\": \"How do I use LangSmith tracing with Cloudflare Workers?\",\n      \"url\": \"https://support.langchain.com/articles/1885761495-how-do-i-use-langsmith-tracing-with-cloudflare-workers\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"e2c86d05-b6fd-4bb3-8637-3f6d35c106dd\",\n      \"title\": \"How do I trace Vercel AI SDK calls with LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9620089182-how-do-i-trace-vercel-ai-sdk-calls-with-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"5f2572a3-9086-4d92-8d15-69f7b8e4c8be\",\n      \"title\": \"MCP Server Runtime in Google Colab / Jupyter Notebook\",\n      \"url\": \"https://support.langchain.com/articles/1061688976-mcp-server-runtime-in-google-colab-jupyter-notebook\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"45269e32-5322-4a17-8866-da640169d21d\",\n      \"title\": \"How do I export annotated traces in bulk from LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9958349143-how-do-i-export-annotated-traces-in-bulk-from-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    }\n  ],\n  \"note\": \"All articles listed are public and have content. Use IDs to fetch full content.\"\n}"
  },
  {
    "role": "assistant",
    "id": "lc_run--019b384e-ab93-7222-b623-2ebe00a12712",
    "content": "**The Gmail tool lets agents access and manipulate a user's Gmail via the Gmail API\u2014read/search messages, create drafts, send emails, and react to incoming mail (requires OAuth and the appropriate Gmail scopes).**\n\nIt works by running authenticated Gmail API calls inside a tool that the agent can call; tools that access Gmail must be configured with an OAuth provider and explicit scopes (for example `https://www.googleapis.com/auth/gmail.readonly` to read and `https://www.googleapis.com/auth/gmail.send` to send). Agents can also be triggered on incoming Gmail messages in Agent Builder.\n\n```python\n# Example (LangSmith Tool Server / Agent Builder style)\nfrom langsmith_tool_server import tool, Context\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\n\n@tool(\n    auth_provider=\"google\",\n    scopes=[\n        \"https://www.googleapis.com/auth/gmail.readonly\",\n        \"https://www.googleapis.com/auth/gmail.send\"\n    ],\n    integration=\"gmail\"\n)\nasync def read_emails(context: Context, max_results: int = 5) -> str:\n    \"\"\"Read recent emails from the authenticated user's mailbox.\"\"\"\n    # Use the OAuth token provided in context to build a Gmail client\n    creds = Credentials(token=context.token)\n    service = build(\"gmail\", \"v1\", credentials=creds)\n    msgs = service.users().messages().list(userId=\"me\", maxResults=max_results).execute()\n    return f\"Found {len(msgs.get('messages', []))} messages\"\n```\n\nCommon uses and notes:\n\n- Use cases:\n  \n  - Read/search mailbox and threads\n  - Compose/send messages or create drafts\n  - Trigger agents on incoming mail (automation)\n  - Manage labels, threads, attachments (via Gmail API)\n\n- Requirements and limits:\n  \n  - Must configure OAuth (Agent Auth) and request correct Gmail scopes\n  - Gmail Toolkit has usage/rate limits (docs list quota guidance, e.g., quota units per user)\n\n- Security:\n  \n  - OAuth tokens are user-scoped; workspace agents requiring Gmail access need each user to authenticate\n  - Only grant the minimum scopes needed (`gmail.readonly` vs `gmail.modify` vs `gmail.send`)\n\nRelevant docs:\n\n- [Agent Builder essentials](https://docs.langchain.com/langsmith/agent-builder-essentials)  \n- [LangSmith Tool Server / MCP framework (tool auth example)](https://docs.langchain.com/langsmith/agent-builder-mcp-framework)  \n- [Google integrations / Gmail Toolkit (tools index)](https://docs.langchain.com/oss/python/integrations/providers/google)"
  }
]