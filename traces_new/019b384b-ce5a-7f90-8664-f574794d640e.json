[
  {
    "role": "user",
    "id": "f98f0548-2ba2-4d3c-90d2-1c8b33faa7bf",
    "content": "\nconfiguration_service = ConfigurationService.get_instance()\nindex_search_service = IndexSearchService.create(\"nymity\")\n\n\n@tool(\n    \"nymity_research\",\n    description=\"\"\"\nThis is a specialized retrieval system for general privacy and compliance knowledge.\nIt must be used for any questions related to privacy principles, regulations (e.g., GDPR, CCPA, LGPD), compliance frameworks, data protection best practices, or organizational policy guidance.\nEven if the AI has an answer, it should always query this tool to ensure accuracy and alignment with authoritative sources.\nWhile other tools may handle customer-specific data, this is the default and required tool for any general or regulatory privacy inquiries.\n\"\"\",\n    args_schema=NymityResearchToolInput,\n    response_format=\"content_and_artifact\",\n)\nasync def nymity_research(\n    step_title: str, step_description: str, query: str\n) -> tuple[str, dict]:\n    has_access = configuration_service.has_role_access(\"nym_raa_\")\n    if not has_access:\n        return get_tool_access_denied_response(\"nymity_research\"), {\"no_access\": True}\n\n    result = await index_search_service.asearch_index(query)\n\n    return result, {}\n\n\n\ub534\ub370 \uc11c\ube44\uc2a4 \uc5b4\ucf00 \uac00\uc9c0\uace0 \uc624\ub0d0? \uc774\ub807\uac8c \ud558\ub294\uac8c \ub9de\ub0d0?"
  },
  {
    "role": "assistant",
    "tool_calls": [
      {
        "type": "function",
        "id": "call_hjDTpZaCJeqNIiVuZTukSfV5",
        "function": {
          "name": "SearchDocsByLangChain",
          "arguments": "{\"language\": \"python\", \"page_size\": 5, \"query\": \"tool\"}"
        }
      },
      {
        "type": "function",
        "id": "call_J5ggXs1cBwc0soKIclrRUl0s",
        "function": {
          "name": "search_support_articles",
          "arguments": "{\"collections\": \"SDKs and APIs,OSS (LangChain and LangGraph)\"}"
        }
      }
    ],
    "id": "lc_run--019b384a-290a-7b51-a575-d3443188261b",
    "content": ""
  },
  {
    "role": "tool",
    "name": "SearchDocsByLangChain",
    "tool_call_id": "call_hjDTpZaCJeqNIiVuZTukSfV5",
    "id": "e6d61197-8c34-495d-aff9-6ebe0f1d1f5b",
    "content": "Result 1:\nTitle: Tools\nLink: https://docs.langchain.comoss/javascript/integrations/tools/anthropic\nContent: Tool Search Tools\nThe tool search tools enable Claude to work with hundreds or thousands of tools by dynamically discovering and loading them on-demand. This is useful when you have a large number of tools but don't want to load them all into the context window at once. There are two variants: toolSearchRegex_20251119 - Claude constructs regex patterns (using Python's re.search() syntax) to search for tools toolSearchBM25_20251119 - Claude uses natural language queries to search for tools using the BM25 algorithm Using the BM25 variant for natural language search: For more information, see Anthropic's Tool Search documentation.\n\nTool Search Tools\nThe tool search tools enable Claude to work with hundreds or thousands of tools by dynamically discovering and loading them on-demand. This is useful when you have a large number of tools but don't want to load them all into the context window at once. There are two variants: toolSearchRegex_20251119 - Claude constructs regex patterns (using Python's re.search() syntax) to search for tools toolSearchBM25_20251119 - Claude uses natural language queries to search for tools using the BM25 algorithm Using the BM25 variant for natural language search: import { tools } from \"@langchain/anthropic\";\n\nconst response = await llm.invoke(\"What is the weather in San Francisco?\", {\n  tools: [tools.toolSearchBM25_20251119(), getWeather, getNews],\n});\n\nTool Search Tools\nThe tool search tools enable Claude to work with hundreds or thousands of tools by dynamically discovering and loading them on-demand. This is useful when you have a large number of tools but don't want to load them all into the context window at once. There are two variants: toolSearchRegex_20251119 - Claude constructs regex patterns (using Python's re.search() syntax) to search for tools toolSearchBM25_20251119 - Claude uses natural language queries to search for tools using the BM25 algorithm import { ChatAnthropic, tools } from \"@langchain/anthropic\";\nimport { tool } from \"langchain\";\nimport { z } from \"zod\";\n\nconst llm = new ChatAnthropic({\n  model: \"claude-sonnet-4-5-20250929\",\n});\n\n// Create tools with defer_loading to make them discoverable via search\nconst getWeather = tool(\n  async (input: { location: string }) => {\n    return `Weather in ${input.location}: Sunny, 72\u00b0F`;\n  },\n  {\n    name: \"get_weather\",\n    description: \"Get the weather at a specific location\",\n    schema: z.object({\n      location: z.string(),\n    }),\n    extras: { defer_loading: true },\n  }\n);\n\nconst getNews = tool(\n  async (input: { topic: string }) => {\n    return `Latest news about ${input.topic}...`;\n  },\n  {\n    name: \"get_news\",\n    description: \"Get the latest news about a topic\",\n    schema: z.object({\n      topic: z.string(),\n    }),\n    extras: { defer_loading: true },\n  }\n);\n\n// Claude will search and discover tools as needed\nconst response = await llm.invoke(\"What is the weather in San Francisco?\", {\n  tools: [tools.toolSearchRegex_20251119(), getWeather, getNews],\n});\n\n---\n\nResult 2:\nTitle: Tools and Toolkits\nLink: https://docs.langchain.comoss/javascript/integrations/tools/index\nContent: [Tools](/oss/javascript/langchain/tools) are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models.\n\nA [toolkit](/oss/javascript/langchain/tools#toolkits) is a collection of tools meant to be used together.\n\n## Integration Platforms\n\nThe following platforms provide access to multiple tools and services through a unified interface:\n\n| Tool/Toolkit                                            | Number of Integrations | Pricing             | Key Features                                               |\n| ------------------------------------------------------- | ---------------------- | ------------------- | ---------------------------------------------------------- |\n| [Composio](/oss/javascript/integrations/tools/composio) | 500+                   | Free tier available | OAuth handling, event-driven workflows, multi-user support |\n\n## All Tools and Toolkits\n\n<Columns cols={3}>\n  <Card title=\"Azure Container Apps Dynamic Sessions\" icon=\"link\" href=\"/oss/javascript/integrations/tools/azure_dynamic_sessions\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Connery Action Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/connery\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Composio\" icon=\"link\" href=\"/oss/javascript/integrations/tools/composio\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Dall-E Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/dalle\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Decodo Tools\" icon=\"link\" href=\"/oss/javascript/integrations/tools/decodo\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Discord Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/discord_tool\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"DuckDuckGoSearch\" icon=\"link\" href=\"/oss/javascript/integrations/tools/duckduckgo_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"ExaSearchResults\" icon=\"link\" href=\"/oss/javascript/integrations/tools/exa_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"FalkorDB\" icon=\"link\" href=\"/oss/javascript/integrations/tools/falkordb\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Gmail Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_gmail\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"GOAT\" icon=\"link\" href=\"/oss/javascript/integrations/tools/goat\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Calendar Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_calendar\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Places Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_places\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Routes Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_routes\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Scholar\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_scholar\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Trends Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_trends\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"JigsawStack Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/jigsawstack\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Agent with AWS Lambda\" icon=\"link\" href=\"/oss/javascript/integrations/tools/lambda_agent\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Python interpreter tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/pyinterpreter\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"SearchApi tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/searchapi\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Searxng Search tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/searxng\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"SerpAPI\" icon=\"link\" href=\"/oss/javascript/integrations/tools/serpapi\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"StackExchange Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/stackexchange\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Stagehand AI Web Automation Toolkit\" icon=\"link\" href=\"/oss/javascript/integrations/tools/stagehand\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Crawl\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_crawl\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Extract\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_extract\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Map\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_map\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Search\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Web Browser Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/webbrowser\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Wikipedia tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/wikipedia\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"WolframAlpha Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/wolframalpha\" arrow=\"true\" cta=\"View guide\" />\n</Columns>\n\n<Info>\n  If you'd like to write your own tool, see [this how-to](/oss/javascript/langchain/tools#customize-tool-properties). If you'd like to contribute an integration, see [Contributing integrations](/oss/javascript/contributing#add-a-new-integration).\n</Info>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/tools/index.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 3:\nTitle: Tools\nLink: https://docs.langchain.comoss/javascript/langchain/tools\nContent: Tools extend what [agents](/oss/javascript/langchain/agents) can do\u2014letting them fetch real-time data, execute code, query external databases, and take actions in the world.\n\nUnder the hood, tools are callable functions with well-defined inputs and outputs that get passed to a [chat model](/oss/javascript/langchain/models). The model decides when to invoke a tool based on the conversation context, and what input arguments to provide.\n\n<Tip>\n  For details on how models handle tool calls, see [Tool calling](/oss/javascript/langchain/models#tool-calling).\n</Tip>\n\n## Create tools\n\n### Basic tool definition\n\nThe simplest way to create a tool is by importing the `tool` function from the `langchain` package. You can use [zod](https://zod.dev/) to define the tool's input schema:\n\n```ts  theme={null}\nimport * as z from \"zod\"\nimport { tool } from \"langchain\"\n\nconst searchDatabase = tool(\n  ({ query, limit }) => `Found ${limit} results for '${query}'`,\n  {\n    name: \"search_database\",\n    description: \"Search the customer database for records matching the query.\",\n    schema: z.object({\n      query: z.string().describe(\"Search terms to look for\"),\n      limit: z.number().describe(\"Maximum number of results to return\"),\n    }),\n  }\n);\n```\n\n<Note>\n  **Server-side tool use**\n\n  Some chat models (e.g., [OpenAI](/oss/javascript/integrations/chat/openai), [Anthropic](/oss/javascript/integrations/chat/anthropic), and [Gemini](/oss/javascript/integrations/chat/google_generative_ai)) feature [built-in tools](/oss/javascript/langchain/models#server-side-tool-use) that are executed server-side, such as web search and code interpreters. Refer to the [provider overview](/oss/javascript/integrations/providers/overview) to learn how to access these tools with your specific chat model.\n</Note>\n\n## Accessing Context\n\n<Info>\n  **Why this matters:** Tools are most powerful when they can access agent state, runtime context, and long-term memory. This enables tools to make context-aware decisions, personalize responses, and maintain information across conversations.\n\n  The runtime context provides a structured way to supply runtime data, such as DB connections, user IDs, or config, into your tools. This avoids global state and keeps tools testable and reusable.\n</Info>\n\n#### Context\n\nTools can access an agent's runtime context through the `config` parameter:\n\n```ts  theme={null}\nimport * as z from \"zod\"\nimport { ChatOpenAI } from \"@langchain/openai\"\nimport { createAgent } from \"langchain\"\n\nconst getUserName = tool(\n  (_, config) => {\n    return config.context.user_name\n  },\n  {\n    name: \"get_user_name\",\n    description: \"Get the user's name.\",\n    schema: z.object({}),\n  }\n);\n\nconst contextSchema = z.object({\n  user_name: z.string(),\n});\n\nconst agent = createAgent({\n  model: new ChatOpenAI({ model: \"gpt-4o\" }),\n  tools: [getUserName],\n  contextSchema,\n});\n\nconst result = await agent.invoke(\n  {\n    messages: [{ role: \"user\", content: \"What is my name?\" }]\n  },\n  {\n    context: { user_name: \"John Smith\" }\n  }\n);\n```\n\n#### Memory (Store)\n\nAccess persistent data across conversations using the store. The store is accessed via `config.store` and allows you to save and retrieve user-specific or application-specific data.\n\n```ts expandable theme={null}\nimport * as z from \"zod\";\nimport { createAgent, tool } from \"langchain\";\nimport { InMemoryStore } from \"@langchain/langgraph\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst store = new InMemoryStore();\n\n// Access memory\nconst getUserInfo = tool(\n  async ({ user_id }) => {\n    const value = await store.get([\"users\"], user_id);\n    console.log(\"get_user_info\", user_id, value);\n    return value;\n  },\n  {\n    name: \"get_user_info\",\n    description: \"Look up user info.\",\n    schema: z.object({\n      user_id: z.string(),\n    }),\n  }\n);\n\n// Update memory\nconst saveUserInfo = tool(\n  async ({ user_id, name, age, email }) => {\n    console.log(\"save_user_info\", user_id, name, age, email);\n    await store.put([\"users\"], user_id, { name, age, email });\n    return \"Successfully saved user info.\";\n  },\n  {\n    name: \"save_user_info\",\n    description: \"Save user info.\",\n    schema: z.object({\n      user_id: z.string(),\n      name: z.string(),\n      age: z.number(),\n      email: z.string(),\n    }),\n  }\n);\n\nconst agent = createAgent({\n  model: new ChatOpenAI({ model: \"gpt-4o\" }),\n  tools: [getUserInfo, saveUserInfo],\n  store,\n});\n\n// First session: save user info\nawait agent.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\",\n    },\n  ],\n});\n\n// Second session: get user info\nconst result = await agent.invoke({\n  messages: [\n    { role: \"user\", content: \"Get user info for user with id 'abc123'\" },\n  ],\n});\n\nconsole.log(result);\n// Here is the user info for user with ID \"abc123\":\n// - Name: Foo\n// - Age: 25\n// - Email: foo@langchain.dev\n```\n\n#### Stream Writer\n\nStream custom updates from tools as they execute using `config.streamWriter`. This is useful for providing real-time feedback to users about what a tool is doing.\n\n```ts  theme={null}\nimport * as z from \"zod\";\nimport { tool, ToolRuntime } from \"langchain\";\n\nconst getWeather = tool(\n  ({ city }, config: ToolRuntime) => {\n    const writer = config.writer;\n\n    // Stream custom updates as the tool executes\n    if (writer) {\n      writer(`Looking up data for city: ${city}`);\n      writer(`Acquired data for city: ${city}`);\n    }\n\n    return `It's always sunny in ${city}!`;\n  },\n  {\n    name: \"get_weather\",\n    description: \"Get weather for a given city.\",\n    schema: z.object({\n      city: z.string(),\n    }),\n  }\n);\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/tools.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 4:\nTitle: Tools and toolkits\nLink: https://docs.langchain.comoss/python/integrations/tools/index\nContent: Search\nThe following table shows tools that execute online searches in some shape or form: Tool/Toolkit Free/Paid Return Data Bing Search Paid URL, Snippet, Title Brave Search Free URL, Snippet, Title DuckDuckgoSearch Free URL, Snippet, Title Exa Search 1000 free searches/month URL, Author, Title, Published Date Google Search Paid URL, Snippet, Title Google Serper Free URL, Snippet, Title, Search Rank, Site Links Jina Search 1M Response Tokens Free URL, Snippet, Title, Page Content Mojeek Search Paid URL, Snippet, Title Parallel Search Paid URL, Title, Excerpts SearchApi 100 Free Searches on Sign Up URL, Snippet, Title, Search Rank, Site Links, Authors SearxNG Search Free URL, Snippet, Title, Category SerpAPI 100 Free Searches/Month Answer Tavily Search 1000 free searches/month URL, Content, Title, Images, Answer You.com Search Free for 60 days URL, Title, Page Content\n\nTools and toolkits\nTools and toolkits\nTools are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models. A toolkit is a collection of tools meant to be used together.\n\nAll tools and toolkits\nADS4GPTs AgentQL AINetwork Toolkit Alpha Vantage Amadeus Toolkit Anchor Browser Apify Actor ArXiv AskNews AWS Lambda Azure AI Services Toolkit Azure Cognitive Services Toolkit Azure Container Apps Dynamic Sessions Shell (bash) Bearly Code Interpreter Bing Search Bodo DataFrames Brave Search BrightData Web Scraper API BrightData SERP BrightData Unlocker Cassandra Database Toolkit CDP ChatGPT Plugins ClickUp Toolkit Cogniswitch Toolkit Compass DeFi Toolkit Composio Connery Toolkit Dall-E Image Generator Dappier Databricks Unity Catalog DataForSEO Dataherald Daytona Data Analysis DuckDuckGo Search Discord E2B Data Analysis Eden AI ElevenLabs Text2Speech Exa Search File System Financial Datasets Toolkit FMP Data GitHub Toolkit GitLab Toolkit Gmail Toolkit GOAT Privy Golden Query Google Books Google Calendar Toolkit Google Cloud Text-to-Speech Google Drive Google Finance Google Imagen Google Jobs Google Lens Google Places Google Scholar Google Search Google Serper Google Trends Gradio GraphQL HuggingFace Hub Tools Human as a Tool Hyperbrowser Browser Agent Tools Hyperbrowser Web Scraping Tools IBM watsonx.ai IBM watsonx.ai (SQL) IFTTT WebHooks Infobip Ionic Shopping Tool Jenkins Jina Search Jira Toolkit JSON Toolkit Lemon Agent Linkup Search Tool Memgraph Memorize Mojeek Search MultiOn Toolkit NASA Toolkit Naver Search Nuclia Understanding NVIDIA Riva Office365 Toolkit OpenAPI Toolkit Natural Language API Toolkits OpenGradient OpenWeatherMap Oracle AI Vector Search Oxylabs Pandas Dataframe Passio NutritionAI Parallel Extract Parallel Search Permit PlayWright Browser Toolkit Polygon IO Toolkit PowerBI Toolkit Prolog PubMed Python REPL Reddit Search Requests Toolkit Riza Code Interpreter Robocorp Toolkit Salesforce SceneXplain ScrapeGraph Scrapeless Crawl Scrapeless Scraping API Scrapeless Universal Scraping SearchApi SearxNG Search Semantic Scholar API SerpAPI Slack Toolkit Spark SQL Toolkit SQLDatabase Toolkit StackExchange Steam Toolkit Stripe Tableau Taiga Tavily Extract Tavily Search Tilores MCP Toolbox Twilio Upstage Valthera ValyuContext Vectara Wikidata Wikipedia Wolfram Alpha WRITER Tools Yahoo Finance News You.com Search YouTube Zapier Natural Language Actions ZenGuard AI If you'd like to contribute an integration, see Contributing integrations. Edit the source of this page on GitHub. Connect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.\n\n---\n\nResult 5:\nTitle: Tools\nLink: https://docs.langchain.comoss/python/langchain/tools\nContent: Tools extend what [agents](/oss/python/langchain/agents) can do\u2014letting them fetch real-time data, execute code, query external databases, and take actions in the world.\n\nUnder the hood, tools are callable functions with well-defined inputs and outputs that get passed to a [chat model](/oss/python/langchain/models). The model decides when to invoke a tool based on the conversation context, and what input arguments to provide.\n\n<Tip>\n  For details on how models handle tool calls, see [Tool calling](/oss/python/langchain/models#tool-calling).\n</Tip>\n\n## Create tools\n\n### Basic tool definition\n\nThe simplest way to create a tool is with the [`@tool`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.tool) decorator. By default, the function's docstring becomes the tool's description that helps the model understand when to use it:\n\n```python  theme={null}\nfrom langchain.tools import tool\n\n@tool\ndef search_database(query: str, limit: int = 10) -> str:\n    \"\"\"Search the customer database for records matching the query.\n\n    Args:\n        query: Search terms to look for\n        limit: Maximum number of results to return\n    \"\"\"\n    return f\"Found {limit} results for '{query}'\"\n```\n\nType hints are **required** as they define the tool's input schema. The docstring should be informative and concise to help the model understand the tool's purpose.\n\n<Note>\n  **Server-side tool use**\n\n  Some chat models (e.g., [OpenAI](/oss/python/integrations/chat/openai), [Anthropic](/oss/python/integrations/chat/anthropic), and [Gemini](/oss/python/integrations/chat/google_generative_ai)) feature [built-in tools](/oss/python/langchain/models#server-side-tool-use) that are executed server-side, such as web search and code interpreters. Refer to the [provider overview](/oss/python/integrations/providers/overview) to learn how to access these tools with your specific chat model.\n</Note>\n\n### Customize tool properties\n\n#### Custom tool name\n\nBy default, the tool name comes from the function name. Override it when you need something more descriptive:\n\n```python  theme={null}\n@tool(\"web_search\")  # Custom name\ndef search(query: str) -> str:\n    \"\"\"Search the web for information.\"\"\"\n    return f\"Results for: {query}\"\n\nprint(search.name)  # web_search\n```\n\n#### Custom tool description\n\nOverride the auto-generated tool description for clearer model guidance:\n\n```python  theme={null}\n@tool(\"calculator\", description=\"Performs arithmetic calculations. Use this for any math problems.\")\ndef calc(expression: str) -> str:\n    \"\"\"Evaluate mathematical expressions.\"\"\"\n    return str(eval(expression))\n```\n\n### Advanced schema definition\n\nDefine complex inputs with Pydantic models or JSON schemas:\n\n<CodeGroup>\n  ```python Pydantic model theme={null}\n  from pydantic import BaseModel, Field\n  from typing import Literal\n\n  class WeatherInput(BaseModel):\n      \"\"\"Input for weather queries.\"\"\"\n      location: str = Field(description=\"City name or coordinates\")\n      units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n          default=\"celsius\",\n          description=\"Temperature unit preference\"\n      )\n      include_forecast: bool = Field(\n          default=False,\n          description=\"Include 5-day forecast\"\n      )\n\n  @tool(args_schema=WeatherInput)\n  def get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n      \"\"\"Get current weather and optional forecast.\"\"\"\n      temp = 22 if units == \"celsius\" else 72\n      result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n      if include_forecast:\n          result += \"\\nNext 5 days: Sunny\"\n      return result\n  ```\n\n  ```python JSON Schema theme={null}\n  weather_schema = {\n      \"type\": \"object\",\n      \"properties\": {\n          \"location\": {\"type\": \"string\"},\n          \"units\": {\"type\": \"string\"},\n          \"include_forecast\": {\"type\": \"boolean\"}\n      },\n      \"required\": [\"location\", \"units\", \"include_forecast\"]\n  }\n\n  @tool(args_schema=weather_schema)\n  def get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n      \"\"\"Get current weather and optional forecast.\"\"\"\n      temp = 22 if units == \"celsius\" else 72\n      result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n      if include_forecast:\n          result += \"\\nNext 5 days: Sunny\"\n      return result\n  ```\n</CodeGroup>\n\n### Reserved argument names\n\nThe following parameter names are reserved and cannot be used as tool arguments. Using these names will cause runtime errors.\n\n| Parameter name | Purpose                                                                |\n| -------------- | ---------------------------------------------------------------------- |\n| `config`       | Reserved for passing `RunnableConfig` to tools internally              |\n| `runtime`      | Reserved for `ToolRuntime` parameter (accessing state, context, store) |\n\nTo access runtime information, use the [`ToolRuntime`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.ToolRuntime) parameter instead of naming your own arguments `config` or `runtime`.\n\n## Accessing Context\n\n<Info>\n  **Why this matters:** Tools are most powerful when they can access agent state, runtime context, and long-term memory. This enables tools to make context-aware decisions, personalize responses, and maintain information across conversations.\n\n  Runtime context provides a way to inject dependencies (like database connections, user IDs, or configuration) into your tools at runtime, making them more testable and reusable.\n</Info>\n\nTools can access runtime information through the `ToolRuntime` parameter, which provides:\n\n* **State** - Mutable data that flows through execution (e.g., messages, counters, custom fields)\n* **Context** - Immutable configuration like user IDs, session details, or application-specific configuration\n* **Store** - Persistent long-term memory across conversations\n* **Stream Writer** - Stream custom updates as tools execute\n* **Config** - `RunnableConfig` for the execution\n* **Tool Call ID** - ID of the current tool call\n\n```mermaid  theme={null}\ngraph LR\n    %% Runtime Context\n    subgraph \"\ud83d\udd27 Tool Runtime Context\"\n        A[Tool Call] --> B[ToolRuntime]\n        B --> C[State Access]\n        B --> D[Context Access]\n        B --> E[Store Access]\n        B --> F[Stream Writer]\n    end\n\n    %% Available Resources\n    subgraph \"\ud83d\udcca Available Resources\"\n        C --> G[Messages]\n        C --> H[Custom State]\n        D --> I[User ID]\n        D --> J[Session Info]\n        E --> K[Long-term Memory]\n        E --> L[User Preferences]\n    end\n\n    %% Tool Capabilities\n    subgraph \"\u26a1 Enhanced Tool Capabilities\"\n        M[Context-Aware Tools]\n        N[Stateful Tools]\n        O[Memory-Enabled Tools]\n        P[Streaming Tools]\n    end\n\n    %% Connections\n    G --> M\n    H --> N\n    I --> M\n    J --> M\n    K --> O\n    L --> O\n    F --> P\n```\n\n### `ToolRuntime`\n\nUse `ToolRuntime` to access all runtime information in a single parameter. Simply add `runtime: ToolRuntime` to your tool signature, and it will be automatically injected without being exposed to the LLM.\n\n<Info>\n  **`ToolRuntime`**: A unified parameter that provides tools access to state, context, store, streaming, config, and tool call ID. This replaces the older pattern of using separate [`InjectedState`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedState), [`InjectedStore`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedStore), [`get_runtime`](https://reference.langchain.com/python/langgraph/runtime/#langgraph.runtime.get_runtime), and [`InjectedToolCallId`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.InjectedToolCallId) annotations.\n\n  The runtime automatically provides these capabilities to your tool functions without you having to pass them explicitly or use global state.\n</Info>\n\n**Accessing state:**\n\nTools can access the current graph state using `ToolRuntime`:\n\n```python  theme={null}\nfrom langchain.tools import tool, ToolRuntime\n\n# Access the current conversation state\n@tool\ndef summarize_conversation(\n    runtime: ToolRuntime\n) -> str:\n    \"\"\"Summarize the conversation so far.\"\"\"\n    messages = runtime.state[\"messages\"]\n\n    human_msgs = sum(1 for m in messages if m.__class__.__name__ == \"HumanMessage\")\n    ai_msgs = sum(1 for m in messages if m.__class__.__name__ == \"AIMessage\")\n    tool_msgs = sum(1 for m in messages if m.__class__.__name__ == \"ToolMessage\")\n\n    return f\"Conversation has {human_msgs} user messages, {ai_msgs} AI responses, and {tool_msgs} tool results\"\n\n# Access custom state fields\n@tool\ndef get_user_preference(\n    pref_name: str,\n    runtime: ToolRuntime  # ToolRuntime parameter is not visible to the model\n) -> str:\n    \"\"\"Get a user preference value.\"\"\"\n    preferences = runtime.state.get(\"user_preferences\", {})\n    return preferences.get(pref_name, \"Not set\")\n```\n\n<Warning>\n  The `runtime` parameter is hidden from the model. For the example above, the model only sees `pref_name` in the tool schema - `runtime` is *not* included in the request.\n</Warning>\n\n**Updating state:**\n\nUse [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) to update the agent's state or control the graph's execution flow:\n\n```python  theme={null}\nfrom langgraph.types import Command\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langchain.tools import tool, ToolRuntime\n\n# Update the conversation history by removing all messages\n@tool\ndef clear_conversation() -> Command:\n    \"\"\"Clear the conversation history.\"\"\"\n\n    return Command(\n        update={\n            \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)],\n        }\n    )\n\n# Update the user_name in the agent state\n@tool\ndef update_user_name(\n    new_name: str,\n    runtime: ToolRuntime\n) -> Command:\n    \"\"\"Update the user's name.\"\"\"\n    return Command(update={\"user_name\": new_name})\n```\n\n#### Context\n\nAccess immutable configuration and contextual data like user IDs, session details, or application-specific configuration through `runtime.context`.\n\nTools can access runtime context through `ToolRuntime`:\n\n```python  theme={null}\nfrom dataclasses import dataclass\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n\nUSER_DATABASE = {\n    \"user123\": {\n        \"name\": \"Alice Johnson\",\n        \"account_type\": \"Premium\",\n        \"balance\": 5000,\n        \"email\": \"alice@example.com\"\n    },\n    \"user456\": {\n        \"name\": \"Bob Smith\",\n        \"account_type\": \"Standard\",\n        \"balance\": 1200,\n        \"email\": \"bob@example.com\"\n    }\n}\n\n@dataclass\nclass UserContext:\n    user_id: str\n\n@tool\ndef get_account_info(runtime: ToolRuntime[UserContext]) -> str:\n    \"\"\"Get the current user's account information.\"\"\"\n    user_id = runtime.context.user_id\n\n    if user_id in USER_DATABASE:\n        user = USER_DATABASE[user_id]\n        return f\"Account holder: {user['name']}\\nType: {user['account_type']}\\nBalance: ${user['balance']}\"\n    return \"User not found\"\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\nagent = create_agent(\n    model,\n    tools=[get_account_info],\n    context_schema=UserContext,\n    system_prompt=\"You are a financial assistant.\"\n)\n\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my current balance?\"}]},\n    context=UserContext(user_id=\"user123\")\n)\n```\n\n#### Memory (Store)\n\nAccess persistent data across conversations using the store. The store is accessed via `runtime.store` and allows you to save and retrieve user-specific or application-specific data.\n\nTools can access and update the store through `ToolRuntime`:\n\n```python expandable theme={null}\nfrom typing import Any\nfrom langgraph.store.memory import InMemoryStore\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n\n# Access memory\n@tool\ndef get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n    \"\"\"Look up user info.\"\"\"\n    store = runtime.store\n    user_info = store.get((\"users\",), user_id)\n    return str(user_info.value) if user_info else \"Unknown user\"\n\n# Update memory\n@tool\ndef save_user_info(user_id: str, user_info: dict[str, Any], runtime: ToolRuntime) -> str:\n    \"\"\"Save user info.\"\"\"\n    store = runtime.store\n    store.put((\"users\",), user_id, user_info)\n    return \"Successfully saved user info.\"\n\nstore = InMemoryStore()\nagent = create_agent(\n    model,\n    tools=[get_user_info, save_user_info],\n    store=store\n)\n\n# First session: save user info\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\"}]\n})\n\n# Second session: get user info\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Get user info for user with id 'abc123'\"}]\n})\n# Here is the user info for user with ID \"abc123\":\n# - Name: Foo\n# - Age: 25\n# - Email: foo@langchain.dev\n```\n\n#### Stream Writer\n\nStream custom updates from tools as they execute using `runtime.stream_writer`. This is useful for providing real-time feedback to users about what a tool is doing.\n\n```python  theme={null}\nfrom langchain.tools import tool, ToolRuntime\n\n@tool\ndef get_weather(city: str, runtime: ToolRuntime) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    writer = runtime.stream_writer\n\n    # Stream custom updates as the tool executes\n    writer(f\"Looking up data for city: {city}\")\n    writer(f\"Acquired data for city: {city}\")\n\n    return f\"It's always sunny in {city}!\"\n```\n\n<Note>\n  If you use `runtime.stream_writer` inside your tool, the tool must be invoked within a LangGraph execution context. See [Streaming](/oss/python/langchain/streaming) for more details.\n</Note>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/tools.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n"
  },
  {
    "role": "tool",
    "name": "search_support_articles",
    "tool_call_id": "call_J5ggXs1cBwc0soKIclrRUl0s",
    "id": "92caca3f-cc49-4ebd-a1eb-433d30d1c62a",
    "content": "{\n  \"collections\": \"SDKs and APIs,OSS (LangChain and LangGraph)\",\n  \"total\": 14,\n  \"articles\": [\n    {\n      \"id\": \"bb651320-775e-4dfa-a054-c955cc3a0d5d\",\n      \"title\": \"Why Do Pydantic\\u00a0date\\u00a0Fields Fail in LangGraph State?\",\n      \"url\": \"https://support.langchain.com/articles/7196116702-why-do-pydantic-date-fields-fail-in-langgraph-state\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"ae959c68-a996-4426-8c8e-ef3fa1dd88cc\",\n      \"title\": \"How do I connect JIRA, Slack, and Confluence MCPs with LangChain?\",\n      \"url\": \"https://support.langchain.com/articles/3473375007-how-do-i-connect-jira-slack-and-confluence-mcps-with-langchain\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"2836b779-a2f5-4058-a994-4fe2502166ca\",\n      \"title\": \"Missing Runs in LangSmith Experiment View with Concurrent Evaluations\",\n      \"url\": \"https://support.langchain.com/articles/8223468578-missing-runs-in-langsmith-experiment-view-with-concurrent-evaluations\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"d55d04fa-c883-4055-b266-343e5157ad31\",\n      \"title\": \"Preserving Trace Hierarchy with Manual RunTree Creation\",\n      \"url\": \"https://support.langchain.com/articles/9515178454-preserving-trace-hierarchy-with-manual-runtree-creation\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"9e06b53a-7b85-4793-b7b6-e179c0c8d815\",\n      \"title\": \"Isolating Subgraph State When Calling Graphs from Tools\",\n      \"url\": \"https://support.langchain.com/articles/6131002418-isolating-subgraph-state-when-calling-graphs-from-tools\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"9ef77ded-7211-4d09-944a-289972726262\",\n      \"title\": \"Why am I getting \\\"Failed to send compressed multipart ingest\\\" errors in LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9901468881-why-am-i-getting-failed-to-send-compressed-multipart-ingest-errors-in-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"e72b134e-bd5a-471d-93ea-8def86caf74a\",\n      \"title\": \"Why do I see inconsistent output formats for the same agent across different traces?\",\n      \"url\": \"https://support.langchain.com/articles/2041161407-why-do-i-see-inconsistent-output-formats-for-the-same-agent-across-different-traces\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"3ea46ebf-6af5-4ce2-b678-1c7d4b82caba\",\n      \"title\": \"Can I reopen a run after calling patch() to write additional data?\",\n      \"url\": \"https://support.langchain.com/articles/9964614152-can-i-reopen-a-run-after-calling-patch-to-write-additional-data\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"32994e7d-a182-41df-9f3d-271adf84fde2\",\n      \"title\": \"How do I filter runs by multiple run IDs using tree filters?\",\n      \"url\": \"https://support.langchain.com/articles/2574288399-how-do-i-filter-runs-by-multiple-run-ids-using-tree-filters\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f5a80963-8fe3-415f-b0e2-04b6f5093f12\",\n      \"title\": \"How do I filter runs by name using the LangSmith SDK?\",\n      \"url\": \"https://support.langchain.com/articles/5601207552-how-do-i-filter-runs-by-name-using-the-langsmith-sdk\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f51b0bb0-b838-40db-baa9-f9099ae34c2f\",\n      \"title\": \"How do I use LangSmith tracing with Cloudflare Workers?\",\n      \"url\": \"https://support.langchain.com/articles/1885761495-how-do-i-use-langsmith-tracing-with-cloudflare-workers\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"e2c86d05-b6fd-4bb3-8637-3f6d35c106dd\",\n      \"title\": \"How do I trace Vercel AI SDK calls with LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9620089182-how-do-i-trace-vercel-ai-sdk-calls-with-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"5f2572a3-9086-4d92-8d15-69f7b8e4c8be\",\n      \"title\": \"MCP Server Runtime in Google Colab / Jupyter Notebook\",\n      \"url\": \"https://support.langchain.com/articles/1061688976-mcp-server-runtime-in-google-colab-jupyter-notebook\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"45269e32-5322-4a17-8866-da640169d21d\",\n      \"title\": \"How do I export annotated traces in bulk from LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9958349143-how-do-i-export-annotated-traces-in-bulk-from-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    }\n  ],\n  \"note\": \"All articles listed are public and have content. Use IDs to fetch full content.\"\n}"
  },
  {
    "role": "assistant",
    "id": "lc_run--019b384a-5d0b-7380-b0b4-ebe129f552f6",
    "content": "**\ub124 \u2014 \ud604\uc7ac \ubc29\uc2dd\ub3c4 \ub3d9\uc791\ud558\uc9c0\ub9cc \ub354 \uad8c\uc7a5\ub418\ub294 \ub450 \uac00\uc9c0 \ud328\ud134\uc774 \uc788\uc2b5\ub2c8\ub2e4: `ToolRuntime`\uc744 \ud1b5\ud55c \uc8fc\uc785\uacfc \ud074\ub85c\uc800(\ud329\ud1a0\ub9ac)\ub85c \uc11c\ube44\uc2a4 \ucea1\ucc98\ud558\ub294 \ubc29\ubc95\uc785\ub2c8\ub2e4.**\n\n`ToolRuntime`\uc744 \uc0ac\uc6a9\ud558\uba74 \ub3c4\uad6c \ub0b4\ubd80\uc5d0\uc11c \uc548\uc804\ud558\uac8c \ub7f0\ud0c0\uc784 \ucee8\ud14d\uc2a4\ud2b8(`runtime.context`, `runtime.store`, `runtime.stream_writer` \ub4f1)\uc5d0 \uc811\uadfc\ud560 \uc218 \uc788\uace0, \ud074\ub85c\uc800 \ubc29\uc2dd\uc740 \ub2e8\uc21c\ud558\uace0 \ud14c\uc2a4\ud2b8\ud558\uae30 \uc26c\uc6b4 \ub300\uc548\uc785\ub2c8\ub2e4. `@tool` \ub370\ucf54\ub808\uc774\ud130\uc758 \ube44\uacf5\uac1c \ub7f0\ud0c0\uc784 \ud30c\ub77c\ubbf8\ud130\ub85c `ToolRuntime`\uc744 \uc120\uc5b8\ud558\uba74 \uadf8 \ud30c\ub77c\ubbf8\ud130\ub294 \ubaa8\ub378\uc5d0 \ub178\ucd9c\ub418\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4(`config`/`runtime` \uac19\uc740 \uc608\uc57d\uc5b4 \uc0ac\uc6a9 \uc8fc\uc758).\n\n```python\n# \ubc29\uc2dd A: ToolRuntime\uc73c\ub85c \uc11c\ube44\uc2a4 \uc8fc\uc785 (\uad8c\uc7a5)\nfrom langchain.tools import tool, ToolRuntime\nfrom dataclasses import dataclass\n\n# \ucee8\ud14d\uc2a4\ud2b8 \uc2a4\ud0a4\ub9c8 \uc815\uc758 (create_agent\uc5d0 \uc804\ub2ec)\n@dataclass\nclass ServicesContext:\n    configuration_service: ConfigurationService\n    index_search_service: IndexSearchService\n\n@tool(\n    \"nymity_research\",\n    args_schema=NymityResearchToolInput,\n    response_format=\"content_and_artifact\",\n)\nasync def nymity_research(\n    step_title: str,\n    step_description: str,\n    query: str,\n    runtime: ToolRuntime[ServicesContext],  # \uc790\ub3d9\uc73c\ub85c \uc8fc\uc785\ub428, \ubaa8\ub378\uc5d0 \ub178\ucd9c\ub418\uc9c0 \uc54a\uc74c\n) -> tuple[str, dict]:\n    configuration_service = runtime.context.configuration_service\n    index_search_service = runtime.context.index_search_service\n\n    has_access = configuration_service.has_role_access(\"nym_raa_\")\n    if not has_access:\n        return get_tool_access_denied_response(\"nymity_research\"), {\"no_access\": True}\n\n    result = await index_search_service.asearch_index(query)\n    return result, {}\n```\n\n\uc124\uc815/\ud638\ucd9c \uc608\uc2dc (agent \uc0dd\uc131 \uc2dc `context_schema`\ub85c \uc120\uc5b8\ud558\uace0 \ud638\ucd9c \uc2dc `context` \uc804\ub2ec):\n\n```python\nfrom langchain.agents import create_agent\n\nagent = create_agent(\n    model=my_model,\n    tools=[nymity_research],\n    context_schema=ServicesContext,\n)\n\n# \uc2e4\ud589 \uc2dc \uc2e4\uc81c \uc11c\ube44\uc2a4 \uc778\uc2a4\ud134\uc2a4 \uc804\ub2ec\nresult = await agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"...\" }]},\n    context=ServicesContext(\n        configuration_service=configuration_service,\n        index_search_service=index_search_service,\n    ),\n)\n```\n\n## \ub2e4\ub978 \uc635\uc158 \u2014 \ud074\ub85c\uc800(\ud329\ud1a0\ub9ac)\ub85c \uc11c\ube44\uc2a4 \ucea1\ucc98\n\n\uc11c\ube44\uc2a4\ub97c \uc804\uc5ed(singleton)\uc73c\ub85c \ub450\uac70\ub098 \ubaa8\ub4c8 \ub808\ubca8\uc5d0\uc11c \uac00\uc838\uc624\ub294 \ub300\uc2e0, \ud234 \uc0dd\uc131 \uc2dc\uc810\uc5d0 \uba85\uc2dc\uc801\uc73c\ub85c \uc8fc\uc785\ud558\uba74 \ud14c\uc2a4\ud2b8/\uad50\uccb4\uac00 \uc26c\uc6cc\uc9d1\ub2c8\ub2e4:\n\n```python\n# \ubc29\uc2dd B: \ud074\ub85c\uc800\ub85c \uc11c\ube44\uc2a4 \ucea1\ucc98\nfrom langchain.tools import tool\n\ndef make_nymity_tool(configuration_service, index_search_service):\n    @tool(\n        \"nymity_research\",\n        args_schema=NymityResearchToolInput,\n        response_format=\"content_and_artifact\",\n    )\n    async def nymity_research(step_title: str, step_description: str, query: str):\n        has_access = configuration_service.has_role_access(\"nym_raa_\")\n        if not has_access:\n            return get_tool_access_denied_response(\"nymity_research\"), {\"no_access\": True}\n        result = await index_search_service.asearch_index(query)\n        return result, {}\n\n    return nymity_research\n\nnymity_tool = make_nymity_tool(configuration_service, index_search_service)\n# nymity_tool\uc744 \uc5d0\uc774\uc804\ud2b8\uc5d0 \ub4f1\ub85d\n```\n\n- \uc804\uc5ed(singleton) \uc9c1\uc811 \ucc38\uc870\ub3c4 \uac00\ub2a5\ud558\ub098, \ud14c\uc2a4\ud2b8ability\uc640 \uba85\uc2dc\uc801 \uc758\uc874\uc131 \uc8fc\uc785 \uad00\uc810\uc5d0\uc11c `ToolRuntime` \ub610\ub294 \ud074\ub85c\uc800 \ubc29\uc2dd\uc774 \ub354 \uad8c\uc7a5\ub429\ub2c8\ub2e4.\n- `ToolRuntime`\uc744 \uc0ac\uc6a9\ud558\uba74 `runtime.store`(\uc601\uc18d \uc2a4\ud1a0\uc5b4), `runtime.stream_writer`(\uc2a4\ud2b8\ub9ac\ubc0d), `runtime.context`(\ubd88\ubcc0 \ucee8\ud14d\uc2a4\ud2b8) \ub4f1\ub3c4 \ud568\uaed8 \ud65c\uc6a9\ud560 \uc218 \uc788\uc5b4 \uc720\uc5f0\ud569\ub2c8\ub2e4.\n- \ud568\uc218 \uc2dc\uadf8\ub2c8\ucc98\uc5d0 \ud0c0\uc785 \ud78c\ud2b8/\uc2a4\ud0a4\ub9c8(`args_schema`)\ub294 \ud544\uc218\uc774\uba70, \uc608\uc57d\ub41c \uc778\uc790 \uc774\ub984(`config`, `runtime`) \uc0ac\uc6a9\uc5d0 \uc8fc\uc758\ud558\uc138\uc694 \u2014 `ToolRuntime` \ud0c0\uc785\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc228\uaca8\uc9c4 \ub7f0\ud0c0\uc784 \ud30c\ub77c\ubbf8\ud130\ub85c \ubc1b\uc73c\uc138\uc694.\n\nRelevant docs:\n\n- [Tools (Python) \u2014 Accessing Context & ToolRuntime](https://docs.langchain.com/oss/python/langchain/tools#toolruntime)\n- [Tools (Python) \u2014 Create tools / Custom tool properties](https://docs.langchain.com/oss/python/langchain/tools)"
  },
  {
    "role": "user",
    "id": "c4a09ae2-4989-4bab-b389-2b79d92e29f2",
    "content": "\ub458\ub2e4 \ubcc4\ub860\ub370?"
  },
  {
    "role": "assistant",
    "id": "lc_run--019b384b-d327-7981-a93a-8c0d713f86a5",
    "content": "**\uc54c\uaca0\uc2b5\ub2c8\ub2e4 \u2014 \ub450 \ubc29\uc2dd \ubaa8\ub450 \ub9c8\uc74c\uc5d0 \ub4e4\uc9c0 \uc54a\uc73c\uba74, \uc6b4\uc601\u00b7\ud14c\uc2a4\ud2b8\u00b7\ubcf4\uc548 \uad00\uc810\uc5d0\uc11c \ub354 \uc2e4\uc6a9\uc801\uc778 \ub300\uc548 3\uac00 \uc788\uc2b5\ub2c8\ub2e4.**\n\n\uac01 \ub300\uc548\uc740 `@tool` \ud568\uc218\ub294 \uac00\ubccd\uac8c \uc720\uc9c0\ud558\uace0, \uad8c\ud55c/\ub85c\uae45/\uc5c5\ub370\uc774\ud2b8\ub294 \uc678\ubd80\ub85c \uc704\uc784\ud558\uac70\ub098 \ucd5c\uc18c\ud55c\uc758 \uac12(\uc5d4\ub4dc\ud3ec\uc778\ud2b8/\ud1a0\ud070)\ub9cc \uc8fc\uc785\ud558\ub294 \ubc29\uc2dd\uc785\ub2c8\ub2e4.\n\n## Option A \u2014 \ub0b4\ubd80 \ub9c8\uc774\ud06c\ub85c\uc11c\ube44\uc2a4(\uad8c\uc7a5)\n\ud234\uc740 \ub2e8\uc21c\ud788 \ub0b4\ubd80 HTTP/gRPC \uc5d4\ub4dc\ud3ec\uc778\ud2b8\ub97c \ud638\ucd9c\ud574 \uc2e4\uc81c \ube44\uc988\ub2c8\uc2a4 \ub85c\uc9c1(\uad8c\ud55c \uac80\uc0ac, \uc0c9\uc778 \uc870\ud68c \ub4f1)\uc744 \uc704\uc784\ud569\ub2c8\ub2e4. \uc911\uc559\ud654\ub85c \ubcf4\uc548\u00b7\ub85c\uae45\u00b7\ubc84\uc804\uad00\ub9ac\uac00 \uc26c\uc6cc\uc9d1\ub2c8\ub2e4.\n\n```python\n# tool -> internal API \ud638\ucd9c\nfrom langchain.tools import tool\nimport httpx, os\n\n@tool(\"nymity_research\", args_schema=NymityResearchToolInput, response_format=\"content_and_artifact\")\nasync def nymity_research(step_title: str, step_description: str, query: str) -> tuple[str, dict]:\n    # \ub0b4\ubd80 \uc11c\ube44\uc2a4\uc5d0 \ubaa8\ub4e0 \uac80\uc99d/\ub85c\uc9c1 \uc704\uc784\n    async with httpx.AsyncClient() as client:\n        resp = await client.post(\n            os.environ[\"NYMITY_API_URL\"] + \"/search\",\n            json={\"title\": step_title, \"description\": step_description, \"query\": query},\n            headers={\"Authorization\": f\"Bearer {os.environ['NYMITY_API_KEY']}\"}\n        )\n    if resp.status_code == 403:\n        return get_tool_access_denied_response(\"nymity_research\"), {\"no_access\": True}\n    resp.raise_for_status()\n    return resp.json(), {}\n```\n\n## Option B \u2014 \ub7f0\ud0c0\uc784 \ucee8\ud14d\uc2a4\ud2b8\uc5d0 \ucd5c\uc18c \uc815\ubcf4\ub9cc \uc8fc\uc785\n\ud234\uc5d0 \uc11c\ube44\uc2a4 \uac1d\uccb4 \uc804\uccb4\ub97c \uc8fc\uc785\ud558\ub294 \ub300\uc2e0 `runtime.context`\uc5d0 `base_url`/`api_key` \uac19\uc740 \ucd5c\uc18c\uac12\ub9cc \uc804\ub2ec\ud558\uace0 \ud234 \ub0b4\ubd80\uc5d0\uc11c \ud638\ucd9c\ud569\ub2c8\ub2e4. \ud14c\uc2a4\ud2b8 \uc2dc\uc810\uc5d0 \uc27d\uac8c \ubaa8\ud0b9 \uac00\ub2a5\ud569\ub2c8\ub2e4.\n\n```python\nfrom langchain.tools import tool, ToolRuntime\nimport httpx\n\n@tool(\"nymity_research\", args_schema=NymityResearchToolInput, response_format=\"content_and_artifact\")\nasync def nymity_research(step_title: str, step_description: str, query: str, runtime: ToolRuntime) -> tuple[str, dict]:\n    base = runtime.context.nymity_base_url\n    key = runtime.context.nymity_api_key\n    async with httpx.AsyncClient() as client:\n        r = await client.post(f\"{base}/search\", json={\"q\": query}, headers={\"Authorization\": f\"Bearer {key}\"})\n    # \uc751\ub2f5 \ucc98\ub9ac...\n    return r.json(), {}\n```\n\n## Option C \u2014 \uac00\ubcbc\uc6b4 \uc5b4\ub311\ud130(\ud504\ub85c\uc138\uc2a4 \ub0b4 \uce90\uc2dc\ub41c \ud074\ub77c\uc774\uc5b8\ud2b8)\n\uc11c\ube44\uc2a4 \ud074\ub77c\uc774\uc5b8\ud2b8\ub97c \uc804\uc5ed single-instance(\uc9c0\uc5f0 \uc0dd\uc131)\ub85c \ub450\uace0, \ud234\uc740 \uadf8 \uc5b4\ub311\ud130\ub97c \ud638\ucd9c\ub9cc \ud569\ub2c8\ub2e4. \uac1d\uccb4 \uc8fc\uc785/\ud074\ub85c\uc800\ubcf4\ub2e4 \uac04\ub2e8\ud558\uace0 \uc131\ub2a5\uc0c1 \uc774\uc810\uc774 \uc788\uc2b5\ub2c8\ub2e4(\ub2e8 \uc11c\ubc84 \uc885\ub8cc \uc2dc \ud074\ub77c\uc774\uc5b8\ud2b8 \ub2eb\uae30 \ud544\uc694).\n\n```python\nfrom functools import lru_cache\nimport httpx, os\nfrom langchain.tools import tool\n\n@lru_cache()\ndef get_client():\n    return httpx.AsyncClient(base_url=os.environ[\"NYMITY_API_URL\"], headers={\"Authorization\": f\"Bearer {os.environ['NYMITY_API_KEY']}\"})\n\n@tool(\"nymity_research\", args_schema=NymityResearchToolInput, response_format=\"content_and_artifact\")\nasync def nymity_research(step_title: str, step_description: str, query: str):\n    client = get_client()\n    resp = await client.post(\"/search\", json={\"q\": query})\n    resp.raise_for_status()\n    return resp.json(), {}\n# \uc8fc\uc758: \ud504\ub85c\uc138\uc2a4 \uc885\ub8cc \uc2dc client.aclose() \ud638\ucd9c \ud544\uc694\n```\n\n- \ub9c8\uc774\ud06c\ub85c\uc11c\ube44\uc2a4 \ubc29\uc2dd\uc740 \uad8c\ud55c/\uac10\uc0ac/\uce90\uc2dc \uc815\ucc45\uc744 \uc911\uc559\uc5d0\uc11c \uad00\ub9ac\ud560 \uc218 \uc788\uc5b4 \uaddc\uc81c\u00b7\ubcf4\uc548 \uc694\uac74\uc5d0 \uc720\ub9ac\ud569\ub2c8\ub2e4.\n- \ub7f0\ud0c0\uc784 \ucee8\ud14d\uc2a4\ud2b8(\uc5d4\ub4dc\ud3ec\uc778\ud2b8/\ud1a0\ud070) \ubc29\uc2dd\uc740 \uc758\uc874\uc131 \uc8fc\uc785\uc758 \uc7a5\uc810\uc744 \uc0b4\ub9ac\uba74\uc11c \ub3c4\uad6c \uc2dc\uadf8\ub2c8\ucc98\ub97c \ub2e8\uc21c\ud788 \uc720\uc9c0\ud569\ub2c8\ub2e4.\n- \uce90\uc2dc\ub41c \ud074\ub77c\uc774\uc5b8\ud2b8 \ubc29\uc2dd\uc740 \uc131\ub2a5\uc0c1 \uc774\uc810\uc774 \uc788\uc9c0\ub9cc, \uc218\uba85 \uad00\ub9ac(\uc885\ub8cc \uc2dc \ub2eb\uae30)\ub97c \uc2e0\uacbd\uc368\uc57c \ud569\ub2c8\ub2e4.\n\nRelevant docs:\n\n- [Tools (Python) \u2014 Create tools / Accessing Context & ToolRuntime](https://docs.langchain.com/oss/python/langchain/tools)\n- [Isolating Subgraph State When Calling Graphs from Tools](https://support.langchain.com/articles/6131002418-isolating-subgraph-state-when-calling-graphs-from-tools)"
  }
]