[
  {
    "role": "user",
    "id": "7f7fac88-2541-4a2d-bcba-3997dd1ca39b",
    "content": "What is tool in langraph or langchain"
  },
  {
    "role": "assistant",
    "tool_calls": [
      {
        "type": "function",
        "id": "call_qFSBi0VujIidhMjBEUe8KnQG",
        "function": {
          "name": "SearchDocsByLangChain",
          "arguments": "{\"language\": \"python\", \"page_size\": 5, \"query\": \"tools\"}"
        }
      },
      {
        "type": "function",
        "id": "call_FLbA3fadTLm4243aCxnF9duL",
        "function": {
          "name": "search_support_articles",
          "arguments": "{\"collections\": \"OSS (LangChain and LangGraph),LangSmith Studio,SDKs and APIs\"}"
        }
      }
    ],
    "id": "lc_run--019b384d-3db2-7340-a2f9-862a0dac60b9",
    "content": ""
  },
  {
    "role": "tool",
    "name": "SearchDocsByLangChain",
    "tool_call_id": "call_qFSBi0VujIidhMjBEUe8KnQG",
    "id": "4be41f80-94b1-4c42-99f9-b571406f3cad",
    "content": "Result 1:\nTitle: Configure prompt settings\nLink: https://docs.langchain.comlangsmith/managing-model-configurations\nContent: The LangSmith [playground](/langsmith/prompt-engineering-concepts#prompt-playground) enables you to control various settings for your prompts. The **Prompt Settings** window contains:\n\n* [Model configuration](#model-configurations)\n* [Tool settings](#tool-settings)\n* [Prompt formatting](#prompt-formatting)\n\nTo access **Prompt Settings**:\n\n1. Navigate to the **Playground** in the left sidebar.\n2. Under the **Prompts** heading select the gear <Icon icon=\"gear\" iconType=\"solid\" /> icon next to the model name, which will launch the **Prompt Settings** window.\n\n   <div style={{ textAlign: 'center' }}>\n     <img className=\"block dark:hidden\" src=\"https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=6c0f7d7012b1e5295fe545149f955e6b\" alt=\"Model Configuration window in the LangSmith UI, settings for Provider, Model, Temperature, Max Output Tokens, Top P, Presence Penalty, Frequency Penalty, Reasoning Effort, etc.\" data-og-width=\"886\" width=\"886\" data-og-height=\"689\" height=\"689\" data-path=\"langsmith/images/model-config-light.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=280&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=4e3b9ad92f6f14f4e0523bef50199318 280w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=560&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=e538eb740495a8afa8bfc552b13ae294 560w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=840&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=ebe73264e977153c869fd04d1552d09b 840w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=1100&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=2eeb01882056046bc73cc019d674af7e 1100w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=1650&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=8f28fe2fe8054cf0623fb9d17f91966f 1650w, https://mintcdn.com/langchain-5e9cc07a/6r3GRtwWCl4ozaHW/langsmith/images/model-config-light.png?w=2500&fit=max&auto=format&n=6r3GRtwWCl4ozaHW&q=85&s=cf9ad39be3623e73322d123699e73f19 2500w\" />\n\n     <img className=\"hidden dark:block\" src=\"https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=2e9da272c3fc8f7ac958c6e6d1da85e3\" alt=\"Model Configuration window in the LangSmith UI, settings for Provider, Model, Temperature, Max Output Tokens, Top P, Presence Penalty, Frequency Penalty, Reasoning Effort, etc.\" data-og-width=\"881\" width=\"881\" data-og-height=\"732\" height=\"732\" data-path=\"langsmith/images/model-config-dark.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=280&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=652fb75a4682cfc813743a1260764e59 280w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=560&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=02c980a8387f3d69a5870660b1668080 560w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=840&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=ee633c06056fa7ad46ea58a179afa169 840w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=1100&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=f62a35ed726b5f89c156a40c9ea76f2c 1100w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=1650&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=18114575db8e6c7ce928763ddcb88c12 1650w, https://mintcdn.com/langchain-5e9cc07a/ppc8uxWc01j4q7Ia/langsmith/images/model-config-dark.png?w=2500&fit=max&auto=format&n=ppc8uxWc01j4q7Ia&q=85&s=ab24dc4975def52db55c4896ead5b77c 2500w\" />\n   </div>\n\n## Model configurations\n\nModel configurations define the parameters your prompt runs against. In the LangSmith Playground, you can save and manage these configurations, which allows you to reuse your preferred settings across prompts and sessions. For details on specific settings, refer to your model provider\u2019s documentation (for example, [Anthropic](https://platform.claude.com/docs/en/api/messages), [OpenAI](https://platform.openai.com/docs/api-reference/responses/create)).\n\n### Create saved configurations\n\n1. In the **Model Configurations** tab, adjust the model configuration as needed\u2014you can select a [saved configuration to edit](#edit-configurations).\n2. Click the **Save As** button in the top bar.\n3. Enter a name and optional description for your configuration and confirm.\n4. Now that you've saved the configuration, anyone in your organization's [workspace](/langsmith/administration-overview#workspaces) can access it. All saved configurations are available in the **Model Configuration** dropdown.\n5. Once you have created a saved configuration, you can set it as your default, so any new prompt you create will automatically use this configuration. To set a configuration as your default, click the **Set as default** <Icon icon=\"thumbtack\" iconType=\"solid\" /> icon next to the model name in the dropdown.\n\n### Edit configurations\n\n1. To rename a saved configuration, or update the description, select the configuration name or description and make the necessary changes.\n2. Update the current configuration's parameters as needed and click the **Save** button at the top.\n\n### Delete configurations\n\n1. Select the configuration you want to remove.\n2. Click the trash <Icon icon=\"trash\" iconType=\"solid\" /> icon to delete it.\n\n### Extra parameters\n\nThe **Extra Parameters** field allows you to pass additional model parameters that aren't directly supported in the LangSmith interface. This is particularly useful in two scenarios:\n\n1. When model providers release new parameters that haven't yet been integrated into the LangSmith interface. You can specify these parameters in JSON format to use them right away. For example:\n\n   ```json  theme={null}\n   {\n       \"reasoning_effort\": \"medium\"\n   }\n   ```\n\n2. When troubleshooting parameter-related errors in the playground, such as:\n\n   ```\n   TypeError: AsyncCompletions.create() got an unexpected keyword argument 'max_concurrency'\n   ```\n\n   If you receive an error about unnecessary parameters (which is more common when using [LangChain JS](/oss/python/langchain/overview) for run tracing), you can use this field to remove the extra parameters.\n\n## Tool settings\n\n[*Tools*](/langsmith/prompt-engineering-concepts#tools) enable your LLM to perform tasks like searching the web, looking up information, and so on. In the **Tools Settings** tab, you can manage the ways your LLM uses and accesses the tools you have defined in your prompt, including:\n\n* **Parallel Tool Calls**: Calling multiple tools in parallel when appropriate. This allows the model to gather information from different sources simultaneously. (Dependent on model support for parallel execution.)\n* **Tool Choice**: Select the tools that the model can access. For more details, refer to [Use tools in a prompt](/langsmith/use-tools).\n\n## Prompt formatting\n\nThe **Prompt Format** tab allows you to specify:\n\n* The **Prompt type**. For details on chat and completion prompts, refer to [Prompt engineering](/langsmith/prompt-engineering-concepts#chat-vs-completion) concepts.\n* The **Template format**. For details on prompt templating and using variables, refer to [F-string vs. mustache](/langsmith/prompt-engineering-concepts##f-string-vs-mustache).\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/managing-model-configurations.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 2:\nTitle: Tools and Toolkits\nLink: https://docs.langchain.comoss/javascript/integrations/tools/index\nContent: [Tools](/oss/javascript/langchain/tools) are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models.\n\nA [toolkit](/oss/javascript/langchain/tools#toolkits) is a collection of tools meant to be used together.\n\n## Integration Platforms\n\nThe following platforms provide access to multiple tools and services through a unified interface:\n\n| Tool/Toolkit                                            | Number of Integrations | Pricing             | Key Features                                               |\n| ------------------------------------------------------- | ---------------------- | ------------------- | ---------------------------------------------------------- |\n| [Composio](/oss/javascript/integrations/tools/composio) | 500+                   | Free tier available | OAuth handling, event-driven workflows, multi-user support |\n\n## All Tools and Toolkits\n\n<Columns cols={3}>\n  <Card title=\"Azure Container Apps Dynamic Sessions\" icon=\"link\" href=\"/oss/javascript/integrations/tools/azure_dynamic_sessions\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Connery Action Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/connery\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Composio\" icon=\"link\" href=\"/oss/javascript/integrations/tools/composio\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Dall-E Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/dalle\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Decodo Tools\" icon=\"link\" href=\"/oss/javascript/integrations/tools/decodo\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Discord Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/discord_tool\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"DuckDuckGoSearch\" icon=\"link\" href=\"/oss/javascript/integrations/tools/duckduckgo_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"ExaSearchResults\" icon=\"link\" href=\"/oss/javascript/integrations/tools/exa_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"FalkorDB\" icon=\"link\" href=\"/oss/javascript/integrations/tools/falkordb\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Gmail Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_gmail\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"GOAT\" icon=\"link\" href=\"/oss/javascript/integrations/tools/goat\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Calendar Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_calendar\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Places Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_places\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Routes Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_routes\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Scholar\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_scholar\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Google Trends Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/google_trends\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"JigsawStack Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/jigsawstack\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Agent with AWS Lambda\" icon=\"link\" href=\"/oss/javascript/integrations/tools/lambda_agent\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Python interpreter tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/pyinterpreter\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"SearchApi tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/searchapi\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Searxng Search tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/searxng\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"SerpAPI\" icon=\"link\" href=\"/oss/javascript/integrations/tools/serpapi\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"StackExchange Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/stackexchange\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Stagehand AI Web Automation Toolkit\" icon=\"link\" href=\"/oss/javascript/integrations/tools/stagehand\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Crawl\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_crawl\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Extract\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_extract\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Map\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_map\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Tavily Search\" icon=\"link\" href=\"/oss/javascript/integrations/tools/tavily_search\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Web Browser Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/webbrowser\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"Wikipedia tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/wikipedia\" arrow=\"true\" cta=\"View guide\" />\n\n  <Card title=\"WolframAlpha Tool\" icon=\"link\" href=\"/oss/javascript/integrations/tools/wolframalpha\" arrow=\"true\" cta=\"View guide\" />\n</Columns>\n\n<Info>\n  If you'd like to write your own tool, see [this how-to](/oss/javascript/langchain/tools#customize-tool-properties). If you'd like to contribute an integration, see [Contributing integrations](/oss/javascript/contributing#add-a-new-integration).\n</Info>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/tools/index.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 3:\nTitle: Tools\nLink: https://docs.langchain.comoss/javascript/langchain/tools\nContent: Many AI applications interact with users via natural language. However, some use cases require models to interface directly with external systems\u2014such as APIs, databases, or file systems\u2014using structured input.\n\nTools are components that [agents](/oss/javascript/langchain/agents) call to perform actions. They extend model capabilities by letting them interact with the world through well-defined inputs and outputs.\n\nTools encapsulate a callable function and its input schema. These can be passed to compatible [chat models](/oss/javascript/langchain/models), allowing the model to decide whether to invoke a tool and with what arguments. In these scenarios, tool calling enables models to generate requests that conform to a specified input schema.\n\n<Note>\n  **Server-side tool use**\n\n  Some chat models (e.g., [OpenAI](/oss/javascript/integrations/chat/openai), [Anthropic](/oss/javascript/integrations/chat/anthropic), and [Gemini](/oss/javascript/integrations/chat/google_generative_ai)) feature [built-in tools](/oss/javascript/langchain/models#server-side-tool-use) that are executed server-side, such as web search and code interpreters. Refer to the [provider overview](/oss/javascript/integrations/providers/overview) to learn how to access these tools with your specific chat model.\n</Note>\n\n## Create tools\n\n### Basic tool definition\n\nThe simplest way to create a tool is by importing the `tool` function from the `langchain` package. You can use [zod](https://zod.dev/) to define the tool's input schema:\n\n```ts  theme={null}\nimport * as z from \"zod\"\nimport { tool } from \"langchain\"\n\nconst searchDatabase = tool(\n  ({ query, limit }) => `Found ${limit} results for '${query}'`,\n  {\n    name: \"search_database\",\n    description: \"Search the customer database for records matching the query.\",\n    schema: z.object({\n      query: z.string().describe(\"Search terms to look for\"),\n      limit: z.number().describe(\"Maximum number of results to return\"),\n    }),\n  }\n);\n```\n\n## Accessing Context\n\n<Info>\n  **Why this matters:** Tools are most powerful when they can access agent state, runtime context, and long-term memory. This enables tools to make context-aware decisions, personalize responses, and maintain information across conversations.\n\n  The runtime context provides a structured way to supply runtime data, such as DB connections, user IDs, or config, into your tools. This avoids global state and keeps tools testable and reusable.\n</Info>\n\n#### Context\n\nTools can access an agent's runtime context through the `config` parameter:\n\n```ts  theme={null}\nimport * as z from \"zod\"\nimport { ChatOpenAI } from \"@langchain/openai\"\nimport { createAgent } from \"langchain\"\n\nconst getUserName = tool(\n  (_, config) => {\n    return config.context.user_name\n  },\n  {\n    name: \"get_user_name\",\n    description: \"Get the user's name.\",\n    schema: z.object({}),\n  }\n);\n\nconst contextSchema = z.object({\n  user_name: z.string(),\n});\n\nconst agent = createAgent({\n  model: new ChatOpenAI({ model: \"gpt-4o\" }),\n  tools: [getUserName],\n  contextSchema,\n});\n\nconst result = await agent.invoke(\n  {\n    messages: [{ role: \"user\", content: \"What is my name?\" }]\n  },\n  {\n    context: { user_name: \"John Smith\" }\n  }\n);\n```\n\n#### Memory (Store)\n\nAccess persistent data across conversations using the store. The store is accessed via `config.store` and allows you to save and retrieve user-specific or application-specific data.\n\n```ts expandable theme={null}\nimport * as z from \"zod\";\nimport { createAgent, tool } from \"langchain\";\nimport { InMemoryStore } from \"@langchain/langgraph\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nconst store = new InMemoryStore();\n\n// Access memory\nconst getUserInfo = tool(\n  async ({ user_id }) => {\n    const value = await store.get([\"users\"], user_id);\n    console.log(\"get_user_info\", user_id, value);\n    return value;\n  },\n  {\n    name: \"get_user_info\",\n    description: \"Look up user info.\",\n    schema: z.object({\n      user_id: z.string(),\n    }),\n  }\n);\n\n// Update memory\nconst saveUserInfo = tool(\n  async ({ user_id, name, age, email }) => {\n    console.log(\"save_user_info\", user_id, name, age, email);\n    await store.put([\"users\"], user_id, { name, age, email });\n    return \"Successfully saved user info.\";\n  },\n  {\n    name: \"save_user_info\",\n    description: \"Save user info.\",\n    schema: z.object({\n      user_id: z.string(),\n      name: z.string(),\n      age: z.number(),\n      email: z.string(),\n    }),\n  }\n);\n\nconst agent = createAgent({\n  model: new ChatOpenAI({ model: \"gpt-4o\" }),\n  tools: [getUserInfo, saveUserInfo],\n  store,\n});\n\n// First session: save user info\nawait agent.invoke({\n  messages: [\n    {\n      role: \"user\",\n      content: \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\",\n    },\n  ],\n});\n\n// Second session: get user info\nconst result = await agent.invoke({\n  messages: [\n    { role: \"user\", content: \"Get user info for user with id 'abc123'\" },\n  ],\n});\n\nconsole.log(result);\n// Here is the user info for user with ID \"abc123\":\n// - Name: Foo\n// - Age: 25\n// - Email: foo@langchain.dev\n```\n\n#### Stream Writer\n\nStream custom updates from tools as they execute using `config.streamWriter`. This is useful for providing real-time feedback to users about what a tool is doing.\n\n```ts  theme={null}\nimport * as z from \"zod\";\nimport { tool } from \"langchain\";\n\nconst getWeather = tool(\n  ({ city }, config) => {\n    const writer = config.streamWriter;\n\n    // Stream custom updates as the tool executes\n    writer(`Looking up data for city: ${city}`);\n    writer(`Acquired data for city: ${city}`);\n\n    return `It's always sunny in ${city}!`;\n  },\n  {\n    name: \"get_weather\",\n    description: \"Get weather for a given city.\",\n    schema: z.object({\n      city: z.string(),\n    }),\n  }\n);\n```\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/tools.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 4:\nTitle: Google\nLink: https://docs.langchain.comoss/python/integrations/providers/google\nContent: Tools\nGoogle Search Perform web searches using Google Custom Search Engine (CSE). Google Drive Tools for interacting with Google Drive. Google Finance Query financial data. Google Jobs Query job listings. Google Lens Perform visual searches. Google Places Search for places information. Google Scholar Search academic papers. Google Trends Query Google Trends data.\n\nToolkits\nCollections of tools for specific Google services. Gmail Toolkit to create, get, search, and send emails using the Gmail API.\n\nYouTube\nSearch tool Search YouTube videos without the official API. Audio loader Download audio from YouTube videos. Transcripts loader Load video transcripts. Edit the source of this page on GitHub. Connect these docs programmatically to Claude, VSCode, and more via MCP for real-time answers.\n\n---\n\nResult 5:\nTitle: Tools\nLink: https://docs.langchain.comoss/python/langchain/tools\nContent: Many AI applications interact with users via natural language. However, some use cases require models to interface directly with external systems\u2014such as APIs, databases, or file systems\u2014using structured input.\n\nTools are components that [agents](/oss/python/langchain/agents) call to perform actions. They extend model capabilities by letting them interact with the world through well-defined inputs and outputs.\n\nTools encapsulate a callable function and its input schema. These can be passed to compatible [chat models](/oss/python/langchain/models), allowing the model to decide whether to invoke a tool and with what arguments. In these scenarios, tool calling enables models to generate requests that conform to a specified input schema.\n\n<Note>\n  **Server-side tool use**\n\n  Some chat models (e.g., [OpenAI](/oss/python/integrations/chat/openai), [Anthropic](/oss/python/integrations/chat/anthropic), and [Gemini](/oss/python/integrations/chat/google_generative_ai)) feature [built-in tools](/oss/python/langchain/models#server-side-tool-use) that are executed server-side, such as web search and code interpreters. Refer to the [provider overview](/oss/python/integrations/providers/overview) to learn how to access these tools with your specific chat model.\n</Note>\n\n## Create tools\n\n### Basic tool definition\n\nThe simplest way to create a tool is with the [`@tool`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.tool) decorator. By default, the function's docstring becomes the tool's description that helps the model understand when to use it:\n\n```python  theme={null}\nfrom langchain.tools import tool\n\n@tool\ndef search_database(query: str, limit: int = 10) -> str:\n    \"\"\"Search the customer database for records matching the query.\n\n    Args:\n        query: Search terms to look for\n        limit: Maximum number of results to return\n    \"\"\"\n    return f\"Found {limit} results for '{query}'\"\n```\n\nType hints are **required** as they define the tool's input schema. The docstring should be informative and concise to help the model understand the tool's purpose.\n\n### Customize tool properties\n\n#### Custom tool name\n\nBy default, the tool name comes from the function name. Override it when you need something more descriptive:\n\n```python  theme={null}\n@tool(\"web_search\")  # Custom name\ndef search(query: str) -> str:\n    \"\"\"Search the web for information.\"\"\"\n    return f\"Results for: {query}\"\n\nprint(search.name)  # web_search\n```\n\n#### Custom tool description\n\nOverride the auto-generated tool description for clearer model guidance:\n\n```python  theme={null}\n@tool(\"calculator\", description=\"Performs arithmetic calculations. Use this for any math problems.\")\ndef calc(expression: str) -> str:\n    \"\"\"Evaluate mathematical expressions.\"\"\"\n    return str(eval(expression))\n```\n\n### Advanced schema definition\n\nDefine complex inputs with Pydantic models or JSON schemas:\n\n<CodeGroup>\n  ```python Pydantic model theme={null}\n  from pydantic import BaseModel, Field\n  from typing import Literal\n\n  class WeatherInput(BaseModel):\n      \"\"\"Input for weather queries.\"\"\"\n      location: str = Field(description=\"City name or coordinates\")\n      units: Literal[\"celsius\", \"fahrenheit\"] = Field(\n          default=\"celsius\",\n          description=\"Temperature unit preference\"\n      )\n      include_forecast: bool = Field(\n          default=False,\n          description=\"Include 5-day forecast\"\n      )\n\n  @tool(args_schema=WeatherInput)\n  def get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n      \"\"\"Get current weather and optional forecast.\"\"\"\n      temp = 22 if units == \"celsius\" else 72\n      result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n      if include_forecast:\n          result += \"\\nNext 5 days: Sunny\"\n      return result\n  ```\n\n  ```python JSON Schema theme={null}\n  weather_schema = {\n      \"type\": \"object\",\n      \"properties\": {\n          \"location\": {\"type\": \"string\"},\n          \"units\": {\"type\": \"string\"},\n          \"include_forecast\": {\"type\": \"boolean\"}\n      },\n      \"required\": [\"location\", \"units\", \"include_forecast\"]\n  }\n\n  @tool(args_schema=weather_schema)\n  def get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n      \"\"\"Get current weather and optional forecast.\"\"\"\n      temp = 22 if units == \"celsius\" else 72\n      result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n      if include_forecast:\n          result += \"\\nNext 5 days: Sunny\"\n      return result\n  ```\n</CodeGroup>\n\n### Reserved argument names\n\nThe following parameter names are reserved and cannot be used as tool arguments. Using these names will cause runtime errors.\n\n| Parameter name | Purpose                                                                |\n| -------------- | ---------------------------------------------------------------------- |\n| `config`       | Reserved for passing `RunnableConfig` to tools internally              |\n| `runtime`      | Reserved for `ToolRuntime` parameter (accessing state, context, store) |\n\nTo access runtime information, use the [`ToolRuntime`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.ToolRuntime) parameter instead of naming your own arguments `config` or `runtime`.\n\n## Accessing Context\n\n<Info>\n  **Why this matters:** Tools are most powerful when they can access agent state, runtime context, and long-term memory. This enables tools to make context-aware decisions, personalize responses, and maintain information across conversations.\n\n  Runtime context provides a way to inject dependencies (like database connections, user IDs, or configuration) into your tools at runtime, making them more testable and reusable.\n</Info>\n\nTools can access runtime information through the `ToolRuntime` parameter, which provides:\n\n* **State** - Mutable data that flows through execution (e.g., messages, counters, custom fields)\n* **Context** - Immutable configuration like user IDs, session details, or application-specific configuration\n* **Store** - Persistent long-term memory across conversations\n* **Stream Writer** - Stream custom updates as tools execute\n* **Config** - `RunnableConfig` for the execution\n* **Tool Call ID** - ID of the current tool call\n\n```mermaid  theme={null}\ngraph LR\n    %% Runtime Context\n    subgraph \"\ud83d\udd27 Tool Runtime Context\"\n        A[Tool Call] --> B[ToolRuntime]\n        B --> C[State Access]\n        B --> D[Context Access]\n        B --> E[Store Access]\n        B --> F[Stream Writer]\n    end\n\n    %% Available Resources\n    subgraph \"\ud83d\udcca Available Resources\"\n        C --> G[Messages]\n        C --> H[Custom State]\n        D --> I[User ID]\n        D --> J[Session Info]\n        E --> K[Long-term Memory]\n        E --> L[User Preferences]\n    end\n\n    %% Tool Capabilities\n    subgraph \"\u26a1 Enhanced Tool Capabilities\"\n        M[Context-Aware Tools]\n        N[Stateful Tools]\n        O[Memory-Enabled Tools]\n        P[Streaming Tools]\n    end\n\n    %% Connections\n    G --> M\n    H --> N\n    I --> M\n    J --> M\n    K --> O\n    L --> O\n    F --> P\n```\n\n### `ToolRuntime`\n\nUse `ToolRuntime` to access all runtime information in a single parameter. Simply add `runtime: ToolRuntime` to your tool signature, and it will be automatically injected without being exposed to the LLM.\n\n<Info>\n  **`ToolRuntime`**: A unified parameter that provides tools access to state, context, store, streaming, config, and tool call ID. This replaces the older pattern of using separate [`InjectedState`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedState), [`InjectedStore`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.tool_node.InjectedStore), [`get_runtime`](https://reference.langchain.com/python/langgraph/runtime/#langgraph.runtime.get_runtime), and [`InjectedToolCallId`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.InjectedToolCallId) annotations.\n\n  The runtime automatically provides these capabilities to your tool functions without you having to pass them explicitly or use global state.\n</Info>\n\n**Accessing state:**\n\nTools can access the current graph state using `ToolRuntime`:\n\n```python  theme={null}\nfrom langchain.tools import tool, ToolRuntime\n\n# Access the current conversation state\n@tool\ndef summarize_conversation(\n    runtime: ToolRuntime\n) -> str:\n    \"\"\"Summarize the conversation so far.\"\"\"\n    messages = runtime.state[\"messages\"]\n\n    human_msgs = sum(1 for m in messages if m.__class__.__name__ == \"HumanMessage\")\n    ai_msgs = sum(1 for m in messages if m.__class__.__name__ == \"AIMessage\")\n    tool_msgs = sum(1 for m in messages if m.__class__.__name__ == \"ToolMessage\")\n\n    return f\"Conversation has {human_msgs} user messages, {ai_msgs} AI responses, and {tool_msgs} tool results\"\n\n# Access custom state fields\n@tool\ndef get_user_preference(\n    pref_name: str,\n    runtime: ToolRuntime  # ToolRuntime parameter is not visible to the model\n) -> str:\n    \"\"\"Get a user preference value.\"\"\"\n    preferences = runtime.state.get(\"user_preferences\", {})\n    return preferences.get(pref_name, \"Not set\")\n```\n\n<Warning>\n  The `runtime` parameter is hidden from the model. For the example above, the model only sees `pref_name` in the tool schema - `runtime` is *not* included in the request.\n</Warning>\n\n**Updating state:**\n\nUse [`Command`](https://reference.langchain.com/python/langgraph/types/#langgraph.types.Command) to update the agent's state or control the graph's execution flow:\n\n```python  theme={null}\nfrom langgraph.types import Command\nfrom langchain.messages import RemoveMessage\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES\nfrom langchain.tools import tool, ToolRuntime\n\n# Update the conversation history by removing all messages\n@tool\ndef clear_conversation() -> Command:\n    \"\"\"Clear the conversation history.\"\"\"\n\n    return Command(\n        update={\n            \"messages\": [RemoveMessage(id=REMOVE_ALL_MESSAGES)],\n        }\n    )\n\n# Update the user_name in the agent state\n@tool\ndef update_user_name(\n    new_name: str,\n    runtime: ToolRuntime\n) -> Command:\n    \"\"\"Update the user's name.\"\"\"\n    return Command(update={\"user_name\": new_name})\n```\n\n#### Context\n\nAccess immutable configuration and contextual data like user IDs, session details, or application-specific configuration through `runtime.context`.\n\nTools can access runtime context through `ToolRuntime`:\n\n```python  theme={null}\nfrom dataclasses import dataclass\nfrom langchain_openai import ChatOpenAI\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n\nUSER_DATABASE = {\n    \"user123\": {\n        \"name\": \"Alice Johnson\",\n        \"account_type\": \"Premium\",\n        \"balance\": 5000,\n        \"email\": \"alice@example.com\"\n    },\n    \"user456\": {\n        \"name\": \"Bob Smith\",\n        \"account_type\": \"Standard\",\n        \"balance\": 1200,\n        \"email\": \"bob@example.com\"\n    }\n}\n\n@dataclass\nclass UserContext:\n    user_id: str\n\n@tool\ndef get_account_info(runtime: ToolRuntime[UserContext]) -> str:\n    \"\"\"Get the current user's account information.\"\"\"\n    user_id = runtime.context.user_id\n\n    if user_id in USER_DATABASE:\n        user = USER_DATABASE[user_id]\n        return f\"Account holder: {user['name']}\\nType: {user['account_type']}\\nBalance: ${user['balance']}\"\n    return \"User not found\"\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\nagent = create_agent(\n    model,\n    tools=[get_account_info],\n    context_schema=UserContext,\n    system_prompt=\"You are a financial assistant.\"\n)\n\nresult = agent.invoke(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"What's my current balance?\"}]},\n    context=UserContext(user_id=\"user123\")\n)\n```\n\n#### Memory (Store)\n\nAccess persistent data across conversations using the store. The store is accessed via `runtime.store` and allows you to save and retrieve user-specific or application-specific data.\n\nTools can access and update the store through `ToolRuntime`:\n\n```python expandable theme={null}\nfrom typing import Any\nfrom langgraph.store.memory import InMemoryStore\nfrom langchain.agents import create_agent\nfrom langchain.tools import tool, ToolRuntime\n\n\n# Access memory\n@tool\ndef get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n    \"\"\"Look up user info.\"\"\"\n    store = runtime.store\n    user_info = store.get((\"users\",), user_id)\n    return str(user_info.value) if user_info else \"Unknown user\"\n\n# Update memory\n@tool\ndef save_user_info(user_id: str, user_info: dict[str, Any], runtime: ToolRuntime) -> str:\n    \"\"\"Save user info.\"\"\"\n    store = runtime.store\n    store.put((\"users\",), user_id, user_info)\n    return \"Successfully saved user info.\"\n\nstore = InMemoryStore()\nagent = create_agent(\n    model,\n    tools=[get_user_info, save_user_info],\n    store=store\n)\n\n# First session: save user info\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev\"}]\n})\n\n# Second session: get user info\nagent.invoke({\n    \"messages\": [{\"role\": \"user\", \"content\": \"Get user info for user with id 'abc123'\"}]\n})\n# Here is the user info for user with ID \"abc123\":\n# - Name: Foo\n# - Age: 25\n# - Email: foo@langchain.dev\n```\n\n#### Stream Writer\n\nStream custom updates from tools as they execute using `runtime.stream_writer`. This is useful for providing real-time feedback to users about what a tool is doing.\n\n```python  theme={null}\nfrom langchain.tools import tool, ToolRuntime\n\n@tool\ndef get_weather(city: str, runtime: ToolRuntime) -> str:\n    \"\"\"Get weather for a given city.\"\"\"\n    writer = runtime.stream_writer\n\n    # Stream custom updates as the tool executes\n    writer(f\"Looking up data for city: {city}\")\n    writer(f\"Acquired data for city: {city}\")\n\n    return f\"It's always sunny in {city}!\"\n```\n\n<Note>\n  If you use `runtime.stream_writer` inside your tool, the tool must be invoked within a LangGraph execution context. See [Streaming](/oss/python/langchain/streaming) for more details.\n</Note>\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/tools.mdx)\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n"
  },
  {
    "role": "tool",
    "name": "search_support_articles",
    "tool_call_id": "call_FLbA3fadTLm4243aCxnF9duL",
    "id": "0f6d5678-d529-4c03-8841-bb02ff6f382f",
    "content": "{\n  \"collections\": \"OSS (LangChain and LangGraph),LangSmith Studio,SDKs and APIs\",\n  \"total\": 17,\n  \"articles\": [\n    {\n      \"id\": \"bb651320-775e-4dfa-a054-c955cc3a0d5d\",\n      \"title\": \"Why Do Pydantic\\u00a0date\\u00a0Fields Fail in LangGraph State?\",\n      \"url\": \"https://support.langchain.com/articles/7196116702-why-do-pydantic-date-fields-fail-in-langgraph-state\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"ae959c68-a996-4426-8c8e-ef3fa1dd88cc\",\n      \"title\": \"How do I connect JIRA, Slack, and Confluence MCPs with LangChain?\",\n      \"url\": \"https://support.langchain.com/articles/3473375007-how-do-i-connect-jira-slack-and-confluence-mcps-with-langchain\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"2836b779-a2f5-4058-a994-4fe2502166ca\",\n      \"title\": \"Missing Runs in LangSmith Experiment View with Concurrent Evaluations\",\n      \"url\": \"https://support.langchain.com/articles/8223468578-missing-runs-in-langsmith-experiment-view-with-concurrent-evaluations\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"d55d04fa-c883-4055-b266-343e5157ad31\",\n      \"title\": \"Preserving Trace Hierarchy with Manual RunTree Creation\",\n      \"url\": \"https://support.langchain.com/articles/9515178454-preserving-trace-hierarchy-with-manual-runtree-creation\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"9e06b53a-7b85-4793-b7b6-e179c0c8d815\",\n      \"title\": \"Isolating Subgraph State When Calling Graphs from Tools\",\n      \"url\": \"https://support.langchain.com/articles/6131002418-isolating-subgraph-state-when-calling-graphs-from-tools\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"9ef77ded-7211-4d09-944a-289972726262\",\n      \"title\": \"Why am I getting \\\"Failed to send compressed multipart ingest\\\" errors in LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9901468881-why-am-i-getting-failed-to-send-compressed-multipart-ingest-errors-in-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"e72b134e-bd5a-471d-93ea-8def86caf74a\",\n      \"title\": \"Why do I see inconsistent output formats for the same agent across different traces?\",\n      \"url\": \"https://support.langchain.com/articles/2041161407-why-do-i-see-inconsistent-output-formats-for-the-same-agent-across-different-traces\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"3ea46ebf-6af5-4ce2-b678-1c7d4b82caba\",\n      \"title\": \"Can I reopen a run after calling patch() to write additional data?\",\n      \"url\": \"https://support.langchain.com/articles/9964614152-can-i-reopen-a-run-after-calling-patch-to-write-additional-data\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"32994e7d-a182-41df-9f3d-271adf84fde2\",\n      \"title\": \"How do I filter runs by multiple run IDs using tree filters?\",\n      \"url\": \"https://support.langchain.com/articles/2574288399-how-do-i-filter-runs-by-multiple-run-ids-using-tree-filters\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f5a80963-8fe3-415f-b0e2-04b6f5093f12\",\n      \"title\": \"How do I filter runs by name using the LangSmith SDK?\",\n      \"url\": \"https://support.langchain.com/articles/5601207552-how-do-i-filter-runs-by-name-using-the-langsmith-sdk\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f51b0bb0-b838-40db-baa9-f9099ae34c2f\",\n      \"title\": \"How do I use LangSmith tracing with Cloudflare Workers?\",\n      \"url\": \"https://support.langchain.com/articles/1885761495-how-do-i-use-langsmith-tracing-with-cloudflare-workers\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"d270716f-edc0-49d9-b5d1-497b5d0e4e6d\",\n      \"title\": \"Private Network Access Blocking LangSmith Studio Connection\",\n      \"url\": \"https://support.langchain.com/articles/1897181200-private-network-access-blocking-langsmith-studio-connection\",\n      \"collection\": \"LangSmith Studio\"\n    },\n    {\n      \"id\": \"e2c86d05-b6fd-4bb3-8637-3f6d35c106dd\",\n      \"title\": \"How do I trace Vercel AI SDK calls with LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9620089182-how-do-i-trace-vercel-ai-sdk-calls-with-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"5f2572a3-9086-4d92-8d15-69f7b8e4c8be\",\n      \"title\": \"MCP Server Runtime in Google Colab / Jupyter Notebook\",\n      \"url\": \"https://support.langchain.com/articles/1061688976-mcp-server-runtime-in-google-colab-jupyter-notebook\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"68fbf7da-954d-454e-8ad4-73e1f1f63b74\",\n      \"title\": \"LangSmith Studio vs Agent Chat UI: When to Use What\",\n      \"url\": \"https://support.langchain.com/articles/1353449293-langsmith-studio-vs-agent-chat-ui\",\n      \"collection\": \"LangSmith Studio\"\n    },\n    {\n      \"id\": \"ada8fd1b-4800-434e-8d6f-b5186b170941\",\n      \"title\": \"LangSmith Studio URL Redirects to Error Page\",\n      \"url\": \"https://support.langchain.com/articles/4270790436-langsmith-studio-url-redirects-to-error-page\",\n      \"collection\": \"LangSmith Studio\"\n    },\n    {\n      \"id\": \"45269e32-5322-4a17-8866-da640169d21d\",\n      \"title\": \"How do I export annotated traces in bulk from LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9958349143-how-do-i-export-annotated-traces-in-bulk-from-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    }\n  ],\n  \"note\": \"All articles listed are public and have content. Use IDs to fetch full content.\"\n}"
  },
  {
    "role": "assistant",
    "id": "lc_run--019b384d-5fe0-73f2-9ed5-249c1e3d6a02",
    "content": "**A tool in LangChain/LangGraph is a callable component (a function) that an agent or model can invoke to perform external actions\u2014like calling APIs, querying a database, running code, or reading/writing files.**\n\nTools let the model extend its capabilities by exposing a defined input schema and returning structured outputs; in Python you typically create them with `@tool`, in JavaScript/TypeScript with `tool()`/toolkits, and tools can access runtime/context via `ToolRuntime` so they remain testable and stateful.\n\n```python\nfrom langchain.tools import tool\n\n@tool\ndef search_database(query: str, limit: int = 10) -> str:\n    \"\"\"Search the customer database for records matching the query.\"\"\"\n    # Implementation: run DB query, format results\n    return f\"Found {limit} results for '{query}'\"  # returned value goes back to the agent\n```\n\n## Examples and runtime access\n\nTools can include richer schemas (Pydantic/JSON in Python, zod in JS) and can access runtime/context, store, and streaming via `ToolRuntime` (hidden from the model). This is how a tool can read user-specific context or update persistent memory:\n\n```python\nfrom langchain.tools import tool, ToolRuntime\n\n@tool\ndef get_user_info(user_id: str, runtime: ToolRuntime) -> str:\n    \"\"\"Look up user info from the runtime store.\"\"\"\n    user_info = runtime.store.get((\"users\",), user_id)\n    return str(user_info.value) if user_info else \"Unknown user\"\n```\n\n- Tools are chosen by the model (tool calling) when the model decides a specific external action is needed.\n- Toolkits are collections of related tools (useful for grouping integrations).\n- Some providers offer server-side built-in tools (e.g., web search, code interpreters) that the model can call directly.\n\nRelevant docs:\n\n- [Tools (Python)](https://docs.langchain.com/oss/python/langchain/tools)  \n- [Tools (JavaScript)](https://docs.langchain.com/oss/javascript/langchain/tools)  \n- [Tools and Toolkits (Integrations)](https://docs.langchain.com/oss/javascript/integrations/tools/index)"
  },
  {
    "role": "user",
    "id": "47fc5605-a3f6-47d5-8629-b2494be405eb",
    "content": "What is gmailtool used for"
  },
  {
    "role": "assistant",
    "tool_calls": [
      {
        "type": "function",
        "id": "call_3VdYYN8YjXDFAuXq35kJqwPi",
        "function": {
          "name": "SearchDocsByLangChain",
          "arguments": "{\"language\": \"python\", \"page_size\": 5, \"query\": \"gmail\"}"
        }
      },
      {
        "type": "function",
        "id": "call_3HVwEGo72osb0EbBfsC3vABN",
        "function": {
          "name": "search_support_articles",
          "arguments": "{\"collections\": \"OSS (LangChain and LangGraph),SDKs and APIs\"}"
        }
      }
    ],
    "id": "lc_run--019b384e-9594-70b3-ba15-40d60002a121",
    "content": ""
  },
  {
    "role": "tool",
    "name": "SearchDocsByLangChain",
    "tool_call_id": "call_3VdYYN8YjXDFAuXq35kJqwPi",
    "id": "09ec8630-e776-4350-b097-66a3d5a4834f",
    "content": "Result 1:\nTitle: Essentials\nLink: https://docs.langchain.comlangsmith/agent-builder-essentials\nContent: ## Tools\n\nTools let your agents interact with your apps and services. Your agents can send emails, create calendar events, post messages, search the web, and more. Choose from built-in tools for Gmail, Slack, Google Calendar, GitHub, and many others.\n\nSee [Supported tools](/langsmith/agent-builder-tools) for a complete list.\n\n## Triggers\n\nTriggers define when your agent should start running. You can connect your agent to external tools or time-based schedules, letting it respond automatically to messages, emails, or recurring events.\n\nHere are some popular ways to trigger your agent:\n\n<CardGroup cols={3}>\n  <Card title=\"Slack\" icon=\"slack\">\n    Activate your agent when messages are received in specific Slack channels.\n  </Card>\n\n  <Card title=\"Gmail\" icon=\"envelope\">\n    Trigger your agent when emails are received.\n  </Card>\n\n  <Card title=\"Cron schedules\" icon=\"clock\">\n    Run your agent on a time-based schedule for recurring tasks.\n  </Card>\n</CardGroup>\n\n## Memory and updates\n\nYour agents get smarter over time. They remember important information from previous conversations and can update themselves to work better.\n\n* Memory: Agents remember relevant details from past interactions, so they can make better decisions in future conversations.\n* Self-updates: Agents can add new tools, remove ones they don't need, or adjust their instructions to improve how they work.\n* What stays the same: Agents can't change their name, description, or the triggers that start them.\n\n## Custom models\n\nAgent Builder supports custom models. You can override the default Anthropic or OpenAI model for a specific agent by editing the agent's settings:\n\n1. In the [LangSmith UI](https://smith.langchain.com), navigate to the agent you want to edit.\n2. Click on the <Icon icon=\"gear\" /> settings icon in the top right corner.\n3. In the **Model** section, select **+ Add custom model**.\n4. Enter the model ID, display name, base URL, and API key name and value.\n5. Click **Save**.\n\n<Note>\n  Custom models may not perform as well as built-in models. Test your custom model before using it in production.\n</Note>\n\n## Sub-agents\n\nBuild complex agents by breaking big tasks into smaller, specialized helpers. Think of sub-agents as a team of specialists\u2014each one handles a specific part of the job while working together with your main agent.\n\nThis approach makes it easier to build sophisticated systems. Instead of one agent trying to do everything, you can have specialized helpers that each excel at their part of the task.\n\nHere are some ways you might use sub-agents:\n\n* Split into sub-tasks: Have one agent fetch data, another summarize it, and a third format the results.\n* Specialized tools: Give different agents access to different tools based on what they need to do.\n* Independent work: Let sub-agents work on their own, then bring their results back to the main agent.\n\n## Human in the loop\n\nStay in control of important decisions. You can set up your agent to pause and ask for your approval before taking certain actions. This ensures your agent handles most tasks automatically, while you retain oversight.\n\n### Setting up approval steps\n\n<Steps>\n  <Step title=\"Select a tool\">\n    When setting up your agent, choose the tool or action you want to review before it runs.\n  </Step>\n\n  <Step title=\"Turn on approval\">\n    Find the approval option for that tool and switch it on.\n  </Step>\n\n  <Step title=\"Agent waits for you\">\n    When your agent reaches that step, it will pause and wait for your approval before continuing.\n  </Step>\n</Steps>\n\n### What you can do when your agent pauses\n\nWhen your agent stops to ask for approval, you have three options:\n\n<CardGroup cols={3}>\n  <Card title=\"Accept\" icon=\"check\">\n    Give the green light and let your agent proceed with its plan.\n  </Card>\n\n  <Card title=\"Edit\" icon=\"pen-to-square\">\n    Modify the agent's message or parameters before allowing it to continue.\n  </Card>\n\n  <Card title=\"Send feedback\" icon=\"comment\">\n    Share feedback to help your agent learn and improve.\n  </Card>\n</CardGroup>\n\n## Next steps\n\n* [Set up your workspace](/langsmith/agent-builder-setup)\n* [Connect apps and services](/langsmith/agent-builder-tools)\n* [Use remote connections](/langsmith/agent-builder-mcp-framework)\n* [Choose between workspace and private agents](/langsmith/agent-builder-workspace-vs-private)\n* [Call agents from your app](/langsmith/agent-builder-code)\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/agent-builder-essentials.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 2:\nTitle: LangSmith Tool Server\nLink: https://docs.langchain.comlangsmith/agent-builder-mcp-framework\nContent: The LangSmith Tool Server is a standalone MCP framework for building and deploying tools with built-in authentication and authorization. Use the Tool Server when you want to:\n\n* [Create custom tools](#create-a-custom-toolkit) that integrate with LangSmith's [Agent Auth](/langsmith/agent-auth) for OAuth authentication\n* [Build an MCP gateway](#use-as-an-mcp-gateway) for agents you're building yourself (outside of Agent Builder)\n\n<Note>\n  If you're using [Agent Builder](/langsmith/agent-builder), you don't need to interact with the Tool Server directly. Agent Builder provides [built-in tools](/langsmith/agent-builder-tools) and supports [remote MCP servers](/langsmith/agent-builder-tools#using-remote-mcp-servers) without requiring Tool Server setup.\n\n  However, you can configure the associated tool server instance as an MCP server, which will allow you to use your custom MCP servers in your agent.\n</Note>\n\nDownload the [PyPi package](https://pypi.org/project/langsmith-tool-server/) to get started.\n\n## Create a custom toolkit\n\nInstall the LangSmith Tool Server and LangChain CLI:\n\n```bash  theme={null}\npip install langsmith-tool-server\npip install langchain-cli-v2\n```\n\nCreate a new toolkit:\n\n```bash  theme={null}\nlangchain tools new my-toolkit\ncd my-toolkit\n```\n\nThis creates a toolkit with the following structure:\n\n```\nmy-toolkit/\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 toolkit.toml\n\u2514\u2500\u2500 my_toolkit/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 auth.py\n    \u2514\u2500\u2500 tools/\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 ...\n```\n\nDefine your tools using the `@tool` decorator:\n\n```python  theme={null}\nfrom langsmith_tool_server import tool\n\n@tool\ndef hello(name: str) -> str:\n    \"\"\"Greet someone by name.\"\"\"\n    return f\"Hello, {name}!\"\n\n@tool\ndef add(x: int, y: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    return x + y\n\nTOOLS = [hello, add]\n```\n\nRun the server:\n\n```bash  theme={null}\nlangchain tools serve\n```\n\nYour tool server will start on `http://localhost:8000`.\n\n## Call tools via MCP protocol\n\nBelow is an example that lists available tools and calls the `add` tool:\n\n```python  theme={null}\nimport asyncio\nimport aiohttp\n\nasync def mcp_request(url: str, method: str, params: dict = None):\n    async with aiohttp.ClientSession() as session:\n        payload = {\"jsonrpc\": \"2.0\", \"method\": method, \"params\": params or {}, \"id\": 1}\n        async with session.post(f\"{url}/mcp\", json=payload) as response:\n            return await response.json()\n\nasync def main():\n    url = \"http://localhost:8000\"\n\n    tools = await mcp_request(url, \"tools/list\")\n    print(f\"Tools: {tools}\")\n\n    result = await mcp_request(url, \"tools/call\", {\"name\": \"add\", \"arguments\": {\"a\": 5, \"b\": 3}})\n    print(f\"Result: {result}\")\n\nasyncio.run(main())\n```\n\n## Use as an MCP gateway\n\nThe LangSmith Tool Server can act as an MCP gateway, aggregating tools from multiple MCP servers into a single endpoint. Configure MCP servers in your `toolkit.toml`:\n\n```toml  theme={null}\n[toolkit]\nname = \"my-toolkit\"\ntools = \"./my_toolkit/__init__.py:TOOLS\"\n\n[[mcp_servers]]\nname = \"weather\"\ntransport = \"streamable_http\"\nurl = \"http://localhost:8001/mcp/\"\n\n[[mcp_servers]]\nname = \"math\"\ntransport = \"stdio\"\ncommand = \"python\"\nargs = [\"-m\", \"mcp_server_math\"]\n```\n\nAll tools from connected MCP servers are exposed through your server's `/mcp` endpoint. MCP tools are prefixed with their server name to avoid conflicts (e.g., `weather_get_forecast`, `math_add`).\n\n## Authenticate\n\n### OAuth for third-party APIs\n\nFor tools that need to access third-party APIs (like Google, GitHub, Slack, etc.), you can use OAuth authentication with [Agent Auth](/langsmith/agent-auth).\n\nBefore using OAuth in your tools, you'll need to configure an OAuth provider in your LangSmith workspace settings. See the [Agent Auth documentation](/langsmith/agent-auth) for setup instructions.\n\nOnce configured, specify the `auth_provider` in your tool decorator:\n\n```python  theme={null}\nfrom langsmith_tool_server import tool, Context\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\n\n@tool(\n    auth_provider=\"google\",\n    scopes=[\"https://www.googleapis.com/auth/gmail.readonly\"],\n    integration=\"gmail\"\n)\nasync def read_emails(context: Context, max_results: int = 10) -> str:\n    \"\"\"Read recent emails from Gmail.\"\"\"\n    credentials = Credentials(token=context.token)\n    service = build('gmail', 'v1', credentials=credentials)\n    # ... Gmail API calls\n    return f\"Retrieved {max_results} emails\"\n```\n\nTools with `auth_provider` must:\n\n* Have `context: Context` as the first parameter\n* Specify at least one scope\n* Use `context.token` to make authenticated API calls\n\n### Custom request authentication\n\nCustom authentication allows you to validate requests and integrate with your identity provider. Define an authentication handler in your `auth.py` file:\n\n```python  theme={null}\nfrom langsmith_tool_server import Auth\n\nauth = Auth()\n\n@auth.authenticate\nasync def authenticate(authorization: str = None) -> dict:\n    \"\"\"Validate requests and return user identity.\"\"\"\n    if not authorization or not authorization.startswith(\"Bearer \"):\n        raise auth.exceptions.HTTPException(\n            status_code=401,\n            detail=\"Unauthorized\"\n        )\n\n    token = authorization.replace(\"Bearer \", \"\")\n    # Validate token with your identity provider\n    user = await verify_token_with_idp(token)\n\n    return {\"identity\": user.id}\n```\n\nThe handler runs on every request and must return a dict with `identity` (and optionally `permissions`).\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/agent-builder-mcp-framework.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 3:\nTitle: Workspace vs. private agents\nLink: https://docs.langchain.comlangsmith/agent-builder-workspace-vs-private\nContent: Agent Builder supports two visibility modes:\n\n* Private agents: private to the creator. Useful for personal workflows and experiments.\n* Workspace agents: shared within the workspace. Good for team workflows, or agents you want to share with others.\n\n## Differences\n\n* Ownership and access: private agents are only visible to you; workspace agents are visible to anyone else within the same LangSmith workspace.\n* Tool Authentication:\n  * **OAuth**: Both modes support OAuth and secret-based tools. OAuth credentials are always scoped to a user, so workspace agents can not share OAuth tokens, and new users cloning workspace agents must re-authenticate with the selected tools.\n  * **Secrets**: Since secrets are scoped to a workspace, workspace agents & private agents will both use the same LangSmith secret.\n\n## What's public vs. private\n\n### Threads/chat history\n\nThreads are always user scoped, so even if an agent is workspace scoped, the chat history created within that agent will always be private, and only accessible to the specific user who created them.\n\n### System prompt, tools, sub-agents\n\nThe system prompt, selected tools, and sub-agents will be public on workspace scoped agents. Users will not be able to modify these fields on the original workspace scoped agent, but can make changes once they've cloned the agent.\n\n### Triggers\n\nThe trigger type on workspace scoped agents is public (e.g., Slack message received), but the specific connection with the trigger (e.g. the Slack channel, or Gmail address) is not shared. This way, users know what trigger to use when cloning an agent, but can't gain unauthorized access to any connections the original user has set up.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/agent-builder-workspace-vs-private.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 4:\nTitle: Google\nLink: https://docs.langchain.comoss/python/integrations/providers/google\nContent: Toolkits\nCollections of tools for specific Google services. Gmail Toolkit to create, get, search, and send emails using the Gmail API.\n\nTools\nGoogle Search Perform web searches using Google Custom Search Engine (CSE). Google Drive Tools for interacting with Google Drive. Google Finance Query financial data. Google Jobs Query job listings. Google Lens Perform visual searches. Google Places Search for places information. Google Scholar Search academic papers. Google Trends Query Google Trends data.\n\nSearch\nSearchApi searchapi.io provides API access to Google search results, YouTube, and more. SerpApi SerpApi provides API access to Google search results. Serper.dev serper.dev provides API access to Google search results.\n\n---\n\nResult 5:\nTitle: Tools and toolkits\nLink: https://docs.langchain.comoss/python/integrations/tools/index\nContent: Productivity\nThe following table shows tools that can be used to automate tasks in productivity tools: Tool/Toolkit Pricing GitHub Toolkit Free GitLab Toolkit Free for personal project Gmail Toolkit Free, with limit of 250 quota units per user per second Infobip Tool Free trial, with variable pricing after Jira Toolkit Free, with rate limits Office365 Toolkit Free with Office365, includes rate limits Slack Toolkit Free Twilio Tool Free trial, with pay-as-you-go pricing after\n\nAll tools and toolkits\nADS4GPTs AgentQL AINetwork Toolkit Alpha Vantage Amadeus Toolkit Anchor Browser Apify Actor ArXiv AskNews AWS Lambda Azure AI Services Toolkit Azure Cognitive Services Toolkit Azure Container Apps Dynamic Sessions Shell (bash) Bearly Code Interpreter Bing Search Bodo DataFrames Brave Search BrightData Web Scraper API BrightData SERP BrightData Unlocker Cassandra Database Toolkit CDP ChatGPT Plugins ClickUp Toolkit Cogniswitch Toolkit Compass DeFi Toolkit Composio Connery Toolkit Dall-E Image Generator Dappier Databricks Unity Catalog DataForSEO Dataherald Daytona Data Analysis DuckDuckGo Search Discord E2B Data Analysis Eden AI ElevenLabs Text2Speech Exa Search File System Financial Datasets Toolkit FMP Data GitHub Toolkit GitLab Toolkit Gmail Toolkit GOAT Privy Golden Query Google Books Google Calendar Toolkit Google Cloud Text-to-Speech Google Drive Google Finance Google Imagen Google Jobs Google Lens Google Places Google Scholar Google Search Google Serper Google Trends Gradio GraphQL HuggingFace Hub Tools Human as a Tool Hyperbrowser Browser Agent Tools Hyperbrowser Web Scraping Tools IBM watsonx.ai IBM watsonx.ai (SQL) IFTTT WebHooks Infobip Ionic Shopping Tool Jenkins Jina Search Jira Toolkit JSON Toolkit Lemon Agent Linkup Search Tool Memgraph Memorize Mojeek Search MultiOn Toolkit NASA Toolkit Naver Search Nuclia Understanding NVIDIA Riva Office365 Toolkit OpenAPI Toolkit Natural Language API Toolkits OpenGradient OpenWeatherMap Oracle AI Vector Search Oxylabs Pandas Dataframe Passio NutritionAI Parallel Extract Parallel Search Permit PlayWright Browser Toolkit Polygon IO Toolkit PowerBI Toolkit Prolog PubMed Python REPL Reddit Search Requests Toolkit Riza Code Interpreter Robocorp Toolkit Salesforce SceneXplain ScrapeGraph Scrapeless Crawl Scrapeless Scraping API Scrapeless Universal Scraping SearchApi SearxNG Search Semantic Scholar API SerpApi Slack Toolkit Spark SQL Toolkit SQLDatabase Toolkit StackExchange Steam Toolkit Stripe Tableau Taiga Tavily Extract Tavily Search Tilores MCP Toolbox Twilio Upstage Valthera ValyuContext Vectara Wikidata Wikipedia Wolfram Alpha WRITER Tools Yahoo Finance News You.com Search YouTube Zapier Natural Language Actions ZenGuard AI If you'd like to contribute an integration, see Contributing integrations. Edit this page on GitHub or file an issue. Connect these docs to Claude, VSCode, and more via MCP for real-time answers.\n\nSearch\nThe following table shows tools that execute online searches in some shape or form: Tool/Toolkit Free/Paid Return Data Bing Search Paid URL, Snippet, Title Brave Search Free URL, Snippet, Title DuckDuckgoSearch Free URL, Snippet, Title Exa Search 1000 free searches/month URL, Author, Title, Published Date Google Search Paid URL, Snippet, Title Google Serper Free URL, Snippet, Title, Search Rank, Site Links Jina Search 1M Response Tokens Free URL, Snippet, Title, Page Content Mojeek Search Paid URL, Snippet, Title Parallel Search Paid URL, Title, Excerpts SearchApi 100 Free Searches on Sign Up URL, Snippet, Title, Search Rank, Site Links, Authors SearxNG Search Free URL, Snippet, Title, Category SerpApi 250 Free Searches/Month Answer Tavily Search 1000 free searches/month URL, Content, Title, Images, Answer You.com Search Free for 60 days URL, Title, Page Content\n"
  },
  {
    "role": "tool",
    "name": "search_support_articles",
    "tool_call_id": "call_3HVwEGo72osb0EbBfsC3vABN",
    "id": "5c064fe7-42da-4cb2-877f-544ba1f8c653",
    "content": "{\n  \"collections\": \"OSS (LangChain and LangGraph),SDKs and APIs\",\n  \"total\": 14,\n  \"articles\": [\n    {\n      \"id\": \"bb651320-775e-4dfa-a054-c955cc3a0d5d\",\n      \"title\": \"Why Do Pydantic\\u00a0date\\u00a0Fields Fail in LangGraph State?\",\n      \"url\": \"https://support.langchain.com/articles/7196116702-why-do-pydantic-date-fields-fail-in-langgraph-state\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"ae959c68-a996-4426-8c8e-ef3fa1dd88cc\",\n      \"title\": \"How do I connect JIRA, Slack, and Confluence MCPs with LangChain?\",\n      \"url\": \"https://support.langchain.com/articles/3473375007-how-do-i-connect-jira-slack-and-confluence-mcps-with-langchain\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"2836b779-a2f5-4058-a994-4fe2502166ca\",\n      \"title\": \"Missing Runs in LangSmith Experiment View with Concurrent Evaluations\",\n      \"url\": \"https://support.langchain.com/articles/8223468578-missing-runs-in-langsmith-experiment-view-with-concurrent-evaluations\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"d55d04fa-c883-4055-b266-343e5157ad31\",\n      \"title\": \"Preserving Trace Hierarchy with Manual RunTree Creation\",\n      \"url\": \"https://support.langchain.com/articles/9515178454-preserving-trace-hierarchy-with-manual-runtree-creation\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"9e06b53a-7b85-4793-b7b6-e179c0c8d815\",\n      \"title\": \"Isolating Subgraph State When Calling Graphs from Tools\",\n      \"url\": \"https://support.langchain.com/articles/6131002418-isolating-subgraph-state-when-calling-graphs-from-tools\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"9ef77ded-7211-4d09-944a-289972726262\",\n      \"title\": \"Why am I getting \\\"Failed to send compressed multipart ingest\\\" errors in LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9901468881-why-am-i-getting-failed-to-send-compressed-multipart-ingest-errors-in-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"e72b134e-bd5a-471d-93ea-8def86caf74a\",\n      \"title\": \"Why do I see inconsistent output formats for the same agent across different traces?\",\n      \"url\": \"https://support.langchain.com/articles/2041161407-why-do-i-see-inconsistent-output-formats-for-the-same-agent-across-different-traces\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"3ea46ebf-6af5-4ce2-b678-1c7d4b82caba\",\n      \"title\": \"Can I reopen a run after calling patch() to write additional data?\",\n      \"url\": \"https://support.langchain.com/articles/9964614152-can-i-reopen-a-run-after-calling-patch-to-write-additional-data\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"32994e7d-a182-41df-9f3d-271adf84fde2\",\n      \"title\": \"How do I filter runs by multiple run IDs using tree filters?\",\n      \"url\": \"https://support.langchain.com/articles/2574288399-how-do-i-filter-runs-by-multiple-run-ids-using-tree-filters\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f5a80963-8fe3-415f-b0e2-04b6f5093f12\",\n      \"title\": \"How do I filter runs by name using the LangSmith SDK?\",\n      \"url\": \"https://support.langchain.com/articles/5601207552-how-do-i-filter-runs-by-name-using-the-langsmith-sdk\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"f51b0bb0-b838-40db-baa9-f9099ae34c2f\",\n      \"title\": \"How do I use LangSmith tracing with Cloudflare Workers?\",\n      \"url\": \"https://support.langchain.com/articles/1885761495-how-do-i-use-langsmith-tracing-with-cloudflare-workers\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"e2c86d05-b6fd-4bb3-8637-3f6d35c106dd\",\n      \"title\": \"How do I trace Vercel AI SDK calls with LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9620089182-how-do-i-trace-vercel-ai-sdk-calls-with-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    },\n    {\n      \"id\": \"5f2572a3-9086-4d92-8d15-69f7b8e4c8be\",\n      \"title\": \"MCP Server Runtime in Google Colab / Jupyter Notebook\",\n      \"url\": \"https://support.langchain.com/articles/1061688976-mcp-server-runtime-in-google-colab-jupyter-notebook\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"45269e32-5322-4a17-8866-da640169d21d\",\n      \"title\": \"How do I export annotated traces in bulk from LangSmith?\",\n      \"url\": \"https://support.langchain.com/articles/9958349143-how-do-i-export-annotated-traces-in-bulk-from-langsmith\",\n      \"collection\": \"SDKs and APIs\"\n    }\n  ],\n  \"note\": \"All articles listed are public and have content. Use IDs to fetch full content.\"\n}"
  },
  {
    "role": "assistant",
    "id": "lc_run--019b384e-ab93-7222-b623-2ebe00a12712",
    "content": "**The Gmail tool lets agents access and manipulate a user's Gmail via the Gmail API\u2014read/search messages, create drafts, send emails, and react to incoming mail (requires OAuth and the appropriate Gmail scopes).**\n\nIt works by running authenticated Gmail API calls inside a tool that the agent can call; tools that access Gmail must be configured with an OAuth provider and explicit scopes (for example `https://www.googleapis.com/auth/gmail.readonly` to read and `https://www.googleapis.com/auth/gmail.send` to send). Agents can also be triggered on incoming Gmail messages in Agent Builder.\n\n```python\n# Example (LangSmith Tool Server / Agent Builder style)\nfrom langsmith_tool_server import tool, Context\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\n\n@tool(\n    auth_provider=\"google\",\n    scopes=[\n        \"https://www.googleapis.com/auth/gmail.readonly\",\n        \"https://www.googleapis.com/auth/gmail.send\"\n    ],\n    integration=\"gmail\"\n)\nasync def read_emails(context: Context, max_results: int = 5) -> str:\n    \"\"\"Read recent emails from the authenticated user's mailbox.\"\"\"\n    # Use the OAuth token provided in context to build a Gmail client\n    creds = Credentials(token=context.token)\n    service = build(\"gmail\", \"v1\", credentials=creds)\n    msgs = service.users().messages().list(userId=\"me\", maxResults=max_results).execute()\n    return f\"Found {len(msgs.get('messages', []))} messages\"\n```\n\nCommon uses and notes:\n\n- Use cases:\n  \n  - Read/search mailbox and threads\n  - Compose/send messages or create drafts\n  - Trigger agents on incoming mail (automation)\n  - Manage labels, threads, attachments (via Gmail API)\n\n- Requirements and limits:\n  \n  - Must configure OAuth (Agent Auth) and request correct Gmail scopes\n  - Gmail Toolkit has usage/rate limits (docs list quota guidance, e.g., quota units per user)\n\n- Security:\n  \n  - OAuth tokens are user-scoped; workspace agents requiring Gmail access need each user to authenticate\n  - Only grant the minimum scopes needed (`gmail.readonly` vs `gmail.modify` vs `gmail.send`)\n\nRelevant docs:\n\n- [Agent Builder essentials](https://docs.langchain.com/langsmith/agent-builder-essentials)  \n- [LangSmith Tool Server / MCP framework (tool auth example)](https://docs.langchain.com/langsmith/agent-builder-mcp-framework)  \n- [Google integrations / Gmail Toolkit (tools index)](https://docs.langchain.com/oss/python/integrations/providers/google)"
  },
  {
    "role": "user",
    "id": "da074197-5dcb-4bcf-854b-18a6860d66a5",
    "content": "If I want to build a agentic ai system where user can connect there external app like gmail , twitter so when they ask to send an emaik to thier freind my system should send email using tools but this enail from the user's account not from my system how can i make this oauth i have integration table in my database with these fields Table: integration_tokens\nColumns\nid\nType: UUID\nPrimary Key\nuser_id\nType: UUID\nForeign Key \u2192 users(id)\nNOT NULL\nprovider\nType: VARCHAR\nNOT NULL\nExample values: google, notion, twitter\naccess_token\nType: TEXT\nNOT NULL\nrefresh_token\nType: TEXT\nNULL allowed\nexpires_at\nType: TIMESTAMPTZ\nNULL allowed\nscope\nType: TEXT\nNULL allowed\ncreated_at\nType: TIMESTAMPTZ\nNOT NULL\nDefault: CURRENT_TIMESTAMP\nupdated_at\nType: TIMESTAMPTZ\nNOT NULL\nDefault: CURRENT_TIMESTAMP\nConstraints\nPrimary Key\nid\nForeign Key\nuser_id \u2192 users(id)\nON DELETE CASCADE\nUnique Constraint\n(user_id, provider)"
  },
  {
    "role": "assistant",
    "tool_calls": [
      {
        "type": "function",
        "id": "call_JgqixvgfTEbWPa5gOYuVhwjn",
        "function": {
          "name": "SearchDocsByLangChain",
          "arguments": "{\"language\": \"python\", \"page_size\": 5, \"query\": \"authentication\"}"
        }
      },
      {
        "type": "function",
        "id": "call_Ez91lFPFDTcNzY2N2DwWJMdy",
        "function": {
          "name": "search_support_articles",
          "arguments": "{\"collections\": \"OSS (LangChain and LangGraph),LangSmith Deployment,LangSmith Studio\"}"
        }
      }
    ],
    "id": "lc_run--019b3852-c62a-7973-bffc-b98bfdb3d0b8",
    "content": ""
  },
  {
    "role": "tool",
    "name": "SearchDocsByLangChain",
    "tool_call_id": "call_JgqixvgfTEbWPa5gOYuVhwjn",
    "id": "eeb2eddf-dcd0-4409-aff4-7fce2014433e",
    "content": "Result 1:\nTitle: Authenticate\nLink: https://docs.langchain.comapi-reference/auth-service-v2/authenticate\nContent: \n\n---\n\nResult 2:\nTitle: Wait For Auth Completion\nLink: https://docs.langchain.comapi-reference/auth-service-v2/wait-for-auth-completion\nContent: \n\n---\n\nResult 3:\nTitle: LangSmith Tool Server\nLink: https://docs.langchain.comlangsmith/agent-builder-mcp-framework\nContent: The LangSmith Tool Server is a standalone MCP framework for building and deploying tools with built-in authentication and authorization. Use the Tool Server when you want to:\n\n* [Create custom tools](#create-a-custom-toolkit) that integrate with LangSmith's [Agent Auth](/langsmith/agent-auth) for OAuth authentication\n* [Build an MCP gateway](#use-as-an-mcp-gateway) for agents you're building yourself (outside of Agent Builder)\n\n<Note>\n  If you're using [Agent Builder](/langsmith/agent-builder), you don't need to interact with the Tool Server directly. Agent Builder provides [built-in tools](/langsmith/agent-builder-tools) and supports [remote MCP servers](/langsmith/agent-builder-tools#using-remote-mcp-servers) without requiring Tool Server setup.\n\n  However, you can configure the associated tool server instance as an MCP server, which will allow you to use your custom MCP servers in your agent.\n</Note>\n\nDownload the [PyPi package](https://pypi.org/project/langsmith-tool-server/) to get started.\n\n## Create a custom toolkit\n\nInstall the LangSmith Tool Server and LangChain CLI:\n\n```bash  theme={null}\npip install langsmith-tool-server\npip install langchain-cli-v2\n```\n\nCreate a new toolkit:\n\n```bash  theme={null}\nlangchain tools new my-toolkit\ncd my-toolkit\n```\n\nThis creates a toolkit with the following structure:\n\n```\nmy-toolkit/\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 toolkit.toml\n\u2514\u2500\u2500 my_toolkit/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 auth.py\n    \u2514\u2500\u2500 tools/\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 ...\n```\n\nDefine your tools using the `@tool` decorator:\n\n```python  theme={null}\nfrom langsmith_tool_server import tool\n\n@tool\ndef hello(name: str) -> str:\n    \"\"\"Greet someone by name.\"\"\"\n    return f\"Hello, {name}!\"\n\n@tool\ndef add(x: int, y: int) -> int:\n    \"\"\"Add two numbers.\"\"\"\n    return x + y\n\nTOOLS = [hello, add]\n```\n\nRun the server:\n\n```bash  theme={null}\nlangchain tools serve\n```\n\nYour tool server will start on `http://localhost:8000`.\n\n## Call tools via MCP protocol\n\nBelow is an example that lists available tools and calls the `add` tool:\n\n```python  theme={null}\nimport asyncio\nimport aiohttp\n\nasync def mcp_request(url: str, method: str, params: dict = None):\n    async with aiohttp.ClientSession() as session:\n        payload = {\"jsonrpc\": \"2.0\", \"method\": method, \"params\": params or {}, \"id\": 1}\n        async with session.post(f\"{url}/mcp\", json=payload) as response:\n            return await response.json()\n\nasync def main():\n    url = \"http://localhost:8000\"\n\n    tools = await mcp_request(url, \"tools/list\")\n    print(f\"Tools: {tools}\")\n\n    result = await mcp_request(url, \"tools/call\", {\"name\": \"add\", \"arguments\": {\"a\": 5, \"b\": 3}})\n    print(f\"Result: {result}\")\n\nasyncio.run(main())\n```\n\n## Use as an MCP gateway\n\nThe LangSmith Tool Server can act as an MCP gateway, aggregating tools from multiple MCP servers into a single endpoint. Configure MCP servers in your `toolkit.toml`:\n\n```toml  theme={null}\n[toolkit]\nname = \"my-toolkit\"\ntools = \"./my_toolkit/__init__.py:TOOLS\"\n\n[[mcp_servers]]\nname = \"weather\"\ntransport = \"streamable_http\"\nurl = \"http://localhost:8001/mcp/\"\n\n[[mcp_servers]]\nname = \"math\"\ntransport = \"stdio\"\ncommand = \"python\"\nargs = [\"-m\", \"mcp_server_math\"]\n```\n\nAll tools from connected MCP servers are exposed through your server's `/mcp` endpoint. MCP tools are prefixed with their server name to avoid conflicts (e.g., `weather_get_forecast`, `math_add`).\n\n## Authenticate\n\n### OAuth for third-party APIs\n\nFor tools that need to access third-party APIs (like Google, GitHub, Slack, etc.), you can use OAuth authentication with [Agent Auth](/langsmith/agent-auth).\n\nBefore using OAuth in your tools, you'll need to configure an OAuth provider in your LangSmith workspace settings. See the [Agent Auth documentation](/langsmith/agent-auth) for setup instructions.\n\nOnce configured, specify the `auth_provider` in your tool decorator:\n\n```python  theme={null}\nfrom langsmith_tool_server import tool, Context\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\n\n@tool(\n    auth_provider=\"google\",\n    scopes=[\"https://www.googleapis.com/auth/gmail.readonly\"],\n    integration=\"gmail\"\n)\nasync def read_emails(context: Context, max_results: int = 10) -> str:\n    \"\"\"Read recent emails from Gmail.\"\"\"\n    credentials = Credentials(token=context.token)\n    service = build('gmail', 'v1', credentials=credentials)\n    # ... Gmail API calls\n    return f\"Retrieved {max_results} emails\"\n```\n\nTools with `auth_provider` must:\n\n* Have `context: Context` as the first parameter\n* Specify at least one scope\n* Use `context.token` to make authenticated API calls\n\n### Custom request authentication\n\nCustom authentication allows you to validate requests and integrate with your identity provider. Define an authentication handler in your `auth.py` file:\n\n```python  theme={null}\nfrom langsmith_tool_server import Auth\n\nauth = Auth()\n\n@auth.authenticate\nasync def authenticate(authorization: str = None) -> dict:\n    \"\"\"Validate requests and return user identity.\"\"\"\n    if not authorization or not authorization.startswith(\"Bearer \"):\n        raise auth.exceptions.HTTPException(\n            status_code=401,\n            detail=\"Unauthorized\"\n        )\n\n    token = authorization.replace(\"Bearer \", \"\")\n    # Validate token with your identity provider\n    user = await verify_token_with_idp(token)\n\n    return {\"identity\": user.id}\n```\n\nThe handler runs on every request and must return a dict with `identity` (and optionally `permissions`).\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/agent-builder-mcp-framework.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n\n---\n\nResult 4:\nTitle: LangGraph CLI\nLink: https://docs.langchain.comlangsmith/cli\nContent: Adding custom authentication\nSee the authentication conceptual guide for details, and the setting up custom authentication guide for a practical walk through of the process.\n\nCustomizing HTTP middleware and headers\nThe http block lets you fine-tune request handling: middleware_order : Choose \"auth_first\" to run authentication before your middleware, or \"middleware_first\" (default) to invert that order. enable_custom_route_auth : Extend authentication to routes you mount through http.app. configurable_headers / logging_headers : Each accepts an object with optional includes and excludes arrays; wildcards are supported and exclusions run before inclusions. cors : In addition to allow_origins , allow_methods , and allow_headers , you can set allow_credentials , allow_origin_regex , expose_headers , and max_age for detailed browser control.\n\nPython\nBasic configuration {\n  \"$schema\": \"https://langgra.ph/schema.json\",\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"chat\": \"chat.graph:graph\"\n  }\n} Using Wolfi base images You can specify the Linux distribution for your base image using the  image_distro  field. Valid options are  debian ,  wolfi ,  bookworm , or  bullseye . Wolfi is the recommended option as it provides smaller and more secure images. This is available in  langgraph-cli>=0.2.11 . {\n  \"$schema\": \"https://langgra.ph/schema.json\",\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"chat\": \"chat.graph:graph\"\n  },\n  \"image_distro\": \"wolfi\"\n} Adding semantic search to the store All deployments come with a DB-backed BaseStore. Adding an \"index\" configuration to your  langgraph.json  will enable  semantic search  within the BaseStore of your deployment. The  index.fields  configuration determines which parts of your documents to embed: If omitted or set to  [\"$\"] , the entire document will be embedded To embed specific fields, use JSON path notation:  [\"metadata.title\", \"content.text\"] Documents missing specified fields will still be stored but won't have embeddings for those fields You can still override which fields to embed on a specific item at  put  time using the  index  parameter {\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"memory_agent\": \"./agent/graph.py:graph\"\n  },\n  \"store\": {\n    \"index\": {\n      \"embed\": \"openai:text-embedding-3-small\",\n      \"dims\": 1536,\n      \"fields\": [\"$\"]\n    }\n  }\n} Common model dimensions openai:text-embedding-3-large : 3072 openai:text-embedding-3-small : 1536 openai:text-embedding-ada-002 : 1536 cohere:embed-english-v3.0 : 1024 cohere:embed-english-light-v3.0 : 384 cohere:embed-multilingual-v3.0 : 1024 cohere:embed-multilingual-light-v3.0 : 384 Semantic search with a custom embedding function If you want to use semantic search with a custom embedding function, you can pass a path to a custom embedding function: {\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"memory_agent\": \"./agent/graph.py:graph\"\n  },\n  \"store\": {\n    \"index\": {\n      \"embed\": \"./embeddings.py:embed_texts\",\n      \"dims\": 768,\n      \"fields\": [\"text\", \"summary\"]\n    }\n  }\n} The  embed  field in store configuration can reference a custom function that takes a list of strings and returns a list of embeddings. Example implementation: # embeddings.py\ndef embed_texts(texts: list[str]) -> list[list[float]]:\n    \"\"\"Custom embedding function for semantic search.\"\"\"\n    # Implementation using your preferred embedding model\n    return [[0.1, 0.2, ...] for _ in texts]  # dims-dimensional vectors Adding custom authentication {\n  \"$schema\": \"https://langgra.ph/schema.json\",\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"chat\": \"chat.graph:graph\"\n  },\n  \"auth\": {\n    \"path\": \"./auth.py:auth\",\n    \"openapi\": {\n      \"securitySchemes\": {\n        \"apiKeyAuth\": {\n          \"type\": \"apiKey\",\n          \"in\": \"header\",\n          \"name\": \"X-API-Key\"\n        }\n      },\n      \"security\": [{ \"apiKeyAuth\": [] }]\n    },\n    \"disable_studio_auth\": false\n  }\n} See the  authentication conceptual guide  for details, and the  setting up custom authentication  guide for a practical walk through of the process.  Configuring store item Time-to-Live You can configure default data expiration for items/memories in the BaseStore using the  store.ttl  key. This determines how long items are retained after they are last accessed (with reads potentially refreshing the timer based on  refresh_on_read ). Note that these defaults can be overwritten on a per-call basis by modifying the corresponding arguments in  get ,  search , etc. The  ttl  configuration is an object containing optional fields: refresh_on_read : If  true  (the default), accessing an item via  get  or  search  resets its expiration timer. Set to  false  to only refresh TTL on writes ( put ). default_ttl : The default lifespan of an item in  minutes . Applies only to newly created items; existing items are not modified. If not set, items do not expire by default. sweep_interval_minutes : How frequently (in minutes) the system should run a background process to delete expired items. If not set, sweeping does not occur automatically. Here is an example enabling a 7-day TTL (10080 minutes), refreshing on reads, and sweeping every hour: {\n  \"$schema\": \"https://langgra.ph/schema.json\",\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"memory_agent\": \"./agent/graph.py:graph\"\n  },\n  \"store\": {\n    \"ttl\": {\n      \"refresh_on_read\": true,\n      \"sweep_interval_minutes\": 60,\n      \"default_ttl\": 10080\n    }\n  }\n}  Configuring checkpoint Time-to-Live You can configure the time-to-live (TTL) for checkpoints using the  checkpointer  key. This determines how long checkpoint data is retained before being automatically handled according to the specified strategy (e.g., deletion). Two optional sub-objects are supported: ttl : Includes  strategy ,  sweep_interval_minutes , and  default_ttl , which collectively set how checkpoints expire. serde   (Agent server 0.5+)  : Lets you control deserialization behavior for checkpoint payloads. Here's an example setting a default TTL of 30 days (43200 minutes): {\n  \"$schema\": \"https://langgra.ph/schema.json\",\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"chat\": \"chat.graph:graph\"\n  },\n  \"checkpointer\": {\n    \"ttl\": {\n      \"strategy\": \"delete\",\n      \"sweep_interval_minutes\": 10,\n      \"default_ttl\": 43200\n    }\n  }\n} In this example, checkpoints older than 30 days will be deleted, and the check runs every 10 minutes. Configuring checkpointer serde The  checkpointer.serde  object shapes deserialization: allowed_json_modules  defines an allow list for custom Python objects you want the server to be able to deserialize from payloads saved in \"json\" mode. This is a list of  [path, to, module, file, symbol]  sequences. If omitted, only LangChain-safe defaults are allowed. You can unsafely set to  true  to allow any module to be deserialized. pickle_fallback : Whether to fall back to pickle deserialization when JSON decoding fails. {\n  \"checkpointer\": {\n    \"serde\": {\n      \"allowed_json_modules\": [\n        [\"my_agent\", \"auth\", \"SessionState\"]\n      ]\n    }\n  }\n} Customizing HTTP middleware and headers The  http  block lets you fine-tune request handling: middleware_order : Choose  \"auth_first\"  to run authentication before your middleware, or  \"middleware_first\"  (default) to invert that order. enable_custom_route_auth : Extend authentication to routes you mount through  http.app . configurable_headers  /  logging_headers : Each accepts an object with optional  includes  and  excludes  arrays; wildcards are supported and exclusions run before inclusi...\n\n---\n\nResult 5:\nTitle: Set up custom authentication\nLink: https://docs.langchain.comlangsmith/set-up-custom-auth\nContent: In this tutorial, we will build a chatbot that only lets specific users access it. We'll start with the LangGraph template and add token-based security step by step. By the end, you'll have a working chatbot that checks for valid tokens before allowing access.\n\nThis is part 1 of our authentication series:\n\n1. Set up custom authentication (you are here) - Control who can access your bot\n2. [Make conversations private](/langsmith/resource-auth) - Let users have private conversations\n3. [Connect an authentication provider](/langsmith/add-auth-server) - Add real user accounts and validate using OAuth2 for production\n\nThis guide assumes basic familiarity with the following concepts:\n\n* [**Authentication & Access Control**](/langsmith/auth)\n* [**LangSmith**](/langsmith/home)\n\n<Note>\n  Custom auth is only available for LangSmith SaaS deployments or Enterprise Self-Hosted deployments.\n</Note>\n\n## 1. Create your app\n\nCreate a new chatbot using the LangGraph starter template:\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install -U \"langgraph-cli[inmem]\"\n  langgraph new --template=new-langgraph-project-python custom-auth\n  cd custom-auth\n  ```\n\n  ```bash uv theme={null}\n  uv add langgraph-cli[inmem]\n  langgraph new --template=new-langgraph-project-python custom-auth\n  cd custom-auth\n  ```\n</CodeGroup>\n\nThe template gives us a placeholder LangGraph app. Try it out by installing the local dependencies and running the development server:\n\n<CodeGroup>\n  ```bash pip theme={null}\n  pip install -e .\n  langgraph dev\n  ```\n\n  ```bash uv theme={null}\n  uv add .\n  langgraph dev\n  ```\n\n  ```bash npm theme={null}\n  npx @langchain/langgraph-cli dev\n  ```\n</CodeGroup>\n\nThe server will start and open [Studio](/langsmith/studio) in your browser:\n\n```\n> - \ud83d\ude80 API: http://127.0.0.1:2024\n> - \ud83c\udfa8 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n> - \ud83d\udcda API Docs: http://127.0.0.1:2024/docs\n>\n> This in-memory server is designed for development and testing.\n> For production use, please use LangSmith.\n```\n\nIf you were to self-host this on the public internet, anyone could access it.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/N1xJUsnxxRqnrjxV/langsmith/images/no-auth.png?fit=max&auto=format&n=N1xJUsnxxRqnrjxV&q=85&s=3ca2c9a8d65891ef71abfb7ad0aae7d3\" alt=\"No authentication: the dev server is publicly reachable, anyone can access the bot if exposed to the internet.\" data-og-width=\"1974\" width=\"1974\" data-og-height=\"1412\" height=\"1412\" data-path=\"langsmith/images/no-auth.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/N1xJUsnxxRqnrjxV/langsmith/images/no-auth.png?w=280&fit=max&auto=format&n=N1xJUsnxxRqnrjxV&q=85&s=67bfe450ee04d2432e5e1b86cfa0af1c 280w, https://mintcdn.com/langchain-5e9cc07a/N1xJUsnxxRqnrjxV/langsmith/images/no-auth.png?w=560&fit=max&auto=format&n=N1xJUsnxxRqnrjxV&q=85&s=087f8083981ae85eeca794bdca3e0e05 560w, https://mintcdn.com/langchain-5e9cc07a/N1xJUsnxxRqnrjxV/langsmith/images/no-auth.png?w=840&fit=max&auto=format&n=N1xJUsnxxRqnrjxV&q=85&s=7967264c0243918be1a8561d4db89586 840w, https://mintcdn.com/langchain-5e9cc07a/N1xJUsnxxRqnrjxV/langsmith/images/no-auth.png?w=1100&fit=max&auto=format&n=N1xJUsnxxRqnrjxV&q=85&s=fd9d62383850b137834bfc7e35bc4533 1100w, https://mintcdn.com/langchain-5e9cc07a/N1xJUsnxxRqnrjxV/langsmith/images/no-auth.png?w=1650&fit=max&auto=format&n=N1xJUsnxxRqnrjxV&q=85&s=66100323459f51596c53b3d941e3f85d 1650w, https://mintcdn.com/langchain-5e9cc07a/N1xJUsnxxRqnrjxV/langsmith/images/no-auth.png?w=2500&fit=max&auto=format&n=N1xJUsnxxRqnrjxV&q=85&s=a7b9157f67b3094370cc5399d917a164 2500w\" />\n\n## 2. Add authentication\n\nNow that you have a base LangGraph app, add authentication to it.\n\n<Note>\n  In this tutorial, you will start with a hard-coded token for example purposes. You will get to a \"production-ready\" authentication scheme in the third tutorial.\n</Note>\n\nThe [Auth](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.auth.Auth) object lets you register an authentication function that the LangSmith deployment will run on every request. This function receives each request and decides whether to accept or reject.\n\nCreate a new file `src/security/auth.py`. This is where your code will live to check if users are allowed to access your bot:\n\n```python {highlight={10,15-16}} title=\"src/security/auth.py\" theme={null}\nfrom langgraph_sdk import Auth\n\n# This is our toy user database. Do not do this in production\nVALID_TOKENS = {\n    \"user1-token\": {\"id\": \"user1\", \"name\": \"Alice\"},\n    \"user2-token\": {\"id\": \"user2\", \"name\": \"Bob\"},\n}\n\n# The \"Auth\" object is a container that LangGraph will use to mark our authentication function\nauth = Auth()\n\n\n# The `authenticate` decorator tells LangGraph to call this function as middleware\n# for every request. This will determine whether the request is allowed or not\n@auth.authenticate\nasync def get_current_user(authorization: str | None) -> Auth.types.MinimalUserDict:\n    \"\"\"Check if the user's token is valid.\"\"\"\n    assert authorization\n    scheme, token = authorization.split()\n    assert scheme.lower() == \"bearer\"\n    # Check if token is valid\n    if token not in VALID_TOKENS:\n        raise Auth.exceptions.HTTPException(status_code=401, detail=\"Invalid token\")\n\n    # Return user info if valid\n    user_data = VALID_TOKENS[token]\n    return {\n        \"identity\": user_data[\"id\"],\n    }\n```\n\nNotice that your [Auth.authenticate](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.auth.Auth.authenticate) handler does two important things:\n\n1. Checks if a valid token is provided in the request's [Authorization header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization)\n2. Returns the user's [MinimalUserDict](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.auth.types.MinimalUserDict)\n\nNow tell LangGraph to use authentication by adding the following to the [langgraph.json](https://reference.langchain.com/python/cloud/reference/cli/#configuration-file) configuration:\n\n```json {highlight={7-9}} title=\"langgraph.json\" theme={null}\n{\n  \"dependencies\": [\".\"],\n  \"graphs\": {\n    \"agent\": \"./src/agent/graph.py:graph\"\n  },\n  \"env\": \".env\",\n  \"auth\": {\n    \"path\": \"src/security/auth.py:auth\"\n  }\n}\n```\n\n## 3. Test your bot\n\nStart the server again to test everything out:\n\n```bash  theme={null}\nlanggraph dev --no-browser\n```\n\nIf you didn't add the `--no-browser`, the Studio UI will open in the browser. By default, we also permit access from Studio, even when using custom auth. This makes it easier to develop and test your bot in Studio. You can remove this alternative authentication option by setting `disable_studio_auth: true` in your auth configuration:\n\n```json  theme={null}\n{\n    \"auth\": {\n        \"path\": \"src/security/auth.py:auth\",\n        \"disable_studio_auth\": true\n    }\n}\n```\n\n## 4. Chat with your bot\n\nYou should now only be able to access the bot if you provide a valid token in the request header. Users will still, however, be able to access each other's resources until you add [resource authorization handlers](/langsmith/auth#resource-specific-handlers) in the next section of the tutorial.\n\n<img src=\"https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/authentication.png?fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=3ccfa86789baea630b8f418e9eb5b648\" alt=\"Auth gate passes requests with a valid token, but no per-resource filters are applied yet\u2014so users share visibility until authorization handlers are added in the next step.\" data-og-width=\"2617\" width=\"2617\" data-og-height=\"1673\" height=\"1673\" data-path=\"langsmith/images/authentication.png\" data-optimize=\"true\" data-opv=\"3\" srcset=\"https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/authentication.png?w=280&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=0216c0cf0cb74f67f43e65561a787c96 280w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/authentication.png?w=560&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=c4a9ab37e2413a38dc61ef6f4288c1b1 560w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/authentication.png?w=840&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=d1146dee549ab13c949efae260706988 840w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/authentication.png?w=1100&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=e430d8ebe4534d20c1d4d3d887f0c938 1100w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/authentication.png?w=1650&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=3aeaa334e3ff1457c165821966721f94 1650w, https://mintcdn.com/langchain-5e9cc07a/IMK8wJkjSpMCGODD/langsmith/images/authentication.png?w=2500&fit=max&auto=format&n=IMK8wJkjSpMCGODD&q=85&s=74d6dd4c73baa0182624085d13f08530 2500w\" />\n\nRun the following code in a file or notebook:\n\n```python  theme={null}\nfrom langgraph_sdk import get_client\n\n# Try without a token (should fail)\nclient = get_client(url=\"http://localhost:2024\")\ntry:\n    thread = await client.threads.create()\n    print(\"\u274c Should have failed without token!\")\nexcept Exception as e:\n    print(\"\u2705 Correctly blocked access:\", e)\n\n# Try with a valid token\nclient = get_client(\n    url=\"http://localhost:2024\", headers={\"Authorization\": \"Bearer user1-token\"}\n)\n\n# Create a thread and chat\nthread = await client.threads.create()\nprint(f\"\u2705 Created thread as Alice: {thread['thread_id']}\")\n\nresponse = await client.runs.create(\n    thread_id=thread[\"thread_id\"],\n    assistant_id=\"agent\",\n    input={\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]},\n)\nprint(\"\u2705 Bot responded:\")\nprint(response)\n```\n\nYou should see that:\n\n1. Without a valid token, we can't access the bot\n2. With a valid token, we can create threads and chat\n\nCongratulations! You've built a chatbot that only lets \"authenticated\" users access it. While this system doesn't (yet) implement a production-ready security scheme, we've learned the basic mechanics of how to control access to our bot. In the next tutorial, we'll learn how to give each user their own private conversations.\n\n## Next steps\n\nNow that you can control who accesses your bot, you might want to:\n\n1. Continue the tutorial by going to [Make conversations private](/langsmith/resource-auth) to learn about resource authorization.\n2. Read more about [authentication concepts](/langsmith/auth).\n3. Check out the API reference for [Auth](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.auth.Auth), [Auth.authenticate](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.auth.Auth.authenticate), and [MinimalUserDict](https://reference.langchain.com/python/langsmith/deployment/sdk/#langgraph_sdk.auth.types.MinimalUserDict) for more authentication details.\n\n***\n\n<Callout icon=\"pen-to-square\" iconType=\"regular\">\n  [Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/langsmith/set-up-custom-auth.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n</Callout>\n\n<Tip icon=\"terminal\" iconType=\"regular\">\n  [Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n</Tip>\n\n"
  },
  {
    "role": "tool",
    "name": "search_support_articles",
    "tool_call_id": "call_Ez91lFPFDTcNzY2N2DwWJMdy",
    "id": "c9198020-f6c6-48d7-bb61-06b1c3f3966f",
    "content": "{\n  \"collections\": \"OSS (LangChain and LangGraph),LangSmith Deployment,LangSmith Studio\",\n  \"total\": 18,\n  \"articles\": [\n    {\n      \"id\": \"bb651320-775e-4dfa-a054-c955cc3a0d5d\",\n      \"title\": \"Why Do Pydantic\\u00a0date\\u00a0Fields Fail in LangGraph State?\",\n      \"url\": \"https://support.langchain.com/articles/7196116702-why-do-pydantic-date-fields-fail-in-langgraph-state\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"ae959c68-a996-4426-8c8e-ef3fa1dd88cc\",\n      \"title\": \"How do I connect JIRA, Slack, and Confluence MCPs with LangChain?\",\n      \"url\": \"https://support.langchain.com/articles/3473375007-how-do-i-connect-jira-slack-and-confluence-mcps-with-langchain\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"9e06b53a-7b85-4793-b7b6-e179c0c8d815\",\n      \"title\": \"Isolating Subgraph State When Calling Graphs from Tools\",\n      \"url\": \"https://support.langchain.com/articles/6131002418-isolating-subgraph-state-when-calling-graphs-from-tools\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"61f0452e-5198-4524-9c94-a9cf476ea5bc\",\n      \"title\": \"How to Create a Locked-Down Deployment with Restricted Access\",\n      \"url\": \"https://support.langchain.com/articles/5382256129-how-to-create-a-locked-down-deployment-with-restricted-access\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"365a0d3f-d784-407d-b741-fe51fa8356d4\",\n      \"title\": \"LangSmith Deployments not working with Valkey\",\n      \"url\": \"https://support.langchain.com/articles/2265174426-why-are-my-langgraph-requests-hanging-when-using-aws-elasticache-with-valkey\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"55a2c6fe-adf8-4b55-bcb9-969b465241b7\",\n      \"title\": \"Why are my agent threads getting deleted automatically?\",\n      \"url\": \"https://support.langchain.com/articles/7993792111-why-are-my-threads-being-marked-as-temporary-and-getting-deleted-automatically\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"d270716f-edc0-49d9-b5d1-497b5d0e4e6d\",\n      \"title\": \"Private Network Access Blocking LangSmith Studio Connection\",\n      \"url\": \"https://support.langchain.com/articles/1897181200-private-network-access-blocking-langsmith-studio-connection\",\n      \"collection\": \"LangSmith Studio\"\n    },\n    {\n      \"id\": \"5f2572a3-9086-4d92-8d15-69f7b8e4c8be\",\n      \"title\": \"MCP Server Runtime in Google Colab / Jupyter Notebook\",\n      \"url\": \"https://support.langchain.com/articles/1061688976-mcp-server-runtime-in-google-colab-jupyter-notebook\",\n      \"collection\": \"OSS (LangChain and LangGraph)\"\n    },\n    {\n      \"id\": \"3cec875c-3c8d-4951-b83b-0ac5b8ba7c7c\",\n      \"title\": \"LangSmith Deployments agent is running, but the UI shows it as \\u201cUnsuccessful\\u201d\",\n      \"url\": \"https://support.langchain.com/articles/8394994213-langsmith-deployments-agent-is-running-but-the-ui-shows-it-as-unsuccessful\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"b740be98-677d-486f-ba77-12258712f70a\",\n      \"title\": \"How do I use the LangSmith Control Plane API to manage deployments?\",\n      \"url\": \"https://support.langchain.com/articles/8184800662-how-do-i-use-the-langgraph-platform-control-plane-api-to-manage-deployments\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"52d389ff-3918-46a8-9ccf-55fe972077bf\",\n      \"title\": \"Why is my LangSmith agent queue Deployment timing out after 600 seconds?\",\n      \"url\": \"https://support.langchain.com/articles/7898522976-why-is-my-queue-deployment-timing-out-after-600-seconds\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"c6c77d41-4376-4452-b7a0-fd42c1428242\",\n      \"title\": \"How do I deploy an MCP server on LangSmith Deployments with my agent?\",\n      \"url\": \"https://support.langchain.com/articles/8743137454-how-do-i-deploy-an-mcp-server-on-langsmith-deployments-with-my-agent\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"ebea1a08-4488-4cac-9c65-75442f3de254\",\n      \"title\": \"Adding FastAPI dependency for custom middleware in LangGraph Platform\",\n      \"url\": \"https://support.langchain.com/articles/7593416758-adding-fastapi-dependency-for-custom-middleware-in-langgraph-platform\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"d37491ce-7f3c-4575-91d5-09c62129248e\",\n      \"title\": \"How do I resolve ChatGoogleGenerativeAI blocking errors in LangGraph?\",\n      \"url\": \"https://support.langchain.com/articles/8574277609-how-do-i-resolve-chatgooglegenerativeai-blocking-errors-in-langgraph\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"0b6ce386-e341-47a1-8be9-ae350de16843\",\n      \"title\": \"How do I resolve ChatGoogleGenerativeAI blocking errors in LangGraph?\",\n      \"url\": \"https://support.langchain.com/articles/3873263156-how-do-i-resolve-chatgooglegenerativeai-blocking-errors-in-langgraph\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"68fbf7da-954d-454e-8ad4-73e1f1f63b74\",\n      \"title\": \"LangSmith Studio vs Agent Chat UI: When to Use What\",\n      \"url\": \"https://support.langchain.com/articles/1353449293-langsmith-studio-vs-agent-chat-ui\",\n      \"collection\": \"LangSmith Studio\"\n    },\n    {\n      \"id\": \"f7dc0a0c-fa3f-4319-b820-ae470d89877f\",\n      \"title\": \"Why is token-by-token streaming not working after upgrading LangGraph?\",\n      \"url\": \"https://support.langchain.com/articles/7150806184-why-is-token-by-token-streaming-not-working-after-upgrading-langgraph\",\n      \"collection\": \"LangSmith Deployment\"\n    },\n    {\n      \"id\": \"ada8fd1b-4800-434e-8d6f-b5186b170941\",\n      \"title\": \"LangSmith Studio URL Redirects to Error Page\",\n      \"url\": \"https://support.langchain.com/articles/4270790436-langsmith-studio-url-redirects-to-error-page\",\n      \"collection\": \"LangSmith Studio\"\n    }\n  ],\n  \"note\": \"All articles listed are public and have content. Use IDs to fetch full content.\"\n}"
  },
  {
    "role": "assistant",
    "id": "lc_run--019b3852-f0ba-7c22-9f38-bfb17c557d63",
    "content": "**Yes \u2014 implement a standard per-user OAuth flow, save each user\u2019s `access_token`/`refresh_token` in your `integration_tokens` table, and have your agent tools load and refresh that token at runtime so API calls (e.g., Gmail send) happen as the user.**\n\nThis works because OAuth grants the user\u2019s consent and returns tokens scoped to that user; your agent/tool must look up that user\u2019s token, refresh it if needed, and use it when calling the provider API (never use a single system-level token for user actions).\n\n```python\n# Example: Flask endpoints to start & complete Google OAuth (google-auth-oauthlib)\n# - exchange authorization code for tokens\n# - save tokens into integration_tokens (upsert by user_id+provider)\n\nfrom flask import Flask, redirect, request, session, url_for\nfrom google_auth_oauthlib.flow import Flow\nfrom datetime import datetime, timezone, timedelta\nimport psycopg2  # or use SQLAlchemy\n\napp = Flask(__name__)\napp.secret_key = \"replace-with-secret\"\n\nCLIENT_SECRETS_FILE = \"client_secret.json\"\nSCOPES = [\n    \"https://www.googleapis.com/auth/gmail.send\",\n    \"https://www.googleapis.com/auth/gmail.readonly\",\n]\n\n# Start OAuth: redirect user to Google consent\n@app.route(\"/auth/google/start\")\ndef google_auth_start():\n    flow = Flow.from_client_secrets_file(\n        CLIENT_SECRETS_FILE, scopes=SCOPES,\n        redirect_uri=url_for(\"google_auth_callback\", _external=True)\n    )\n    auth_url, state = flow.authorization_url(access_type=\"offline\", include_granted_scopes=\"true\")\n    session[\"oauth_state\"] = state\n    return redirect(auth_url)\n\n# OAuth callback: exchange code for tokens, store them\n@app.route(\"/auth/google/callback\")\ndef google_auth_callback():\n    flow = Flow.from_client_secrets_file(\n        CLIENT_SECRETS_FILE, scopes=SCOPES,\n        state=session.get(\"oauth_state\"),\n        redirect_uri=url_for(\"google_auth_callback\", _external=True)\n    )\n    flow.fetch_token(authorization_response=request.url)\n    creds = flow.credentials\n\n    # credentials fields\n    access_token = creds.token\n    refresh_token = creds.refresh_token  # may be None if previously granted\n    expires_at = datetime.now(timezone.utc) + timedelta(seconds=creds.expiry.timestamp() - datetime(1970,1,1, tzinfo=timezone.utc).timestamp()) \\\n                 if creds.expiry else None\n    scope = \" \".join(creds.scopes) if creds.scopes else None\n\n    # Save to DB (pseudo - use parameterized queries)\n    user_id = session[\"current_user_id\"]  # your authenticated user\n    conn = psycopg2.connect(...) \n    cur = conn.cursor()\n    cur.execute(\"\"\"\n      INSERT INTO integration_tokens (id, user_id, provider, access_token, refresh_token, expires_at, scope, created_at, updated_at)\n      VALUES (gen_random_uuid(), %s, %s, %s, %s, %s, %s, NOW(), NOW())\n      ON CONFLICT (user_id, provider) DO UPDATE SET\n        access_token = EXCLUDED.access_token,\n        refresh_token = COALESCE(EXCLUDED.refresh_token, integration_tokens.refresh_token),\n        expires_at = EXCLUDED.expires_at,\n        scope = EXCLUDED.scope,\n        updated_at = NOW()\n    \"\"\", (user_id, \"google\", access_token, refresh_token, expires_at, scope))\n    conn.commit()\n    cur.close()\n    conn.close()\n\n    return \"Google connected\"\n```\n\n## Tool runtime: load & refresh tokens, then call Gmail API\n\n- Your agent tool should lookup the user\u2019s token (by `user_id`), construct `Credentials`, refresh if expired, persist updated tokens back to `integration_tokens`, then call Gmail.\n\n```python\n# Example LangChain tool (Python) using ToolRuntime or your own runtime context\nfrom google.oauth2.credentials import Credentials\nfrom googleapiclient.discovery import build\nfrom google.auth.transport.requests import Request\nfrom langchain.tools import tool, ToolRuntime\nimport psycopg2\nfrom datetime import timezone\n\n@tool\ndef send_email(to: str, subject: str, body: str, runtime: ToolRuntime) -> str:\n    \"\"\"Send email from the authenticated user's Gmail.\"\"\"\n    user_id = runtime.context.user_id  # Make sure runtime.context supplies the user id\n\n    # 1) Load tokens from DB\n    conn = psycopg2.connect(...)\n    cur = conn.cursor()\n    cur.execute(\"SELECT access_token, refresh_token, expires_at, scope FROM integration_tokens WHERE user_id=%s AND provider=%s\", (user_id, \"google\"))\n    row = cur.fetchone()\n    if not row:\n        raise Exception(\"Google not connected for user\")\n\n    access_token, refresh_token, expires_at, scope = row\n    # 2) Build Credentials\n    creds = Credentials(\n        token=access_token,\n        refresh_token=refresh_token,\n        token_uri=\"https://oauth2.googleapis.com/token\",\n        client_id=\"YOUR_CLIENT_ID\",\n        client_secret=\"YOUR_CLIENT_SECRET\",\n        scopes=scope.split() if scope else SCOPES\n    )\n\n    # 3) Refresh if needed\n    if not creds.valid:\n        if creds.expired and creds.refresh_token:\n            creds.refresh(Request())  # will call the token endpoint\n            # persist updated access_token & expiry back to DB\n            cur.execute(\"\"\"\n                UPDATE integration_tokens SET access_token=%s, expires_at=%s, updated_at=NOW()\n                WHERE user_id=%s AND provider=%s\n            \"\"\", (creds.token, creds.expiry.astimezone(timezone.utc), user_id, \"google\"))\n            conn.commit()\n        else:\n            raise Exception(\"User needs to re-authenticate\")\n\n    # 4) Call Gmail API with refreshed creds\n    service = build(\"gmail\", \"v1\", credentials=creds)\n    message = (f\"From: me\\nTo: {to}\\nSubject: {subject}\\n\\n{body}\").encode(\"utf-8\")\n    import base64\n    raw = base64.urlsafe_b64encode(message).decode()\n    send_result = service.users().messages().send(userId=\"me\", body={\"raw\": raw}).execute()\n\n    cur.close()\n    conn.close()\n    return f\"Sent message id={send_result['id']}\"\n```\n\n## Integration details & best practices\n\n- Store tokens securely:\n  \n  - Encrypt `refresh_token` at rest; restrict DB access.\n  - Only store the minimum fields you need (`access_token`, `refresh_token`, `expires_at`, `scope`).\n  - Your current schema with unique `(user_id, provider)` is correct for one integration per provider per user.\n\n- Scopes and consent:\n  \n  - Request minimal scopes like `gmail.send` only when needed.\n  - Use `access_type=offline` and `prompt=consent` on first consent to obtain `refresh_token`.\n\n- Token refresh & persistence:\n  \n  - Always persist new `access_token` and updated `expires_at` after refresh.\n  - Handle refresh failures (token revoked) by prompting re-authentication and removing/marking token row.\n\n- Security & multi-tenant considerations:\n  \n  - Associate user actions with `user_id` in runtime context so tools cannot pick another user\u2019s token.\n  - Use per-user OAuth (not a global system credential).\n  - Implement unlink endpoint to delete `integration_tokens` row.\n\n- UX / Agent triggers:\n  \n  - Allow users to connect apps in a settings UI that starts the OAuth flow.\n  - Show which provider accounts are connected and when tokens expire.\n  - For incoming-email triggers, create webhooks or polling that map messages to your user and trigger agents.\n\n- If you use LangSmith/Agent Builder:\n  \n  - You can use the LangSmith Tool Server with `auth_provider=\"google\"` so LangSmith handles OAuth flows and injects `context.token` into tools (docs show `context.token`). If you self-host tools, follow the pattern above to read tokens from your DB and inject into the tool runtime.\n\nRelevant docs:\n\n- [LangSmith Tool Server / MCP framework](https://docs.langchain.com/langsmith/agent-builder-mcp-framework)  \n- [Google integrations / Gmail Toolkit](https://docs.langchain.com/oss/python/integrations/providers/google)  \n- [Tools (Python)](https://docs.langchain.com/oss/python/langchain/tools)  \n- [Set up custom authentication](https://docs.langchain.com/langsmith/set-up-custom-auth)"
  }
]